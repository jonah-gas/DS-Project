{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1075f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision as T\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "root_path = os.path.abspath(os.path.join('../..')) # <- adjust such that root_path always points at the root project dir (i.e. if current file is two folders deep, use '../..'). \n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "import database_server.db_utilities as dbu \n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "from Help_functions import preprocess, game_dict, inputs, inputs_2seas, club_dict, points_and_co, points_and_co_oppon, data_to_lstm, Sport_pred_2LSTM_1, predict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f14d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69420)\n",
    "random.seed(69420)\n",
    "np.random.seed(69420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0920f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "SELECT ms.*, \n",
    "       m.schedule_date, m.schedule_time, m.schedule_round, m.schedule_day,\n",
    "       w.annual_wages_eur AS annual_wage_team, \n",
    "       w.weekly_wages_eur AS weekly_wages_eur,\n",
    "       w.annual_wages_eur/w.n_players AS annual_wage_player_avg\n",
    "FROM matchstats ms \n",
    "LEFT JOIN matches m ON ms.match_id = m.id\n",
    "LEFT JOIN teamwages w ON ms.team_id = w.team_id\n",
    "AND     ms.season_str = w.season_str\n",
    "ORDER BY m.schedule_date DESC, m.schedule_time DESC; \n",
    "\"\"\"\n",
    "\n",
    "df_allinfo = dbu.select_query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cb2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_test = preprocess(df_allinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d390a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_df = new_data_test.data_frame.copy()\n",
    "#scale_df[\"stad_capac\"] = 0\n",
    "for team in scale_df.team_id.unique():\n",
    "    max_attend = max(scale_df[(scale_df.team_id == team) & (scale_df.venue == new_data_test.return_dicts(\"venue\")[\"Home\"])].attendance)\n",
    "    scale_df.loc[(scale_df.team_id == team) & (scale_df.venue == new_data_test.return_dicts(\"venue\")[\"Home\"]),\"stad_capac\"] = scale_df[(scale_df.team_id == team) & (scale_df.venue == new_data_test.return_dicts(\"venue\")[\"Home\"])].attendance.apply(lambda x: x/max_attend)\n",
    "    scale_df.loc[(scale_df.opponent_id == team) & (scale_df.venue == new_data_test.return_dicts(\"venue\")[\"Away\"]),\"stad_capac\"] = scale_df[(scale_df.opponent_id == team) & (scale_df.venue == new_data_test.return_dicts(\"venue\")[\"Away\"])].attendance.apply(lambda x: x/max_attend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f79892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>ga</th>\n",
       "      <th>xg</th>\n",
       "      <th>xga</th>\n",
       "      <th>attendance</th>\n",
       "      <th>captain</th>\n",
       "      <th>formation</th>\n",
       "      <th>referee</th>\n",
       "      <th>...</th>\n",
       "      <th>misc_aerialduels_lost</th>\n",
       "      <th>misc_aerialduels_won_perc</th>\n",
       "      <th>schedule_date</th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>schedule_round</th>\n",
       "      <th>schedule_day</th>\n",
       "      <th>annual_wage_team</th>\n",
       "      <th>weekly_wages_eur</th>\n",
       "      <th>annual_wage_player_avg</th>\n",
       "      <th>stad_capac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.840228</td>\n",
       "      <td>1027</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.984829</td>\n",
       "      <td>1.958156</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.809407</td>\n",
       "      <td>-0.809407</td>\n",
       "      <td>-0.547866</td>\n",
       "      <td>-1.513961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.216427</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.837538</td>\n",
       "      <td>2.666886</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.875627</td>\n",
       "      <td>-0.875628</td>\n",
       "      <td>-0.649831</td>\n",
       "      <td>0.900104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.348198</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132120</td>\n",
       "      <td>-2.331530</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.520861</td>\n",
       "      <td>-0.520861</td>\n",
       "      <td>0.119906</td>\n",
       "      <td>0.991026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.561956</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.984829</td>\n",
       "      <td>0.466091</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.389500</td>\n",
       "      <td>-0.389500</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.701977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.712704</td>\n",
       "      <td>171</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416357</td>\n",
       "      <td>-0.186687</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.751744</td>\n",
       "      <td>-0.751744</td>\n",
       "      <td>-0.441241</td>\n",
       "      <td>-0.962527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   venue  result  gf  ga   xg  xga  attendance  captain  formation  referee  \\\n",
       "0      0       2   3   3  1.8  0.6   -0.840228     1027          2        1   \n",
       "1      1       1   2   3  1.4  1.1   -0.216427       63          2        2   \n",
       "2      1       0   2   1  0.7  1.2   -0.348198      162          2        3   \n",
       "3      0       1   2   5  1.2  4.0   -0.561956      314          0        4   \n",
       "4      0       2   1   1  2.5  1.6   -0.712704      171          3        5   \n",
       "\n",
       "   ...  misc_aerialduels_lost  misc_aerialduels_won_perc  schedule_date  \\\n",
       "0  ...              -0.984829                   1.958156     2023-06-04   \n",
       "1  ...              -1.837538                   2.666886     2023-06-04   \n",
       "2  ...              -0.132120                  -2.331530     2023-06-04   \n",
       "3  ...              -0.984829                   0.466091     2023-06-04   \n",
       "4  ...              -0.416357                  -0.186687     2023-06-04   \n",
       "\n",
       "   schedule_time  schedule_round  schedule_day  annual_wage_team  \\\n",
       "0              1              38             0         -0.809407   \n",
       "1              1              38             0         -0.875627   \n",
       "2              1              38             0         -0.520861   \n",
       "3              1              38             0         -0.389500   \n",
       "4              1              38             0         -0.751744   \n",
       "\n",
       "   weekly_wages_eur  annual_wage_player_avg  stad_capac  \n",
       "0         -0.809407               -0.547866   -1.513961  \n",
       "1         -0.875628               -0.649831    0.900104  \n",
       "2         -0.520861                0.119906    0.991026  \n",
       "3         -0.389500               -0.097483    0.701977  \n",
       "4         -0.751744               -0.441241   -0.962527  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale_df = new_data_test.data_frame.copy()\n",
    "\n",
    "liste = ['schedule_time', 'schedule_round', 'schedule_day', 'result', 'gf', 'ga', 'xg', 'xga', 'formation', \n",
    "         'referee', 'season_str', 'league_id', 'team_id', 'opponent_id', 'match_id', 'id', 'fbref_id', \n",
    "         'home_team_id', 'away_team_id', 'schedule_date', 'venue', 'captain',]\n",
    "\n",
    "cols_to_scale = list(set(list(scale_df.columns)).difference(liste))\n",
    "object_ = StandardScaler()\n",
    "\n",
    "scale_df.loc[:,cols_to_scale] = object_.fit_transform(scale_df.loc[:,cols_to_scale])\n",
    "scale_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d02879",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_team = OneHotEncoder()\n",
    "to_ohe_team = scale_df.loc[:, [\"team_id\", \"opponent_id\"]]\n",
    "ohe_team.fit(to_ohe_team)\n",
    "\n",
    "codes = ohe_team.transform(to_ohe_team).toarray()\n",
    "feature_names = ohe_team.get_feature_names(['team_id', 'opponent_id'])\n",
    "\n",
    "scale_df = pd.concat([scale_df, \n",
    "               pd.DataFrame(codes, columns = feature_names).astype(int)], axis=1)\n",
    "##########################################\n",
    "ohe_ligue = OneHotEncoder()\n",
    "to_ohe_ligue = scale_df.loc[:,[\"league_id\"]]\n",
    "ohe_ligue.fit(to_ohe_ligue)\n",
    "\n",
    "codes = ohe_ligue.transform(to_ohe_ligue).toarray()\n",
    "feature_names = ohe_ligue.get_feature_names(['league_id'])\n",
    "\n",
    "scale_df = pd.concat([scale_df, \n",
    "               pd.DataFrame(codes, columns = feature_names).astype(int)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e47c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, save_name):\n",
    "        \"\"\"\n",
    "        Saves obj to a pickle file in directory path.\n",
    "        \"\"\" \n",
    "        with open(os.path.join(f\"{save_name}.pkl\"), 'wb') as f:\n",
    "            pkl.dump(obj, f)\n",
    "\n",
    "def load_data_prep_object(obj_name):\n",
    "    \"\"\"\n",
    "    Loads and returns the specified data prep object from the data_prep_objects_path.\n",
    "    \"\"\"\n",
    "        # check if file exists\n",
    "    if not os.path.isfile(os.path.join(f\"{obj_name}.pkl\")):\n",
    "        raise ValueError(f\"Data prep object file '{obj_name}.pkl' does not exist.\")\n",
    "    else:\n",
    "        with open(os.path.join(f\"{obj_name}.pkl\"), 'rb') as f:\n",
    "            obj = pkl.load(f)\n",
    "            return obj\n",
    "            \n",
    "def do_pca(df, perc_var, col_name1 = \"shooting_standard_gls\", col_name2 = 'misc_aerialduels_won_perc'):\n",
    "    try:\n",
    "        pcs_matchstat = load_data_prep_object(\"./pca_matchstats\")\n",
    "    except:\n",
    "        x = df.loc[:,col_name1:col_name2].fillna(0)\n",
    "        pca_matchstat = PCA(n_components = perc_var)\n",
    "        pcs_matchstat = pca_matchstat.fit_transform(x)\n",
    "        save_object(pcs_matchstat, \"pca_matchstats\")\n",
    "    principal_ms_df = pd.DataFrame(data = pcs_matchstat, columns = [f\"feature_{p}\" for p in range(pcs_matchstat.shape[1])])\n",
    "    num_pcs = principal_ms_df.shape[1]\n",
    "    print(num_pcs)\n",
    "    columns_to_overwrite = list(df.loc[:, col_name1:col_name2].columns)\n",
    "    df = df.drop(labels = columns_to_overwrite, axis = \"columns\")\n",
    "    new_cols = columns_to_overwrite[:num_pcs-1] + columns_to_overwrite[-1:]\n",
    "    print(len(new_cols))\n",
    "    df.loc[:, new_cols] = principal_ms_df.values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62f1612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "scale_df_pca = do_pca(scale_df, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be580d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs = club_dict(scale_df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192619ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = new_data_test.return_dicts(\"result\")\n",
    "clubs = points_and_co(clubs, result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5200d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs = points_and_co_oppon(clubs, result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d2d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_train, game_valid = game_dict(scale_df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b5e107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['result',\n",
       " 'gf',\n",
       " 'ga',\n",
       " 'goal_diff',\n",
       " 'xg',\n",
       " 'xga',\n",
       " 'shooting_standard_gls',\n",
       " 'shooting_standard_sh',\n",
       " 'shooting_standard_sot',\n",
       " 'shooting_standard_sot_perc',\n",
       " 'shooting_standard_g_per_sh',\n",
       " 'shooting_standard_g_per_sot',\n",
       " 'shooting_standard_dist',\n",
       " 'shooting_standard_fk',\n",
       " 'shooting_standard_pk',\n",
       " 'shooting_standard_pkatt',\n",
       " 'shooting_expected_npxg',\n",
       " 'shooting_expected_npxg_per_sh',\n",
       " 'shooting_expected_g_minus_xg',\n",
       " 'shooting_expected_npg_minus_xg',\n",
       " 'keeper_performance_sota',\n",
       " 'keeper_performance_saves',\n",
       " 'keeper_performance_save_perc',\n",
       " 'keeper_performance_cs',\n",
       " 'keeper_performance_psxg',\n",
       " 'keeper_performance_psxg_plus_minus',\n",
       " 'keeper_penaltykicks_pkatt',\n",
       " 'keeper_penaltykicks_pka',\n",
       " 'keeper_penaltykicks_pksv',\n",
       " 'keeper_penaltykicks_pkm',\n",
       " 'keeper_launched_cmp',\n",
       " 'keeper_launched_att',\n",
       " 'keeper_launched_cmp_perc',\n",
       " 'keeper_passes_att',\n",
       " 'keeper_passes_thr',\n",
       " 'keeper_passes_launch_perc',\n",
       " 'keeper_passes_avglen',\n",
       " 'keeper_goalkicks_att',\n",
       " 'keeper_goalkicks_launch_perc',\n",
       " 'keeper_goalkicks_avglen',\n",
       " 'keeper_crosses_opp',\n",
       " 'keeper_crosses_stp',\n",
       " 'keeper_crosses_stp_perc',\n",
       " 'keeper_sweeper_number_opa',\n",
       " 'keeper_sweeper_avgdist',\n",
       " 'passing_total_cmp',\n",
       " 'passing_total_att',\n",
       " 'passing_total_cmp_perc',\n",
       " 'passing_total_totdist',\n",
       " 'passing_total_prgdist',\n",
       " 'passing_short_cmp',\n",
       " 'passing_short_att',\n",
       " 'passing_short_cmp_perc',\n",
       " 'passing_medium_cmp',\n",
       " 'passing_medium_att',\n",
       " 'passing_medium_cmp_perc',\n",
       " 'passing_long_cmp',\n",
       " 'passing_long_att',\n",
       " 'passing_long_cmp_perc',\n",
       " 'passing_attacking_ast',\n",
       " 'passing_attacking_xag',\n",
       " 'passing_attacking_xa',\n",
       " 'passing_attacking_kp',\n",
       " 'passing_attacking_1_per_3',\n",
       " 'passing_attacking_ppa',\n",
       " 'passing_attacking_crspa',\n",
       " 'passing_attacking_prgp',\n",
       " 'passing_types_passtypes_live',\n",
       " 'passing_types_passtypes_dead',\n",
       " 'passing_types_passtypes_fk',\n",
       " 'passing_types_passtypes_tb',\n",
       " 'misc_aerialduels_won_perc',\n",
       " 'attendance',\n",
       " 'points',\n",
       " 'mean_points',\n",
       " 'weekly_wages_eur',\n",
       " 'season_str',\n",
       " 'league_id',\n",
       " 'venue',\n",
       " 'stad_capac',\n",
       " 'team_id_1',\n",
       " 'team_id_2',\n",
       " 'team_id_3',\n",
       " 'team_id_4',\n",
       " 'team_id_5',\n",
       " 'team_id_6',\n",
       " 'team_id_7',\n",
       " 'team_id_8',\n",
       " 'team_id_9',\n",
       " 'team_id_10',\n",
       " 'team_id_11',\n",
       " 'team_id_12',\n",
       " 'team_id_13',\n",
       " 'team_id_14',\n",
       " 'team_id_15',\n",
       " 'team_id_16',\n",
       " 'team_id_17',\n",
       " 'team_id_18',\n",
       " 'team_id_19',\n",
       " 'team_id_20',\n",
       " 'team_id_21',\n",
       " 'team_id_22',\n",
       " 'team_id_23',\n",
       " 'team_id_24',\n",
       " 'team_id_25',\n",
       " 'team_id_26',\n",
       " 'team_id_27',\n",
       " 'team_id_28',\n",
       " 'team_id_29',\n",
       " 'team_id_30',\n",
       " 'team_id_31',\n",
       " 'team_id_32',\n",
       " 'team_id_33',\n",
       " 'team_id_34',\n",
       " 'team_id_35',\n",
       " 'team_id_36',\n",
       " 'team_id_37',\n",
       " 'team_id_38',\n",
       " 'team_id_39',\n",
       " 'team_id_40',\n",
       " 'team_id_41',\n",
       " 'team_id_42',\n",
       " 'team_id_43',\n",
       " 'team_id_44',\n",
       " 'team_id_45',\n",
       " 'team_id_46',\n",
       " 'team_id_47',\n",
       " 'team_id_48',\n",
       " 'team_id_49',\n",
       " 'team_id_50',\n",
       " 'team_id_51',\n",
       " 'team_id_52',\n",
       " 'team_id_53',\n",
       " 'team_id_54',\n",
       " 'team_id_55',\n",
       " 'team_id_56',\n",
       " 'team_id_57',\n",
       " 'team_id_58',\n",
       " 'team_id_59',\n",
       " 'team_id_60',\n",
       " 'team_id_61',\n",
       " 'team_id_62',\n",
       " 'team_id_63',\n",
       " 'team_id_64',\n",
       " 'team_id_65',\n",
       " 'team_id_66',\n",
       " 'team_id_67',\n",
       " 'team_id_68',\n",
       " 'team_id_69',\n",
       " 'team_id_70',\n",
       " 'team_id_71',\n",
       " 'team_id_72',\n",
       " 'team_id_73',\n",
       " 'team_id_74',\n",
       " 'team_id_75',\n",
       " 'team_id_76',\n",
       " 'team_id_77',\n",
       " 'team_id_78',\n",
       " 'team_id_79',\n",
       " 'team_id_80',\n",
       " 'team_id_81',\n",
       " 'team_id_82',\n",
       " 'team_id_83',\n",
       " 'team_id_84',\n",
       " 'team_id_85',\n",
       " 'team_id_86',\n",
       " 'team_id_87',\n",
       " 'team_id_88',\n",
       " 'team_id_89',\n",
       " 'team_id_90',\n",
       " 'team_id_91',\n",
       " 'team_id_92',\n",
       " 'team_id_93',\n",
       " 'team_id_94',\n",
       " 'team_id_95',\n",
       " 'team_id_96',\n",
       " 'team_id_97',\n",
       " 'team_id_98',\n",
       " 'team_id_99',\n",
       " 'team_id_100',\n",
       " 'team_id_101',\n",
       " 'team_id_102',\n",
       " 'team_id_103',\n",
       " 'team_id_104',\n",
       " 'team_id_105',\n",
       " 'team_id_106',\n",
       " 'team_id_107',\n",
       " 'team_id_108',\n",
       " 'team_id_109',\n",
       " 'team_id_110',\n",
       " 'team_id_111',\n",
       " 'team_id_112',\n",
       " 'team_id_113',\n",
       " 'team_id_114',\n",
       " 'team_id_115',\n",
       " 'team_id_116',\n",
       " 'team_id_117',\n",
       " 'team_id_118',\n",
       " 'team_id_119',\n",
       " 'team_id_120',\n",
       " 'team_id_121',\n",
       " 'team_id_122',\n",
       " 'team_id_123',\n",
       " 'team_id_124',\n",
       " 'team_id_125',\n",
       " 'team_id_127',\n",
       " 'team_id_128',\n",
       " 'team_id_129',\n",
       " 'team_id_130',\n",
       " 'team_id_131',\n",
       " 'team_id_133',\n",
       " 'team_id_134',\n",
       " 'team_id_135',\n",
       " 'team_id_136',\n",
       " 'team_id_137',\n",
       " 'team_id_138',\n",
       " 'team_id_139',\n",
       " 'team_id_140',\n",
       " 'team_id_141',\n",
       " 'team_id_142',\n",
       " 'team_id_143',\n",
       " 'opponent_id_1',\n",
       " 'opponent_id_2',\n",
       " 'opponent_id_3',\n",
       " 'opponent_id_4',\n",
       " 'opponent_id_5',\n",
       " 'opponent_id_6',\n",
       " 'opponent_id_7',\n",
       " 'opponent_id_8',\n",
       " 'opponent_id_9',\n",
       " 'opponent_id_10',\n",
       " 'opponent_id_11',\n",
       " 'opponent_id_12',\n",
       " 'opponent_id_13',\n",
       " 'opponent_id_14',\n",
       " 'opponent_id_15',\n",
       " 'opponent_id_16',\n",
       " 'opponent_id_17',\n",
       " 'opponent_id_18',\n",
       " 'opponent_id_19',\n",
       " 'opponent_id_20',\n",
       " 'opponent_id_21',\n",
       " 'opponent_id_22',\n",
       " 'opponent_id_23',\n",
       " 'opponent_id_24',\n",
       " 'opponent_id_25',\n",
       " 'opponent_id_26',\n",
       " 'opponent_id_27',\n",
       " 'opponent_id_28',\n",
       " 'opponent_id_29',\n",
       " 'opponent_id_30',\n",
       " 'opponent_id_31',\n",
       " 'opponent_id_32',\n",
       " 'opponent_id_33',\n",
       " 'opponent_id_34',\n",
       " 'opponent_id_35',\n",
       " 'opponent_id_36',\n",
       " 'opponent_id_37',\n",
       " 'opponent_id_38',\n",
       " 'opponent_id_39',\n",
       " 'opponent_id_40',\n",
       " 'opponent_id_41',\n",
       " 'opponent_id_42',\n",
       " 'opponent_id_43',\n",
       " 'opponent_id_44',\n",
       " 'opponent_id_45',\n",
       " 'opponent_id_46',\n",
       " 'opponent_id_47',\n",
       " 'opponent_id_48',\n",
       " 'opponent_id_49',\n",
       " 'opponent_id_50',\n",
       " 'opponent_id_51',\n",
       " 'opponent_id_52',\n",
       " 'opponent_id_53',\n",
       " 'opponent_id_54',\n",
       " 'opponent_id_55',\n",
       " 'opponent_id_56',\n",
       " 'opponent_id_57',\n",
       " 'opponent_id_58',\n",
       " 'opponent_id_59',\n",
       " 'opponent_id_60',\n",
       " 'opponent_id_61',\n",
       " 'opponent_id_62',\n",
       " 'opponent_id_63',\n",
       " 'opponent_id_64',\n",
       " 'opponent_id_65',\n",
       " 'opponent_id_66',\n",
       " 'opponent_id_67',\n",
       " 'opponent_id_68',\n",
       " 'opponent_id_69',\n",
       " 'opponent_id_70',\n",
       " 'opponent_id_71',\n",
       " 'opponent_id_72',\n",
       " 'opponent_id_73',\n",
       " 'opponent_id_74',\n",
       " 'opponent_id_75',\n",
       " 'opponent_id_76',\n",
       " 'opponent_id_77',\n",
       " 'opponent_id_78',\n",
       " 'opponent_id_79',\n",
       " 'opponent_id_80',\n",
       " 'opponent_id_81',\n",
       " 'opponent_id_82',\n",
       " 'opponent_id_83',\n",
       " 'opponent_id_84',\n",
       " 'opponent_id_85',\n",
       " 'opponent_id_86',\n",
       " 'opponent_id_87',\n",
       " 'opponent_id_88',\n",
       " 'opponent_id_89',\n",
       " 'opponent_id_90',\n",
       " 'opponent_id_91',\n",
       " 'opponent_id_92',\n",
       " 'opponent_id_93',\n",
       " 'opponent_id_94',\n",
       " 'opponent_id_95',\n",
       " 'opponent_id_96',\n",
       " 'opponent_id_97',\n",
       " 'opponent_id_98',\n",
       " 'opponent_id_99',\n",
       " 'opponent_id_100',\n",
       " 'opponent_id_101',\n",
       " 'opponent_id_102',\n",
       " 'opponent_id_103',\n",
       " 'opponent_id_104',\n",
       " 'opponent_id_105',\n",
       " 'opponent_id_106',\n",
       " 'opponent_id_107',\n",
       " 'opponent_id_108',\n",
       " 'opponent_id_109',\n",
       " 'opponent_id_110',\n",
       " 'opponent_id_111',\n",
       " 'opponent_id_112',\n",
       " 'opponent_id_113',\n",
       " 'opponent_id_114',\n",
       " 'opponent_id_115',\n",
       " 'opponent_id_116',\n",
       " 'opponent_id_117',\n",
       " 'opponent_id_118',\n",
       " 'opponent_id_119',\n",
       " 'opponent_id_120',\n",
       " 'opponent_id_121',\n",
       " 'opponent_id_122',\n",
       " 'opponent_id_123',\n",
       " 'opponent_id_124',\n",
       " 'opponent_id_125',\n",
       " 'opponent_id_127',\n",
       " 'opponent_id_128',\n",
       " 'opponent_id_129',\n",
       " 'opponent_id_130',\n",
       " 'opponent_id_131',\n",
       " 'opponent_id_133',\n",
       " 'opponent_id_134',\n",
       " 'opponent_id_135',\n",
       " 'opponent_id_136',\n",
       " 'opponent_id_137',\n",
       " 'opponent_id_138',\n",
       " 'opponent_id_139',\n",
       " 'opponent_id_140',\n",
       " 'opponent_id_141',\n",
       " 'opponent_id_142',\n",
       " 'opponent_id_143',\n",
       " 'league_id_0',\n",
       " 'league_id_1',\n",
       " 'league_id_2',\n",
       " 'league_id_3',\n",
       " 'league_id_4',\n",
       " 'oppon_wages',\n",
       " 'last_results',\n",
       " 'oppon_points',\n",
       " 'oppon_mean_points',\n",
       " 'schedule_round',\n",
       " 'captain',\n",
       " 'formation',\n",
       " 'referee',\n",
       " 'match_id',\n",
       " 'schedule_date',\n",
       " 'schedule_time',\n",
       " 'schedule_day',\n",
       " 'annual_wage_team',\n",
       " 'annual_wage_player_avg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abcdefg = list(scale_df.columns)\n",
    "abc = abcdefg[:abcdefg.index(\"annual_wage_player_avg\")+1]\n",
    "defg = abcdefg[abcdefg.index(\"annual_wage_player_avg\")+1:]\n",
    "\n",
    "rearange_list = ['result', 'gf', 'ga', 'goal_diff', 'xg', 'xga', 'shooting_standard_gls',\n",
    "       'shooting_standard_sh', 'shooting_standard_sot',\n",
    "       'shooting_standard_sot_perc', 'shooting_standard_g_per_sh',\n",
    "       'shooting_standard_g_per_sot', 'shooting_standard_dist',\n",
    "       'shooting_standard_fk', 'shooting_standard_pk',\n",
    "       'shooting_standard_pkatt', 'shooting_expected_npxg',\n",
    "       'shooting_expected_npxg_per_sh', 'shooting_expected_g_minus_xg',\n",
    "       'shooting_expected_npg_minus_xg', 'keeper_performance_sota',\n",
    "       'keeper_performance_saves', 'keeper_performance_save_perc',\n",
    "       'keeper_performance_cs', 'keeper_performance_psxg',\n",
    "       'keeper_performance_psxg_plus_minus', 'keeper_penaltykicks_pkatt',\n",
    "       'keeper_penaltykicks_pka', 'keeper_penaltykicks_pksv',\n",
    "       'keeper_penaltykicks_pkm', 'keeper_launched_cmp', 'keeper_launched_att',\n",
    "       'keeper_launched_cmp_perc', 'keeper_passes_att', 'keeper_passes_thr',\n",
    "       'keeper_passes_launch_perc', 'keeper_passes_avglen',\n",
    "       'keeper_goalkicks_att', 'keeper_goalkicks_launch_perc',\n",
    "       'keeper_goalkicks_avglen', 'keeper_crosses_opp', 'keeper_crosses_stp',\n",
    "       'keeper_crosses_stp_perc', 'keeper_sweeper_number_opa',\n",
    "       'keeper_sweeper_avgdist', 'passing_total_cmp', 'passing_total_att',\n",
    "       'passing_total_cmp_perc', 'passing_total_totdist',\n",
    "       'passing_total_prgdist', 'passing_short_cmp', 'passing_short_att',\n",
    "       'passing_short_cmp_perc', 'passing_medium_cmp', 'passing_medium_att',\n",
    "       'passing_medium_cmp_perc', 'passing_long_cmp', 'passing_long_att',\n",
    "       'passing_long_cmp_perc', 'passing_attacking_ast',\n",
    "       'passing_attacking_xag', 'passing_attacking_xa', 'passing_attacking_kp',\n",
    "       'passing_attacking_1_per_3', 'passing_attacking_ppa',\n",
    "       'passing_attacking_crspa', 'passing_attacking_prgp',\n",
    "       'passing_types_passtypes_live', 'passing_types_passtypes_dead',\n",
    "       'passing_types_passtypes_fk', 'passing_types_passtypes_tb',\n",
    "       'misc_aerialduels_won_perc','attendance', 'points', 'mean_points',\n",
    "       'weekly_wages_eur', 'season_str',  'league_id', 'venue', 'team_id', 'oppon_wages',\n",
    "       'opponent_id', 'last_results', 'oppon_points', 'oppon_mean_points', 'schedule_round',\n",
    "        'captain', 'formation', 'referee',  'match_id', 'schedule_date', 'schedule_time',\n",
    "        'schedule_day', 'annual_wage_team', 'annual_wage_player_avg',]\n",
    "\n",
    "rearange_list = list(itertools.chain.from_iterable(defg if item == \"team_id\" else [item] for item in rearange_list))\n",
    "\n",
    "del rearange_list[rearange_list.index(\"opponent_id\")]\n",
    "rearange_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dba078bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "train_inputs = inputs_2seas(game_train, clubs, rearange_list, scale_df_pca)\n",
    "valid_inputs = inputs_2seas(game_valid, clubs, rearange_list, scale_df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af16a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_loader = data_to_lstm(train_inputs)\n",
    "valid_for_loader = data_to_lstm(valid_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d677f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_for_loader, batch_size = 32, drop_last = True)\n",
    "test_loader = torch.utils.data.DataLoader(valid_for_loader, batch_size = 32, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00842cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss accuracy training: 37.362637362637365%\n",
      "Epoch: 0\n",
      "Loss 38.20027278363705 accuracy 46.35989010989011%\n",
      "Epoch: 1\n",
      "Loss 38.656844317913055 accuracy 46.46291208791209%\n",
      "Epoch: 2\n",
      "Loss 40.29108799248934 accuracy 47.25274725274725%\n",
      "Epoch: 3\n",
      "Loss 49.67716025561094 accuracy 45.32967032967033%\n",
      "Epoch: 4\n",
      "Loss 58.64155311882496 accuracy 44.36813186813187%\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "len_input = train_inputs[0][0].shape[1]\n",
    "lr = 2e-5\n",
    "#wdc = [0.2, 0.15, 0.1, 0.05, 0]\n",
    "#lrs = [1e-3, 1e-4, 1e-5, 1e-6]\n",
    "#for lr in lrs:\n",
    "#for wd in wdc:\n",
    "net = Sport_pred_2LSTM_1(len_input, len_input, 3, 3)\n",
    "#print(f\"\\n\\nLR: {lr}, WD: {wd}\")\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = lr)#, weight_decay = 0.01)\n",
    "\n",
    "net.eval()\n",
    "accur = 0\n",
    "for step, ((input1, input2), (result1, result2)) in enumerate(test_loader):\n",
    "    pred = net(input1)\n",
    "    #print(pred.shape)\n",
    "    #print(result1.shape)\n",
    "    pred = torch.argmax(pred[:,-1,:], dim = 1)\n",
    "    result = result1[:,-1,:]\n",
    "    result = torch.argmax(result, dim = 1)\n",
    "    accur += pred.eq(result).sum().item()\n",
    "\n",
    "    pred = net(input2)\n",
    "    pred = torch.argmax(pred[:,-1,:], dim = 1)\n",
    "    result2 = result2[:,-1,:]\n",
    "    result2 = torch.argmax(result2, dim = 1)\n",
    "    accur += pred.eq(result2).sum().item()\n",
    "print(f\"Loss accuracy training: {100 * accur /((step + 1) * 64)}%\")\n",
    "\n",
    "for epoch in range(5):\n",
    "    losses_val = []\n",
    "    accuracies = []\n",
    "\n",
    "    net.train()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for step, ((input1, input2), (result1, result2)) in enumerate(train_loader):\n",
    "        net.zero_grad()\n",
    "        pred = net(input1)\n",
    "        #result = torch.nn.functional.one_hot(result.to(torch.int64), num_classes = 3).to(torch.float32)\n",
    "        #print(f\"pred {pred.dtype}, result {result.dtype}\")\n",
    "        #result1 = result1[:,-1,:]\n",
    "        loss = criterion(pred.float(), result1.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        net.zero_grad()\n",
    "        pred = net(input2)\n",
    "        #result2 = result2[:,-1,:]\n",
    "        #result = torch.nn.functional.one_hot(result.to(torch.int64), num_classes = 3).to(torch.float32)\n",
    "        #print(f\"pred {pred.dtype}, result {result.dtype}\")\n",
    "        loss = criterion(pred.float(), result2.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    accur = 0\n",
    "    for step, ((input1, input2), (result1, result2)) in enumerate(test_loader):\n",
    "        pred = net(input1)\n",
    "        #print(pred)\n",
    "        #print(pred.shape)\n",
    "        result1 = result1[:,-1,:]\n",
    "        pred = pred[:,-1,:]\n",
    "        loss += criterion(pred, result1).item()\n",
    "        #\n",
    "        #print(pred)\n",
    "        #print(pred.shape)\n",
    "        pred = torch.argmax(pred, dim = 1)\n",
    "        #print(pred)\n",
    "        #print(pred.shape)\n",
    "\n",
    "        result1 = torch.argmax(result1, dim = 1)\n",
    "        accur += pred.eq(result1).sum().item()\n",
    "       # if epoch == 9:\n",
    "        #    print(\"pred\", pred)\n",
    "         #   print(\"result\", result1)\n",
    "        pred = net(input2)\n",
    "        result2 = result2[:,-1,:]\n",
    "        pred = pred[:,-1,:]\n",
    "        loss += criterion(pred, result2).item()\n",
    "        #pred = pred[:,-1,:]\n",
    "        pred = torch.argmax(pred, dim = 1)\n",
    "        result2  = torch.argmax(result2, dim = 1)\n",
    "        accur += pred.eq(result2).sum().item()\n",
    "    losses_val.append(loss)\n",
    "    accuracy = 100 * (accur /((step + 1) * 64))\n",
    "    os.makedirs(os.path.dirname(f\"./models/sequence_model_pca_2seas/LSTM/{lr}/accur_{round(accuracy, 2)}\"), exist_ok = True)\n",
    "    torch.save(net.state_dict(), f\"./models/sequence_model_pca_2seas/LSTM/{lr}/accur_{round(accuracy, 2)}\")\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Loss {loss} accuracy {accuracy}%\") \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dde5361b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss accuracy training: 30.563186813186814%\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m#result2 = change_result(result2)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred\u001b[38;5;241m.\u001b[39mfloat(), result2\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len_input = train_inputs[0][0].shape[1]\n",
    "lr = 2e-5\n",
    "#wdc = [0.2, 0.15, 0.1, 0.05, 0]\n",
    "#lrs = [1e-3, 1e-4, 1e-5, 1e-6]\n",
    "#for lr in lrs:\n",
    "#for wd in wdc:\n",
    "net = Sport_pred_2LSTM_1(len_input, len_input, 3, 3)\n",
    "#print(f\"\\n\\nLR: {lr}, WD: {wd}\")\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 2e-5)#, weight_decay = 0.01)\n",
    "\n",
    "net.eval()\n",
    "accur = 0\n",
    "for step, ((input1, input2), (result1, result2)) in enumerate(test_loader):\n",
    "    pred1 = net(input1)\n",
    "    pred2 = net(input2)\n",
    "    #pred1_n = change_back(pred1)\n",
    "    #pred2_n = change_back(pred2)\n",
    "    result = result1[:,-1,:]\n",
    "    result = torch.argmax(result, dim = 1)\n",
    "    predicted = predict(pred1, pred2, result_dict)\n",
    "    accur += predicted.eq(result).sum().item()\n",
    "print(f\"Loss accuracy training: {100 * accur /((step + 1) * 32)}%\")\n",
    "\n",
    "for epoch in range(3):\n",
    "    losses_val = []\n",
    "    accuracies = []\n",
    "\n",
    "    net.train()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for step, ((input1, input2), (result1, result2)) in enumerate(train_loader):\n",
    "        net.zero_grad()\n",
    "        pred = net(input1)\n",
    "        #result1 = change_result(result1)\n",
    "        loss = criterion(pred.float(), result1.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        net.zero_grad()\n",
    "        pred = net(input2)\n",
    "        #result2 = change_result(result2)\n",
    "        loss = criterion(pred.float(), result2.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    accur = 0\n",
    "    for step, ((input1, input2), (result1, result2)) in enumerate(test_loader):\n",
    "        pred1 = net(input1)\n",
    "        pred2 = net(input2)\n",
    "        result = result1[:,-1,:]\n",
    "        #pred1_n = change_back(pred1)\n",
    "        #pred2_n = change_back(pred2)\n",
    "        result = torch.argmax(result, dim = 1)\n",
    "        predicted = predict(pred1, pred2, result_dict)\n",
    "        #test = pred1.clone()\n",
    "        #test[pred1 > 0.5] = 0\n",
    "        #predicted = torch.argmax(test, dim = 1)\n",
    "        accur += predicted.eq(result).sum().item()\n",
    "    losses_val.append(loss)\n",
    "    accuracy = 100 * (accur /((step + 1) * 32))\n",
    "    os.makedirs(os.path.dirname(f\"./models/sequence_model_pca_2seas/{lr}/LSTM/accur_{round(accuracy, 2)}\"), exist_ok = True)\n",
    "    torch.save(net.state_dict(), f\"./models/sequence_model_pca_2seas/{lr}/LSTM/accur_{round(accuracy, 2)}\")\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Loss {loss} accuracy {accuracy}%\") \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcfbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tensor1, tensor2, result_dict):\n",
    "    # tensor with results\n",
    "    tens1 = tensor1[:,-1,:]\n",
    "    tens2 = tensor2[:,-1,:]\n",
    "    \n",
    "    sum1 = torch.sum(tens1, dim = 1)\n",
    "    sum2 = torch.sum(tens2, dim = 1)\n",
    "    sum1_reshaped = sum1.unsqueeze(1).expand_as(tens1)\n",
    "    sum2_reshaped = sum2.unsqueeze(1).expand_as(tens2)\n",
    "    output1 = tens1 / sum1_reshaped\n",
    "    output2 = tens2 / sum1_reshaped\n",
    "    \n",
    "    vals1, idx1 = torch.max(output1, dim = 1)\n",
    "    vals2, idx2 = torch.max(output2, dim = 1)\n",
    "    #high_val1 = torch.max(output1, dim = 1)\n",
    "    #high_val2 = torch.argmax(output2, dim = 1)\n",
    "    #print(high_val1.shape)\n",
    "    small_val1,_ = torch.topk(output1, k = 2, dim = 1, largest = False)\n",
    "    small_val2,_ = torch.topk(output2, k = 2, dim = 1, largest = False)\n",
    "    \n",
    "    diff1 = torch.sum(torch.square(vals1.unsqueeze(1).expand_as(small_val1) - small_val1), dim = 1)\n",
    "    diff2 = torch.sum(torch.square(vals2.unsqueeze(1).expand_as(small_val2) - small_val2), dim = 1) \n",
    "    \n",
    "    result = torch.where(diff1 > diff2, idx1, torch.where(abs(diff1 - diff2) < 0.02, result_dict[\"D\"], result_dict[\"L\"]))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdeecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_replace(tensor):\n",
    "    # we create a copy of the original tensor, \n",
    "    # because of the way we are replacing them.\n",
    "    res = tensor.clone()\n",
    "    res[tensor == 0] = 1\n",
    "    res[tensor == 1] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simil_metric(tens1):\n",
    "    count = torch.abs(tens1.unsqueeze(1) - tens1.unsqueeze(2))\n",
    "    div, _ = torch.max(tens1, dim = 1)\n",
    "    res = 1 - (count/div)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0632cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pred1.clone()\n",
    "test[pred1 > 0.5] = 0\n",
    "test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(tensor):\n",
    "    x = tensor[:, 0]\n",
    "    y = tensor[:, 1]\n",
    "    z = tensor[:, 2]\n",
    "\n",
    "    absolute_diff_12 = torch.abs(x - y)\n",
    "    absolute_diff_13 = torch.abs(x - z)\n",
    "\n",
    "    max_value_12 = torch.max(x, y)\n",
    "    max_value_13 = torch.max(x, z)\n",
    "\n",
    "    distance = torch.stack([absolute_diff_12 / max_value_12, absolute_diff_13 / max_value_13], dim=1)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bef4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(compute_distance(pred1), dim =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e030a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Softmax(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23007a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = result1[:,-1,:]\n",
    "torch.where(result1[:,:2].sum() == 1, 1,  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6aef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_result(tensor):\n",
    "    result = tensor.float()\n",
    "    is_last_column_one = result[:,:,-1] == 1\n",
    "    result[is_last_column_one] = 0.5\n",
    "    result = result[:,:,:2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = result1.float()\n",
    "is_last_column_one = result1[:,:,-1] == 1\n",
    "result1[is_last_column_one] = 0.5 #torch.full((308, 3), 0.5)\n",
    "result1[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a845fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1[0,0,0] = 1\n",
    "result1[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5673273",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result1[is_last_column_one]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabce919",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_result(result1)[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a61df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_back(tensor):\n",
    "    tensor = tensor[:,-1,:]\n",
    "    new = torch.zeros(len(tensor))\n",
    "    col1 = tensor[:,0]\n",
    "    col2 = tensor[:,1]\n",
    "    col1 = torch.where(col1 > 0.6, 1., 0.)\n",
    "    col2 = torch.where(col2 > 0.6, 1., 0.)\n",
    "    new = torch.where(new == col1 + col2, 1., 0.)\n",
    "    out = torch.stack((col1, col2, new), dim = -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b73bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "change_back(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c128ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a717cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = pred1[:,-1,:]\n",
    "col1 = tensor[:,0]\n",
    "col2 = tensor[:,1]\n",
    "col1\n",
    "torch.where(col2 > 0.7, 1., 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
