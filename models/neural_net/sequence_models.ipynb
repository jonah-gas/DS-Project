{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35bc8322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/paul/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <8080486D-E510-3000-AA6A-F3AD49ACC172> /Users/paul/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <EB47298B-CC51-3FA7-885A-620F458D20C5> /Users/paul/opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision as T\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5b7c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>schedule_round</th>\n",
       "      <th>schedule_day</th>\n",
       "      <th>result_home</th>\n",
       "      <th>gf_home</th>\n",
       "      <th>gf_away</th>\n",
       "      <th>xg_home</th>\n",
       "      <th>xg_away</th>\n",
       "      <th>attendance</th>\n",
       "      <th>captain_home</th>\n",
       "      <th>...</th>\n",
       "      <th>misc_performance_crdr_away</th>\n",
       "      <th>misc_performance_2crdy_away</th>\n",
       "      <th>misc_performance_fls_away</th>\n",
       "      <th>misc_performance_fld_away</th>\n",
       "      <th>misc_performance_off_away</th>\n",
       "      <th>misc_performance_og_away</th>\n",
       "      <th>misc_performance_recov_away</th>\n",
       "      <th>misc_aerialduels_won_away</th>\n",
       "      <th>misc_aerialduels_lost_away</th>\n",
       "      <th>misc_aerialduels_won_perc_away</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>18:00</td>\n",
       "      <td>Matchweek 1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>39226.0</td>\n",
       "      <td>Gianluigi Buffon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>18:00</td>\n",
       "      <td>Matchweek 3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>39457.0</td>\n",
       "      <td>Stephan Lichtsteiner</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>20:45</td>\n",
       "      <td>Matchweek 5</td>\n",
       "      <td>Wed</td>\n",
       "      <td>W</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>35652.0</td>\n",
       "      <td>Andrea Barzagli</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-23</th>\n",
       "      <td>20:45</td>\n",
       "      <td>Matchweek 6</td>\n",
       "      <td>Sat</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40856.0</td>\n",
       "      <td>Gianluigi Buffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-14</th>\n",
       "      <td>18:00</td>\n",
       "      <td>Matchweek 8</td>\n",
       "      <td>Sat</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>39145.0</td>\n",
       "      <td>Gianluigi Buffon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              schedule_time schedule_round schedule_day result_home  gf_home  \\\n",
       "schedule_date                                                                  \n",
       "2017-08-19            18:00    Matchweek 1          Sat           W      3.0   \n",
       "2017-09-09            18:00    Matchweek 3          Sat           W      3.0   \n",
       "2017-09-20            20:45    Matchweek 5          Wed           W      1.0   \n",
       "2017-09-23            20:45    Matchweek 6          Sat           W      4.0   \n",
       "2017-10-14            18:00    Matchweek 8          Sat           L      1.0   \n",
       "\n",
       "               gf_away  xg_home  xg_away  attendance          captain_home  \\\n",
       "schedule_date                                                                \n",
       "2017-08-19         0.0      1.1      1.4     39226.0      Gianluigi Buffon   \n",
       "2017-09-09         0.0      1.3      0.6     39457.0  Stephan Lichtsteiner   \n",
       "2017-09-20         0.0      0.9      0.4     35652.0       Andrea Barzagli   \n",
       "2017-09-23         0.0      2.2      0.2     40856.0      Gianluigi Buffon   \n",
       "2017-10-14         2.0      2.3      1.6     39145.0      Gianluigi Buffon   \n",
       "\n",
       "               ... misc_performance_crdr_away misc_performance_2crdy_away  \\\n",
       "schedule_date  ...                                                          \n",
       "2017-08-19     ...                        0.0                         0.0   \n",
       "2017-09-09     ...                        0.0                         0.0   \n",
       "2017-09-20     ...                        1.0                         1.0   \n",
       "2017-09-23     ...                        1.0                         1.0   \n",
       "2017-10-14     ...                        0.0                         0.0   \n",
       "\n",
       "              misc_performance_fls_away  misc_performance_fld_away  \\\n",
       "schedule_date                                                        \n",
       "2017-08-19                         11.0                       13.0   \n",
       "2017-09-09                          7.0                       15.0   \n",
       "2017-09-20                         23.0                       10.0   \n",
       "2017-09-23                         12.0                       16.0   \n",
       "2017-10-14                         14.0                        8.0   \n",
       "\n",
       "              misc_performance_off_away misc_performance_og_away  \\\n",
       "schedule_date                                                      \n",
       "2017-08-19                          0.0                      0.0   \n",
       "2017-09-09                          1.0                      1.0   \n",
       "2017-09-20                          1.0                      0.0   \n",
       "2017-09-23                          1.0                      0.0   \n",
       "2017-10-14                          1.0                      0.0   \n",
       "\n",
       "              misc_performance_recov_away  misc_aerialduels_won_away  \\\n",
       "schedule_date                                                          \n",
       "2017-08-19                           40.0                        9.0   \n",
       "2017-09-09                           34.0                       10.0   \n",
       "2017-09-20                           46.0                        8.0   \n",
       "2017-09-23                           41.0                        6.0   \n",
       "2017-10-14                           47.0                       14.0   \n",
       "\n",
       "               misc_aerialduels_lost_away  misc_aerialduels_won_perc_away  \n",
       "schedule_date                                                              \n",
       "2017-08-19                            8.0                            52.9  \n",
       "2017-09-09                           10.0                            50.0  \n",
       "2017-09-20                            9.0                            47.1  \n",
       "2017-09-23                           11.0                            35.3  \n",
       "2017-10-14                           12.0                            53.8  \n",
       "\n",
       "[5 rows x 295 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/paul/Downloads/data_match_clean(1).csv\", delimiter = \";\", index_col = 1)\n",
    "data = data.drop([\"Unnamed: 0\"], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26fb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess():\n",
    "    \n",
    "    def __init__(self, data_frame):\n",
    "        self.data_frame = data_frame\n",
    "        \n",
    "        self.day_dict = {}\n",
    "        i = 0\n",
    "        for day in self.data_frame.schedule_day.unique():\n",
    "            self.day_dict[day] = i\n",
    "            i += 1\n",
    "        \n",
    "        self.result = {}\n",
    "        i = 0\n",
    "        for res in self.data_frame.result_home.unique():\n",
    "            self.result[res] = i\n",
    "            i += 1\n",
    "        #print(self.result)\n",
    "        \n",
    "        self.capt = {}\n",
    "        i = 0\n",
    "        for cap in set(list(self.data_frame.captain_home) + list(self.data_frame.captain_away)):\n",
    "            self.capt[cap] = i\n",
    "            i += 1\n",
    "            \n",
    "        self.formation = {}\n",
    "        i = 0\n",
    "        for form in self.data_frame.formation_home.unique():\n",
    "            self.formation[form] = i\n",
    "            i += 1\n",
    "            \n",
    "        self.referee = {}\n",
    "        i = 0\n",
    "        for ref in self.data_frame.referee.unique():\n",
    "            self.referee[ref] = i\n",
    "            i += 1\n",
    "        \n",
    "        self.teams = {}\n",
    "        i = 0\n",
    "        for team in set(list(self.data_frame.fbref_home_id) + list(self.data_frame.fbref_away_id)):\n",
    "            self.teams[team] = i\n",
    "            i += 1\n",
    "        #print(self.teams)\n",
    "        \n",
    "        self.season = {}\n",
    "        i = 0\n",
    "        for seas in self.data_frame.fbref_season.unique():\n",
    "            self.season[seas] = i\n",
    "            i += 1\n",
    "        \n",
    "        self.time = {}\n",
    "        i = 0\n",
    "        for tim in self.data_frame.schedule_time.unique():\n",
    "            self.time[tim] = i\n",
    "            i += 1\n",
    "            \n",
    "        self.ligue = {}\n",
    "        i = 0\n",
    "        for lig in self.data_frame.fbref_league_id.unique():\n",
    "            self.ligue[lig] = i\n",
    "            i += 1\n",
    "            \n",
    "        self.match = {}\n",
    "        i = 0\n",
    "        for mat in self.data_frame.fbref_match_id.unique():\n",
    "            self.match[mat] = i\n",
    "            i += 1\n",
    "        \n",
    "        self.data_frame.schedule_day.replace(self.day_dict, inplace = True)\n",
    "        self.data_frame.result_home.replace(self.result, inplace = True)\n",
    "        self.data_frame.result_away.replace(self.result, inplace = True)\n",
    "        self.data_frame.captain_home.replace(self.capt, inplace = True)\n",
    "        self.data_frame.captain_away.replace(self.capt, inplace = True)\n",
    "        self.data_frame.formation_home.replace(self.formation, inplace = True)\n",
    "        self.data_frame.formation_away.replace(self.formation, inplace = True)\n",
    "        self.data_frame.referee.replace(self.referee, inplace = True)\n",
    "        self.data_frame.fbref_home_id.replace(self.teams, inplace = True)\n",
    "        self.data_frame.fbref_away_id.replace(self.teams, inplace = True)\n",
    "        self.data_frame.fbref_season.replace(self.season, inplace = True)\n",
    "        self.data_frame.schedule_time.replace(self.time, inplace = True)\n",
    "        self.data_frame.fbref_league_id.replace(self.ligue, inplace = True)\n",
    "        self.data_frame.fbref_match_id.replace(self.match, inplace = True)\n",
    "        \n",
    "        self.features = ['shooting_standard_gls', 'shooting_standard_sh', 'shooting_standard_sot', \n",
    "                         'shooting_standard_sot_perc', 'shooting_standard_g_per_sh', 'shooting_standard_g_per_sot',\n",
    "                         'shooting_standard_dist', 'shooting_standard_fk', 'shooting_standard_pk', \n",
    "                         'shooting_standard_pkatt', 'shooting_expected_npxg', 'shooting_expected_npxg_per_sh',\n",
    "                         'shooting_expected_g_minus_xg', 'shooting_expected_npg_minus_xg', 'keeper_performance_sota',\n",
    "                         'keeper_performance_saves', 'keeper_performance_save_perc', 'keeper_performance_cs',\n",
    "                         'keeper_performance_psxg', 'keeper_performance_psxg_plus_minus', 'keeper_penaltykicks_pkatt', \n",
    "                         'keeper_penaltykicks_pksv', 'keeper_penaltykicks_pkm', 'keeper_launched_cmp', 'keeper_launched_att',\n",
    "                         'keeper_launched_cmp_perc', 'keeper_passes_att', 'keeper_passes_thr', 'keeper_passes_launch_perc',\n",
    "                         'keeper_passes_avglen', 'keeper_goalkicks_att', 'keeper_goalkicks_launch_perc', \n",
    "                         'keeper_goalkicks_avglen', 'keeper_crosses_opp', 'keeper_crosses_stp', 'keeper_crosses_stp_perc',\n",
    "                         'keeper_sweeper_number_opa', 'keeper_sweeper_avgdist', 'passing_total_cmp', 'passing_total_att',\n",
    "                         'passing_total_cmp_perc', 'passing_total_totdist', 'passing_total_prgdist', 'passing_short_cmp',\n",
    "                         'passing_short_att', 'passing_short_cmp_perc', 'passing_medium_cmp', 'passing_medium_att',\n",
    "                         'passing_medium_cmp_perc', 'passing_long_cmp', 'passing_long_att', 'passing_long_cmp_perc',\n",
    "                         'passing_attacking_ast', 'passing_attacking_xag', 'passing_attacking_xa', 'passing_attacking_kp',\n",
    "                         'passing_attacking_1_per_3', 'passing_attacking_ppa', 'passing_attacking_crspa', 'passing_attacking_prgp',\n",
    "                         'passing_types_passtypes_live', 'passing_types_passtypes_dead', 'passing_types_passtypes_fk',\n",
    "                         'passing_types_passtypes_tb', 'passing_types_passtypes_sw', 'passing_types_passtypes_crs',\n",
    "                         'passing_types_passtypes_ti', 'passing_types_passtypes_ck', 'passing_types_cornerkicks_in',\n",
    "                         'passing_types_cornerkicks_out', 'passing_types_cornerkicks_str', 'passing_types_outcomes_off',\n",
    "                         'passing_types_outcomes_blocks', 'gca_scatypes_sca', 'gca_scatypes_passlive', 'gca_scatypes_passdead',\n",
    "                         'gca_scatypes_to', 'gca_scatypes_sh', 'gca_scatypes_fld', 'gca_scatypes_def', 'gca_gcatypes_gca', \n",
    "                         'gca_gcatypes_passlive', 'gca_gcatypes_passdead', 'gca_gcatypes_to', 'gca_gcatypes_sh',\n",
    "                         'gca_gcatypes_fld',  'gca_gcatypes_def', 'defense_tackles_tkl', 'defense_tackles_tklw',\n",
    "                         'defense_tackles_def3rd', 'defense_tackles_mid3rd', 'defense_tackles_att3rd', 'defense_challenges_tkl',\n",
    "                         'defense_challenges_att', 'defense_challenges_tkl_perc', 'defense_challenges_lost', 'defense_blocks_blocks',\n",
    "                         'defense_blocks_sh', 'defense_blocks_pass', 'defense_general_int', 'defense_general_tkl_plus_int',\n",
    "                         'defense_general_clr', 'defense_general_err', 'possession_general_poss', 'possession_touches_touches',\n",
    "                         'possession_touches_defpen', 'possession_touches_def3rd', 'possession_touches_mid3rd',\n",
    "                         'possession_touches_att3rd', 'possession_touches_attpen', 'possession_touches_live', 'possession_takeons_att',\n",
    "                         'possession_takeons_succ', 'possession_takeons_succ_perc', 'possession_takeons_tkld', 'possession_takeons_tkld_perc',\n",
    "                         'possession_carries_carries', 'possession_carries_totdist', 'possession_carries_prgdist',\n",
    "                         'possession_carries_prgc', 'possession_carries_1_per_3', 'possession_carries_cpa', 'possession_carries_mis',\n",
    "                         'possession_carries_dis', 'possession_receiving_rec', 'possession_receiving_prgr',\n",
    "                         'misc_performance_crdy', 'misc_performance_crdr', 'misc_performance_2crdy', 'misc_performance_fls',\n",
    "                         'misc_performance_fld', 'misc_performance_off', 'misc_performance_og', 'misc_performance_recov',\n",
    "                         'misc_aerialduels_won', 'misc_aerialduels_lost', 'misc_aerialduels_won_perc', 'keeper_penaltykicks_pka',\n",
    "                         'attendance']\n",
    "        \n",
    "        \n",
    "        #self.data_frame = data_frame\n",
    "    \n",
    "    def data_frame(self):\n",
    "        return self.data_frame\n",
    "        \n",
    "    def dataset_team(self, team_id):\n",
    "        # split dataset \n",
    "        random_team1 = self.data_frame[self.data_frame.fbref_home_id == team_id].loc[:, self.data_frame.columns.str.endswith('home')]\n",
    "        random_team2 = self.data_frame[self.data_frame.fbref_away_id == team_id].loc[:, self.data_frame.columns.str.endswith('away')]\n",
    "        random_team3 = self.data_frame[(self.data_frame.fbref_home_id == team_id) |\n",
    "                        (self.data_frame.fbref_away_id == team_id)].loc[:,['schedule_time', 'attendance',\n",
    "                                                                           'referee', 'fbref_season',\n",
    "                                                                           'fbref_league_id', 'fbref_home_id',\n",
    "                                                                           'fbref_away_id', 'fbref_match_id']]\n",
    "\n",
    "        #random_team2.rename({\"gf_away\": \"gf_home\", \"gf_home\": \"gf_away\"}, axis = 1, inplace = True)\n",
    "        # preprocess chunks\n",
    "        self.concat_preprocess(random_team1, \"home\")\n",
    "        self.concat_preprocess(random_team2, \"away\")\n",
    "        random_team = pd.concat([random_team1, random_team2])\n",
    "\n",
    "        # dummy to account for home and away\n",
    "        random_team3[\"home\"] = np.where(random_team3.fbref_home_id == team_id, 1, 0)\n",
    "\n",
    "        # rename columns to change them\n",
    "        random_team3_away = random_team3.loc[random_team3.fbref_away_id == team_id].copy()\n",
    "        random_team3_away.rename({\"fbref_home_id\": \"fbref_away_id\",\n",
    "                                  \"fbref_away_id\": \"fbref_home_id\"}, axis = 1, inplace = True)\n",
    "        random_team3_home = random_team3[random_team3.fbref_home_id == team_id]\n",
    "\n",
    "        # concat after changing column names and rename \n",
    "        random_team3 = pd.concat([random_team3_home, random_team3_away])\n",
    "        random_team3.rename({\"fbref_home_id\": \"fbref_own\", \n",
    "                             \"fbref_away_id\": \"fbref_oppon\",\n",
    "                             \"gf_home\": \"gf_own\", \n",
    "                             \"gf_away\": \"gf_own\"}, axis = 1, inplace = True)\n",
    "\n",
    "        self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
    "\n",
    "        return self.end_team\n",
    "\n",
    "    def concat_preprocess(self, df, where):\n",
    "        colname_dict = {}\n",
    "        result_dict = {self.result[\"W\"]: \"L\", self.result[\"D\"]: \"D\", self.result[\"L\"]: \"W\"}\n",
    "        for colname in self.data_frame.loc[:, self.data_frame.columns.str.endswith(where)]:\n",
    "            colname_dict[colname]  = colname[:-5]\n",
    "    \n",
    "        return df.rename(colname_dict, axis = 1, inplace = True)\n",
    "    \n",
    "    def return_dicts(self, dict_name):\n",
    "        if dict_name == \"day\":\n",
    "            return self.day_dict\n",
    "        elif dict_name == \"result\":\n",
    "            return self.result\n",
    "        elif dict_name == \"captain\":\n",
    "            return self.capt\n",
    "        elif dict_name == \"formation\":\n",
    "            return self.formation\n",
    "        elif dict_name == \"referee\":\n",
    "            return self.referee\n",
    "        elif dict_name == \"teams\":\n",
    "            return self.teams\n",
    "        elif dict_name == \"season\":\n",
    "            return self.season\n",
    "        \n",
    "    def data_for_team1(self, date, team_1, window_size = 10, discount = 0.5):\n",
    "        \n",
    "        object = StandardScaler()\n",
    "        dataset1 = self.dataset_team(team_1)\n",
    "        cols_for_movavg = dataset1.columns.isin(self.features)\n",
    "        dataset1.loc[:,cols_for_movavg] = object.fit_transform(dataset1.loc[:,cols_for_movavg])#self.moving_average(dataset1.loc[:,cols_for_movavg], window_size, discount))\n",
    "        dataset1 = dataset1.add_suffix('_1')\n",
    "        dataset1 = dataset1.loc[date]\n",
    "        \n",
    "        dataset2 = self.dataset_team(dataset1.fbref_oppon_1)\n",
    "        dataset2.loc[:,cols_for_movavg] = object.fit_transform(#self.moving_average(dataset2.loc[:,cols_for_movavg], window_size, discount))\n",
    "        dataset2 = dataset2.add_suffix('_2')\n",
    "        dataset2 = dataset2.loc[date]\n",
    "        \n",
    "        cols_to_drop = ['gf_1', 'xg_1', 'schedule_time_1', 'referee_1', 'fbref_season_1', 'fbref_league_id_1', \n",
    "                'fbref_own_1', 'fbref_oppon_1', 'fbref_match_id_1','gf_2', 'xg_2', \n",
    "                'fbref_own_2', 'fbref_oppon_2', 'fbref_match_id_2']\n",
    "        \n",
    "        to_return = pd.concat([dataset1, dataset2])#.loc[date]\n",
    "        to_return = to_return[~to_return.index.isin(cols_to_drop)]\n",
    "        \n",
    "        X = to_return[~to_return.index.isin([\"result_1\", \"result_2\"])]\n",
    "        y = to_return[to_return.index.isin([\"result_1\"])]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def moving_average(self, df, window_size = 10, discount = 0.5, date = None):\n",
    "        \"compute the moving average with recency bias\"\n",
    "        weights = np.array([discount**x for x in reversed(range(window_size))]) # discount y_t-windowsize with discount**windowsize\n",
    "        weights = np.append(weights , 0)\n",
    "        sum_weights = np.sum(weights)\n",
    "        mov_avg = df.rolling(window = window_size + 1).apply(lambda x: np.sum(weights*x) / sum_weights, raw=False) # compute moving average of window_size \n",
    "        return mov_avg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249dc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = preprocess(data)\n",
    "new_data1 = new_data.data_frame#.dataset_team(\"e0652b02\").captain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14d903f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>schedule_round</th>\n",
       "      <th>schedule_day</th>\n",
       "      <th>result_home</th>\n",
       "      <th>gf_home</th>\n",
       "      <th>gf_away</th>\n",
       "      <th>xg_home</th>\n",
       "      <th>xg_away</th>\n",
       "      <th>attendance</th>\n",
       "      <th>captain_home</th>\n",
       "      <th>...</th>\n",
       "      <th>misc_performance_crdr_away</th>\n",
       "      <th>misc_performance_2crdy_away</th>\n",
       "      <th>misc_performance_fls_away</th>\n",
       "      <th>misc_performance_fld_away</th>\n",
       "      <th>misc_performance_off_away</th>\n",
       "      <th>misc_performance_og_away</th>\n",
       "      <th>misc_performance_recov_away</th>\n",
       "      <th>misc_aerialduels_won_away</th>\n",
       "      <th>misc_aerialduels_lost_away</th>\n",
       "      <th>misc_aerialduels_won_perc_away</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>0</td>\n",
       "      <td>Matchweek 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>39226.0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>0</td>\n",
       "      <td>Matchweek 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>39457.0</td>\n",
       "      <td>861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>1</td>\n",
       "      <td>Matchweek 5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>35652.0</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-23</th>\n",
       "      <td>1</td>\n",
       "      <td>Matchweek 6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40856.0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-14</th>\n",
       "      <td>0</td>\n",
       "      <td>Matchweek 8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>39145.0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-15</th>\n",
       "      <td>12</td>\n",
       "      <td>Matchweek 7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>30438.0</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-18</th>\n",
       "      <td>2</td>\n",
       "      <td>Matchweek 28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>30157.0</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>34</td>\n",
       "      <td>Matchweek 30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>30963.0</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-15</th>\n",
       "      <td>2</td>\n",
       "      <td>Matchweek 31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30309.0</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>35</td>\n",
       "      <td>Matchweek 33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30414.0</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10657 rows Ã— 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               schedule_time schedule_round  schedule_day  result_home  \\\n",
       "schedule_date                                                            \n",
       "2017-08-19                 0    Matchweek 1             0            0   \n",
       "2017-09-09                 0    Matchweek 3             0            0   \n",
       "2017-09-20                 1    Matchweek 5             1            0   \n",
       "2017-09-23                 1    Matchweek 6             0            0   \n",
       "2017-10-14                 0    Matchweek 8             0            1   \n",
       "...                      ...            ...           ...          ...   \n",
       "2023-03-15                12    Matchweek 7             1            1   \n",
       "2023-03-18                 2   Matchweek 28             0            2   \n",
       "2023-04-08                34   Matchweek 30             0            1   \n",
       "2023-04-15                 2   Matchweek 31             0            1   \n",
       "2023-04-27                35   Matchweek 33             6            1   \n",
       "\n",
       "               gf_home  gf_away  xg_home  xg_away  attendance  captain_home  \\\n",
       "schedule_date                                                                 \n",
       "2017-08-19         3.0      0.0      1.1      1.4     39226.0            29   \n",
       "2017-09-09         3.0      0.0      1.3      0.6     39457.0           861   \n",
       "2017-09-20         1.0      0.0      0.9      0.4     35652.0           135   \n",
       "2017-09-23         4.0      0.0      2.2      0.2     40856.0            29   \n",
       "2017-10-14         1.0      2.0      2.3      1.6     39145.0            29   \n",
       "...                ...      ...      ...      ...         ...           ...   \n",
       "2023-03-15         0.0      2.0      0.5      1.9     30438.0           227   \n",
       "2023-03-18         3.0      3.0      2.4      2.3     30157.0           227   \n",
       "2023-04-08         1.0      4.0      0.4      2.9     30963.0           227   \n",
       "2023-04-15         0.0      2.0      0.8      0.9     30309.0           227   \n",
       "2023-04-27         0.0      1.0      0.5      0.9     30414.0           227   \n",
       "\n",
       "               ...  misc_performance_crdr_away  misc_performance_2crdy_away  \\\n",
       "schedule_date  ...                                                            \n",
       "2017-08-19     ...                         0.0                          0.0   \n",
       "2017-09-09     ...                         0.0                          0.0   \n",
       "2017-09-20     ...                         1.0                          1.0   \n",
       "2017-09-23     ...                         1.0                          1.0   \n",
       "2017-10-14     ...                         0.0                          0.0   \n",
       "...            ...                         ...                          ...   \n",
       "2023-03-15     ...                         0.0                          0.0   \n",
       "2023-03-18     ...                         0.0                          0.0   \n",
       "2023-04-08     ...                         0.0                          0.0   \n",
       "2023-04-15     ...                         0.0                          0.0   \n",
       "2023-04-27     ...                         0.0                          0.0   \n",
       "\n",
       "               misc_performance_fls_away  misc_performance_fld_away  \\\n",
       "schedule_date                                                         \n",
       "2017-08-19                          11.0                       13.0   \n",
       "2017-09-09                           7.0                       15.0   \n",
       "2017-09-20                          23.0                       10.0   \n",
       "2017-09-23                          12.0                       16.0   \n",
       "2017-10-14                          14.0                        8.0   \n",
       "...                                  ...                        ...   \n",
       "2023-03-15                          10.0                       14.0   \n",
       "2023-03-18                           8.0                       12.0   \n",
       "2023-04-08                          10.0                        6.0   \n",
       "2023-04-15                          13.0                        6.0   \n",
       "2023-04-27                          11.0                        7.0   \n",
       "\n",
       "               misc_performance_off_away  misc_performance_og_away  \\\n",
       "schedule_date                                                        \n",
       "2017-08-19                           0.0                       0.0   \n",
       "2017-09-09                           1.0                       1.0   \n",
       "2017-09-20                           1.0                       0.0   \n",
       "2017-09-23                           1.0                       0.0   \n",
       "2017-10-14                           1.0                       0.0   \n",
       "...                                  ...                       ...   \n",
       "2023-03-15                           1.0                       0.0   \n",
       "2023-03-18                           1.0                       0.0   \n",
       "2023-04-08                           2.0                       0.0   \n",
       "2023-04-15                           1.0                       0.0   \n",
       "2023-04-27                           2.0                       0.0   \n",
       "\n",
       "               misc_performance_recov_away  misc_aerialduels_won_away  \\\n",
       "schedule_date                                                           \n",
       "2017-08-19                            40.0                        9.0   \n",
       "2017-09-09                            34.0                       10.0   \n",
       "2017-09-20                            46.0                        8.0   \n",
       "2017-09-23                            41.0                        6.0   \n",
       "2017-10-14                            47.0                       14.0   \n",
       "...                                    ...                        ...   \n",
       "2023-03-15                            51.0                       23.0   \n",
       "2023-03-18                            48.0                       14.0   \n",
       "2023-04-08                            45.0                       13.0   \n",
       "2023-04-15                            53.0                       14.0   \n",
       "2023-04-27                            60.0                       12.0   \n",
       "\n",
       "               misc_aerialduels_lost_away  misc_aerialduels_won_perc_away  \n",
       "schedule_date                                                              \n",
       "2017-08-19                            8.0                            52.9  \n",
       "2017-09-09                           10.0                            50.0  \n",
       "2017-09-20                            9.0                            47.1  \n",
       "2017-09-23                           11.0                            35.3  \n",
       "2017-10-14                           12.0                            53.8  \n",
       "...                                   ...                             ...  \n",
       "2023-03-15                           17.0                            57.5  \n",
       "2023-03-18                           10.0                            58.3  \n",
       "2023-04-08                            7.0                            65.0  \n",
       "2023-04-15                           20.0                            41.2  \n",
       "2023-04-27                           10.0                            54.5  \n",
       "\n",
       "[10657 rows x 295 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec096f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>xg</th>\n",
       "      <th>captain</th>\n",
       "      <th>formation</th>\n",
       "      <th>shooting_standard_gls</th>\n",
       "      <th>shooting_standard_sh</th>\n",
       "      <th>shooting_standard_sot</th>\n",
       "      <th>shooting_standard_sot_perc</th>\n",
       "      <th>shooting_standard_g_per_sh</th>\n",
       "      <th>...</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>attendance</th>\n",
       "      <th>referee</th>\n",
       "      <th>fbref_season</th>\n",
       "      <th>fbref_league_id</th>\n",
       "      <th>fbref_own</th>\n",
       "      <th>fbref_oppon</th>\n",
       "      <th>fbref_match_id</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>0.993065</td>\n",
       "      <td>-0.492178</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>1.573056</td>\n",
       "      <td>1.379440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.364858</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>4713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>616</td>\n",
       "      <td>11</td>\n",
       "      <td>0.993065</td>\n",
       "      <td>0.202280</td>\n",
       "      <td>1.173772</td>\n",
       "      <td>1.189740</td>\n",
       "      <td>0.872919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395817</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.704719</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>4694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>-0.029206</td>\n",
       "      <td>0.182895</td>\n",
       "      <td>0.258828</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395817</td>\n",
       "      <td>8</td>\n",
       "      <td>3.054934</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>4524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>-0.029206</td>\n",
       "      <td>-0.807981</td>\n",
       "      <td>-0.986950</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.491020</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>4714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-10</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>0.665252</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.210914</td>\n",
       "      <td>-0.849250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395817</td>\n",
       "      <td>2</td>\n",
       "      <td>1.164133</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>4582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>-0.955151</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>2.654556</td>\n",
       "      <td>0.569007</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>6602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-16</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>-0.955151</td>\n",
       "      <td>0.182895</td>\n",
       "      <td>1.675730</td>\n",
       "      <td>0.569007</td>\n",
       "      <td>...</td>\n",
       "      <td>4.799276</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>6450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-21</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>935</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>1.128224</td>\n",
       "      <td>0.182895</td>\n",
       "      <td>-0.521495</td>\n",
       "      <td>-0.241426</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>126</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>6603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-30</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>0.993065</td>\n",
       "      <td>-1.881095</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.046635</td>\n",
       "      <td>2.493785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395817</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>6366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-07</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>-0.260692</td>\n",
       "      <td>-0.312543</td>\n",
       "      <td>-0.179248</td>\n",
       "      <td>0.163791</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>6604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               result   gf   xg  captain  formation  shooting_standard_gls  \\\n",
       "schedule_date                                                                \n",
       "2017-08-06          2  2.0  1.2       59         11               0.993065   \n",
       "2017-08-12          0  2.0  1.4      616         11               0.993065   \n",
       "2017-08-20          2  1.0  0.6       19         11              -0.014119   \n",
       "2017-08-27          2  1.0  0.8       19         11              -0.014119   \n",
       "2017-09-10          2  1.0  2.4       59         11              -0.014119   \n",
       "...               ...  ...  ...      ...        ...                    ...   \n",
       "2023-04-08          0  1.0  1.0      175         12              -0.014119   \n",
       "2023-04-16          1  1.0  0.3       80         12              -0.014119   \n",
       "2023-04-21          1  1.0  1.8      935         12              -0.014119   \n",
       "2023-04-30          1  2.0  1.0       80         12               0.993065   \n",
       "2023-05-07          1  1.0  1.0       80         12              -0.014119   \n",
       "\n",
       "               shooting_standard_sh  shooting_standard_sot  \\\n",
       "schedule_date                                                \n",
       "2017-08-06                -0.492178               0.678333   \n",
       "2017-08-12                 0.202280               1.173772   \n",
       "2017-08-20                -0.029206               0.182895   \n",
       "2017-08-27                -0.029206              -0.807981   \n",
       "2017-09-10                 0.665252               0.678333   \n",
       "...                             ...                    ...   \n",
       "2023-04-08                -0.955151               0.678333   \n",
       "2023-04-16                -0.955151               0.182895   \n",
       "2023-04-21                 1.128224               0.182895   \n",
       "2023-04-30                -1.881095              -1.303419   \n",
       "2023-05-07                -0.260692              -0.312543   \n",
       "\n",
       "               shooting_standard_sot_perc  shooting_standard_g_per_sh  ...  \\\n",
       "schedule_date                                                          ...   \n",
       "2017-08-06                       1.573056                    1.379440  ...   \n",
       "2017-08-12                       1.189740                    0.872919  ...   \n",
       "2017-08-20                       0.258828                    0.062487  ...   \n",
       "2017-08-27                      -0.986950                    0.062487  ...   \n",
       "2017-09-10                       0.210914                   -0.849250  ...   \n",
       "...                                   ...                         ...  ...   \n",
       "2023-04-08                       2.654556                    0.569007  ...   \n",
       "2023-04-16                       1.675730                    0.569007  ...   \n",
       "2023-04-21                      -0.521495                   -0.241426  ...   \n",
       "2023-04-30                       0.046635                    2.493785  ...   \n",
       "2023-05-07                      -0.179248                    0.163791  ...   \n",
       "\n",
       "               keeper_penaltykicks_pka  schedule_time  attendance  referee  \\\n",
       "schedule_date                                                                \n",
       "2017-08-06                         NaN              8   -0.364858      115   \n",
       "2017-08-12                   -0.395817             27   -0.704719      120   \n",
       "2017-08-20                   -0.395817              8    3.054934      119   \n",
       "2017-08-27                         NaN              8   -0.491020      107   \n",
       "2017-09-10                   -0.395817              2    1.164133      110   \n",
       "...                                ...            ...         ...      ...   \n",
       "2023-04-08                         NaN              8         NaN      141   \n",
       "2023-04-16                    4.799276              2         NaN      113   \n",
       "2023-04-21                         NaN              6    0.073005      126   \n",
       "2023-04-30                   -0.395817              2         NaN      125   \n",
       "2023-05-07                         NaN             26         NaN      127   \n",
       "\n",
       "               fbref_season  fbref_league_id  fbref_own  fbref_oppon  \\\n",
       "schedule_date                                                          \n",
       "2017-08-06                0                2          1           47   \n",
       "2017-08-12                0                2          1           93   \n",
       "2017-08-20                0                2          1           91   \n",
       "2017-08-27                0                2          1           44   \n",
       "2017-09-10                0                2          1           61   \n",
       "...                     ...              ...        ...          ...   \n",
       "2023-04-08                5                2          1           44   \n",
       "2023-04-16                5                2          1           77   \n",
       "2023-04-21                5                2          1          102   \n",
       "2023-04-30                5                2          1          129   \n",
       "2023-05-07                5                2          1          113   \n",
       "\n",
       "               fbref_match_id  home  \n",
       "schedule_date                        \n",
       "2017-08-06               4713     1  \n",
       "2017-08-12               4694     0  \n",
       "2017-08-20               4524     0  \n",
       "2017-08-27               4714     1  \n",
       "2017-09-10               4582     0  \n",
       "...                       ...   ...  \n",
       "2023-04-08               6602     1  \n",
       "2023-04-16               6450     0  \n",
       "2023-04-21               6603     1  \n",
       "2023-04-30               6366     0  \n",
       "2023-05-07               6604     1  \n",
       "\n",
       "[214 rows x 152 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = new_data.dataset_team(1)\n",
    "df\n",
    "cols_to_transform = ['shooting_standard_gls', 'shooting_standard_sh', 'shooting_standard_sot', \n",
    "                         'shooting_standard_sot_perc', 'shooting_standard_g_per_sh', 'shooting_standard_g_per_sot',\n",
    "                         'shooting_standard_dist', 'shooting_standard_fk', 'shooting_standard_pk', \n",
    "                         'shooting_standard_pkatt', 'shooting_expected_npxg', 'shooting_expected_npxg_per_sh',\n",
    "                         'shooting_expected_g_minus_xg', 'shooting_expected_npg_minus_xg', 'keeper_performance_sota',\n",
    "                         'keeper_performance_saves', 'keeper_performance_save_perc', 'keeper_performance_cs',\n",
    "                         'keeper_performance_psxg', 'keeper_performance_psxg_plus_minus', 'keeper_penaltykicks_pkatt', \n",
    "                         'keeper_penaltykicks_pksv', 'keeper_penaltykicks_pkm', 'keeper_launched_cmp', 'keeper_launched_att',\n",
    "                         'keeper_launched_cmp_perc', 'keeper_passes_att', 'keeper_passes_thr', 'keeper_passes_launch_perc',\n",
    "                         'keeper_passes_avglen', 'keeper_goalkicks_att', 'keeper_goalkicks_launch_perc', \n",
    "                         'keeper_goalkicks_avglen', 'keeper_crosses_opp', 'keeper_crosses_stp', 'keeper_crosses_stp_perc',\n",
    "                         'keeper_sweeper_number_opa', 'keeper_sweeper_avgdist', 'passing_total_cmp', 'passing_total_att',\n",
    "                         'passing_total_cmp_perc', 'passing_total_totdist', 'passing_total_prgdist', 'passing_short_cmp',\n",
    "                         'passing_short_att', 'passing_short_cmp_perc', 'passing_medium_cmp', 'passing_medium_att',\n",
    "                         'passing_medium_cmp_perc', 'passing_long_cmp', 'passing_long_att', 'passing_long_cmp_perc',\n",
    "                         'passing_attacking_ast', 'passing_attacking_xag', 'passing_attacking_xa', 'passing_attacking_kp',\n",
    "                         'passing_attacking_1_per_3', 'passing_attacking_ppa', 'passing_attacking_crspa', 'passing_attacking_prgp',\n",
    "                         'passing_types_passtypes_live', 'passing_types_passtypes_dead', 'passing_types_passtypes_fk',\n",
    "                         'passing_types_passtypes_tb', 'passing_types_passtypes_sw', 'passing_types_passtypes_crs',\n",
    "                         'passing_types_passtypes_ti', 'passing_types_passtypes_ck', 'passing_types_cornerkicks_in',\n",
    "                         'passing_types_cornerkicks_out', 'passing_types_cornerkicks_str', 'passing_types_outcomes_off',\n",
    "                         'passing_types_outcomes_blocks', 'gca_scatypes_sca', 'gca_scatypes_passlive', 'gca_scatypes_passdead',\n",
    "                         'gca_scatypes_to', 'gca_scatypes_sh', 'gca_scatypes_fld', 'gca_scatypes_def', 'gca_gcatypes_gca', \n",
    "                         'gca_gcatypes_passlive', 'gca_gcatypes_passdead', 'gca_gcatypes_to', 'gca_gcatypes_sh',\n",
    "                         'gca_gcatypes_fld',  'gca_gcatypes_def', 'defense_tackles_tkl', 'defense_tackles_tklw',\n",
    "                         'defense_tackles_def3rd', 'defense_tackles_mid3rd', 'defense_tackles_att3rd', 'defense_challenges_tkl',\n",
    "                         'defense_challenges_att', 'defense_challenges_tkl_perc', 'defense_challenges_lost', 'defense_blocks_blocks',\n",
    "                         'defense_blocks_sh', 'defense_blocks_pass', 'defense_general_int', 'defense_general_tkl_plus_int',\n",
    "                         'defense_general_clr', 'defense_general_err', 'possession_general_poss', 'possession_touches_touches',\n",
    "                         'possession_touches_defpen', 'possession_touches_def3rd', 'possession_touches_mid3rd',\n",
    "                         'possession_touches_att3rd', 'possession_touches_attpen', 'possession_touches_live', 'possession_takeons_att',\n",
    "                         'possession_takeons_succ', 'possession_takeons_succ_perc', 'possession_takeons_tkld', 'possession_takeons_tkld_perc',\n",
    "                         'possession_carries_carries', 'possession_carries_totdist', 'possession_carries_prgdist',\n",
    "                         'possession_carries_prgc', 'possession_carries_1_per_3', 'possession_carries_cpa', 'possession_carries_mis',\n",
    "                         'possession_carries_dis', 'possession_receiving_rec', 'possession_receiving_prgr',\n",
    "                         'misc_performance_crdy', 'misc_performance_crdr', 'misc_performance_2crdy', 'misc_performance_fls',\n",
    "                         'misc_performance_fld', 'misc_performance_off', 'misc_performance_og', 'misc_performance_recov',\n",
    "                         'misc_aerialduels_won', 'misc_aerialduels_lost', 'misc_aerialduels_won_perc', 'keeper_penaltykicks_pka',\n",
    "                         'attendance']\n",
    "\n",
    "object = StandardScaler()\n",
    "\n",
    "df.loc[:,cols_to_transform] = object.fit_transform(df.loc[:,cols_to_transform])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5ab603a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_2420/3851513251.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "object = StandardScaler()\n",
    "cols_to_transform = ['shooting_standard_gls', 'shooting_standard_sh', 'shooting_standard_sot', \n",
    "                         'shooting_standard_sot_perc', 'shooting_standard_g_per_sh', 'shooting_standard_g_per_sot',\n",
    "                         'shooting_standard_dist', 'shooting_standard_fk', 'shooting_standard_pk', \n",
    "                         'shooting_standard_pkatt', 'shooting_expected_npxg', 'shooting_expected_npxg_per_sh',\n",
    "                         'shooting_expected_g_minus_xg', 'shooting_expected_npg_minus_xg', 'keeper_performance_sota',\n",
    "                         'keeper_performance_saves', 'keeper_performance_save_perc', 'keeper_performance_cs',\n",
    "                         'keeper_performance_psxg', 'keeper_performance_psxg_plus_minus', 'keeper_penaltykicks_pkatt', \n",
    "                         'keeper_penaltykicks_pksv', 'keeper_penaltykicks_pkm', 'keeper_launched_cmp', 'keeper_launched_att',\n",
    "                         'keeper_launched_cmp_perc', 'keeper_passes_att', 'keeper_passes_thr', 'keeper_passes_launch_perc',\n",
    "                         'keeper_passes_avglen', 'keeper_goalkicks_att', 'keeper_goalkicks_launch_perc', \n",
    "                         'keeper_goalkicks_avglen', 'keeper_crosses_opp', 'keeper_crosses_stp', 'keeper_crosses_stp_perc',\n",
    "                         'keeper_sweeper_number_opa', 'keeper_sweeper_avgdist', 'passing_total_cmp', 'passing_total_att',\n",
    "                         'passing_total_cmp_perc', 'passing_total_totdist', 'passing_total_prgdist', 'passing_short_cmp',\n",
    "                         'passing_short_att', 'passing_short_cmp_perc', 'passing_medium_cmp', 'passing_medium_att',\n",
    "                         'passing_medium_cmp_perc', 'passing_long_cmp', 'passing_long_att', 'passing_long_cmp_perc',\n",
    "                         'passing_attacking_ast', 'passing_attacking_xag', 'passing_attacking_xa', 'passing_attacking_kp',\n",
    "                         'passing_attacking_1_per_3', 'passing_attacking_ppa', 'passing_attacking_crspa', 'passing_attacking_prgp',\n",
    "                         'passing_types_passtypes_live', 'passing_types_passtypes_dead', 'passing_types_passtypes_fk',\n",
    "                         'passing_types_passtypes_tb', 'passing_types_passtypes_sw', 'passing_types_passtypes_crs',\n",
    "                         'passing_types_passtypes_ti', 'passing_types_passtypes_ck', 'passing_types_cornerkicks_in',\n",
    "                         'passing_types_cornerkicks_out', 'passing_types_cornerkicks_str', 'passing_types_outcomes_off',\n",
    "                         'passing_types_outcomes_blocks', 'gca_scatypes_sca', 'gca_scatypes_passlive', 'gca_scatypes_passdead',\n",
    "                         'gca_scatypes_to', 'gca_scatypes_sh', 'gca_scatypes_fld', 'gca_scatypes_def', 'gca_gcatypes_gca', \n",
    "                         'gca_gcatypes_passlive', 'gca_gcatypes_passdead', 'gca_gcatypes_to', 'gca_gcatypes_sh',\n",
    "                         'gca_gcatypes_fld',  'gca_gcatypes_def', 'defense_tackles_tkl', 'defense_tackles_tklw',\n",
    "                         'defense_tackles_def3rd', 'defense_tackles_mid3rd', 'defense_tackles_att3rd', 'defense_challenges_tkl',\n",
    "                         'defense_challenges_att', 'defense_challenges_tkl_perc', 'defense_challenges_lost', 'defense_blocks_blocks',\n",
    "                         'defense_blocks_sh', 'defense_blocks_pass', 'defense_general_int', 'defense_general_tkl_plus_int',\n",
    "                         'defense_general_clr', 'defense_general_err', 'possession_general_poss', 'possession_touches_touches',\n",
    "                         'possession_touches_defpen', 'possession_touches_def3rd', 'possession_touches_mid3rd',\n",
    "                         'possession_touches_att3rd', 'possession_touches_attpen', 'possession_touches_live', 'possession_takeons_att',\n",
    "                         'possession_takeons_succ', 'possession_takeons_succ_perc', 'possession_takeons_tkld', 'possession_takeons_tkld_perc',\n",
    "                         'possession_carries_carries', 'possession_carries_totdist', 'possession_carries_prgdist',\n",
    "                         'possession_carries_prgc', 'possession_carries_1_per_3', 'possession_carries_cpa', 'possession_carries_mis',\n",
    "                         'possession_carries_dis', 'possession_receiving_rec', 'possession_receiving_prgr',\n",
    "                         'misc_performance_crdy', 'misc_performance_crdr', 'misc_performance_2crdy', 'misc_performance_fls',\n",
    "                         'misc_performance_fld', 'misc_performance_off', 'misc_performance_og', 'misc_performance_recov',\n",
    "                         'misc_aerialduels_won', 'misc_aerialduels_lost', 'misc_aerialduels_won_perc', 'keeper_penaltykicks_pka',\n",
    "                         'attendance']\n",
    "\n",
    "\n",
    "for team in set(list(new_data.data_frame.fbref_home_id.unique()) + list(new_data.data_frame.fbref_away_id.unique())):\n",
    "    df = new_data.dataset_team(team)\n",
    "    df.loc[:,cols_to_transform] = object.fit_transform(df.loc[:,cols_to_transform])\n",
    "    for seas in df.fbref_season.unique():\n",
    "        for i in range(len(df[df.fbref_season == seas])-1):\n",
    "            #i = i + 1\n",
    "            empty_df = np.zeros([38, df[df.fbref_season == seas].shape[1]])\n",
    "            empty_df[-i - 1:,:] = df[df.fbref_season == seas].iloc[:i + 1]\n",
    "            result = np.array(df[df.fbref_season == seas].iloc[i + 1].result)\n",
    "            X.append(empty_df)\n",
    "            y.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a256c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [torch.from_numpy(x.astype(float)) for x in X]\n",
    "y1 = [torch.from_numpy(Y.astype(float)) for Y in y]\n",
    "y1 = [torch.nn.functional.one_hot(x.long(), num_classes = 3) for x in y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e5a8bb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 5.0000e-01,  ..., 6.1000e+01, 4.5800e+03,\n",
       "         0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "59de86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_to_lstm():\n",
    "\n",
    "    def __init__(self, mylist1, mylist2):\n",
    "        self.output = []\n",
    "        self.mylist1 = mylist1\n",
    "        self.mylist2 = mylist2\n",
    "        \n",
    "        for i in range(len(mylist1)):\n",
    "            self.output.append((mylist1[i], mylist2[i]))\n",
    "        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.output)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.output[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9d106ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tansformed = data_to_lstm(X1,y1)\n",
    "len_train = int(0.8 * len(X1))\n",
    "len_test = len(X1) - len_train\n",
    "\n",
    "train, test = torch.utils.data.random_split(data_tansformed, [len_train, len_test])\n",
    "#test = torch.utils.data.random_split(data_tansformed, len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "57590bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(test, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "31281a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sport_pred_LSTM(torch.nn.Module):\n",
    "    def __init__(self,n_features, hidden, num_classes):\n",
    "        super(Sport_pred_LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.num_classes = num_classes\n",
    "        self.n_hidden = hidden # number of hidden states\n",
    "        self.n_layers = 2 # number of LSTM layers (stacked)\n",
    "        \n",
    "        self.l_lstm = torch.nn.LSTM(input_size = n_features, \n",
    "                             hidden_size = self.n_hidden,\n",
    "                             num_layers = self.n_layers)\n",
    "\n",
    "        self.l_linear = torch.nn.Linear(self.n_hidden, self.n_hidden)\n",
    "        self.l_linear2 = torch.nn.Linear(self.n_hidden, num_classes)\n",
    "        self.soft = torch.nn.Softmax(dim = 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    #def init_hidden(self, batch_size):\n",
    "     #   hidden_state = torch.randn(self.n_layers,batch_size,self.n_hidden)\n",
    "      #  cell_state = torch.randn(self.n_layers,batch_size,self.n_hidden)\n",
    "       # self.hidden = (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = torch.nan_to_num(x, nan = 0.0)\n",
    "        #print(x)\n",
    "        h0 = torch.randn(self.n_layers*1, 38, self.n_hidden).to(x.dtype)\n",
    "        #print(h0.dtype)\n",
    "        c0 = torch.randn(self.n_layers*1, 38, self.n_hidden).to(x.dtype)\n",
    "        #print(c0.dtype)\n",
    "        \n",
    "        lstm_out,(hn, cn) = self.l_lstm(x,(h0, c0))\n",
    "        #print(\"lstm out:\", lstm_out)\n",
    "        #x = lstm_out.contiguous().view(-1, self.n_hidden)\n",
    "        x = lstm_out[:, -1, :]\n",
    "        #print(x)\n",
    "        x = self.relu(self.l_linear(x))\n",
    "        out = self.soft(self.l_linear2(x))\n",
    "        #print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f6fdaf15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.22065456211566925 \n",
      " Accuracy 26.5625%\n",
      " Loss: 0.22083884477615356 \n",
      " Accuracy 26.923076923076923%\n",
      " Loss: 0.222123920917511 \n",
      " Accuracy 28.75%\n",
      " Loss: 0.2279193252325058 \n",
      " Accuracy 31.634615384615383%\n",
      " Loss: 0.21734578907489777 \n",
      " Accuracy 33.70192307692308%\n",
      " Loss: 0.21990744769573212 \n",
      " Accuracy 36.17788461538461%\n",
      " Loss: 0.22095263004302979 \n",
      " Accuracy 36.17788461538461%\n",
      " Loss: 0.22415636479854584 \n",
      " Accuracy 36.68269230769231%\n",
      " Loss: 0.21830154955387115 \n",
      " Accuracy 36.85096153846154%\n",
      " Loss: 0.21481472253799438 \n",
      " Accuracy 36.58653846153846%\n",
      " Loss: 0.216144397854805 \n",
      " Accuracy 37.13942307692308%\n",
      " Loss: 0.22176431119441986 \n",
      " Accuracy 36.58653846153846%\n",
      " Loss: 0.21400441229343414 \n",
      " Accuracy 36.51442307692308%\n",
      " Loss: 0.21768547594547272 \n",
      " Accuracy 36.5625%\n",
      " Loss: 0.21896494925022125 \n",
      " Accuracy 36.49038461538461%\n",
      " Loss: 0.20585651695728302 \n",
      " Accuracy 36.5625%\n",
      " Loss: 0.21569214761257172 \n",
      " Accuracy 36.61057692307692%\n",
      " Loss: 0.2329302579164505 \n",
      " Accuracy 36.77884615384615%\n",
      " Loss: 0.208807110786438 \n",
      " Accuracy 36.58653846153846%\n",
      " Loss: 0.21907353401184082 \n",
      " Accuracy 36.03365384615385%\n",
      " Loss: 0.21533037722110748 \n",
      " Accuracy 36.49038461538461%\n",
      " Loss: 0.2194194197654724 \n",
      " Accuracy 37.40384615384615%\n",
      " Loss: 0.2162015438079834 \n",
      " Accuracy 36.82692307692308%\n",
      " Loss: 0.20599442720413208 \n",
      " Accuracy 36.39423076923077%\n",
      " Loss: 0.2210126519203186 \n",
      " Accuracy 35.91346153846154%\n",
      " Loss: 0.21974091231822968 \n",
      " Accuracy 37.06730769230769%\n",
      " Loss: 0.22230511903762817 \n",
      " Accuracy 36.65865384615385%\n",
      " Loss: 0.2192631959915161 \n",
      " Accuracy 36.41826923076923%\n",
      " Loss: 0.2244124412536621 \n",
      " Accuracy 36.63461538461539%\n",
      " Loss: 0.23103803396224976 \n",
      " Accuracy 36.94711538461539%\n"
     ]
    }
   ],
   "source": [
    "model = Sport_pred_LSTM(152,38,3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "epoch = 30\n",
    "losses = list()\n",
    "for epoch in range(epoch):\n",
    "    model.eval()\n",
    "    loss_test = 0\n",
    "    accur = 0\n",
    "    for i, (seq, target) in enumerate(test_loader):\n",
    "        pred = model(seq)\n",
    "        #print(pred.shape)\n",
    "        #print(target.shape)\n",
    "        loss_test += criterion(pred, target.to(torch.float32)).item()\n",
    "        pred = torch.argmax(pred, dim = 1)\n",
    "        target = torch.argmax(target, dim = 1)\n",
    "        #losses += loss\n",
    "        accur += pred.eq(target).sum().item()\n",
    "    \n",
    "    print(f\" Loss: {loss} \\n Accuracy {100 * accur / ((i + 1) * 32)}%\")\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, (seq, target) in enumerate(train_loader):\n",
    "        model.zero_grad()\n",
    "        pred = model(seq)\n",
    "        loss = criterion(pred, target.to(torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd0549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5ee09475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 38, 152])\n",
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "for _, (s,p) in enumerate(train_loader):\n",
    "    print(s.shape)\n",
    "    print(p.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0407666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sport_pred_LSTM(torch.nn.Module):\n",
    "    def __init__(self,n_features, hidden, num_classes):\n",
    "        super(Sport_pred_LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.num_classes = num_classes\n",
    "        self.n_hidden = hidden # number of hidden states\n",
    "        self.n_layers = 2 # number of LSTM layers (stacked)\n",
    "        \n",
    "        self.l_lstm = torch.nn.LSTM(input_size = n_features, \n",
    "                             hidden_size = self.n_hidden,\n",
    "                             num_layers = self.n_layers)\n",
    "\n",
    "        self.l_linear = torch.nn.Linear(self.n_hidden, num_classes)\n",
    "        self.soft = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "    #def init_hidden(self, batch_size):\n",
    "     #   hidden_state = torch.randn(self.n_layers,batch_size,self.n_hidden)\n",
    "      #  cell_state = torch.randn(self.n_layers,batch_size,self.n_hidden)\n",
    "       # self.hidden = (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = torch.nan_to_num(x, nan = 0.0)\n",
    "        #print(x)\n",
    "        h0 = torch.randn(self.n_layers*1, self.n_hidden).to(x.dtype)\n",
    "        #print(h0.dtype)\n",
    "        c0 = torch.randn(self.n_layers*1, self.n_hidden).to(x.dtype)\n",
    "        #print(c0.dtype)\n",
    "        \n",
    "        lstm_out,_ = self.l_lstm(x,(h0, c0))\n",
    "        #print(\"lstm out:\", lstm_out)\n",
    "        x = lstm_out.contiguous().view(-1, self.n_hidden)\n",
    "        #print(x)\n",
    "        out = self.soft(self.l_linear(x))\n",
    "        #print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a5350704",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(X1[0]) # this is number of parallel inputs\n",
    "\n",
    "# create NN\n",
    "mv_net = Sport_pred_LSTM(n_features, 150, 3)\n",
    "criterion = torch.nn.MSELoss() # reduction='sum' created huge loss value\n",
    "optimizer = torch.optim.Adam(mv_net.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "\n",
    "train_episodes = 500\n",
    "batch_size = 30\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "966f94b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For batched 3-D input, hx and cx should also be 3-D but got (2-D, 2-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [197]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m label \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(data.dtype)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmv_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, label\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)) \n",
      "Input \u001b[0;32mIn [195]\u001b[0m, in \u001b[0;36mSport_pred_LSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_hidden)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#print(c0.dtype)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m lstm_out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#print(\"lstm out:\", lstm_out)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m hn\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:760\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    758\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched 3-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    759\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 3-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 760\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For batched 3-D input, hx and cx should also be 3-D but got (2-D, 2-D) tensors"
     ]
    }
   ],
   "source": [
    "mv_net.train()\n",
    "\n",
    "for t in range(train_episodes):\n",
    "\n",
    "    mv_net.train()\n",
    "    for _, (data, target) in enumerate(dataloader):\n",
    "        inpt = data.to(torch.float32)\n",
    "        label = target\n",
    "        #print(data.dtype)\n",
    "\n",
    "        output = mv_net.forward(data) \n",
    "        print(output)\n",
    "        loss = criterion(output, label.to(torch.float32)) \n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        optimizer.zero_grad() \n",
    "        break\n",
    "    if t%50 == 0:\n",
    "        print('step : ' , t , 'loss : ' , loss.item())\n",
    "        \n",
    "    #mv_net.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2080e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da888cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797ec9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "717bd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schedule_date\n",
       "2017-08-19        0\n",
       "2017-09-09        1\n",
       "2017-09-20        2\n",
       "2017-09-23        3\n",
       "2017-10-14        4\n",
       "              ...  \n",
       "2023-03-15    10652\n",
       "2023-03-18    10653\n",
       "2023-04-08    10654\n",
       "2023-04-15    10655\n",
       "2023-04-27    10656\n",
       "Name: fbref_match_id, Length: 10657, dtype: int64"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fbref_match_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8536cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sequencizer(X, y, seq_len):\n",
    "    x_t = []\n",
    "    y_t = []\n",
    "    for i in range(len(X)):\n",
    "        if i + seq_len + 1 == len(X):\n",
    "            break\n",
    "        x_train = X[i:i + seq_len]\n",
    "        y_train = y[i + seq_len + 1]\n",
    "        \n",
    "        x_t.append(x_train)\n",
    "        y_t.append(y_train)\n",
    "        \n",
    "    return np.array(x_t), np.array(y_t)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "b82c2017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>schedule_round</th>\n",
       "      <th>schedule_day</th>\n",
       "      <th>result_home</th>\n",
       "      <th>gf_home</th>\n",
       "      <th>gf_away</th>\n",
       "      <th>xg_home</th>\n",
       "      <th>xg_away</th>\n",
       "      <th>attendance</th>\n",
       "      <th>captain_home</th>\n",
       "      <th>formation_home</th>\n",
       "      <th>referee</th>\n",
       "      <th>fbref_season</th>\n",
       "      <th>fbref_league_id</th>\n",
       "      <th>fbref_home_id</th>\n",
       "      <th>fbref_away_id</th>\n",
       "      <th>fbref_match_id</th>\n",
       "      <th>shooting_standard_gls_home</th>\n",
       "      <th>shooting_standard_sh_home</th>\n",
       "      <th>shooting_standard_sot_home</th>\n",
       "      <th>shooting_standard_sot_perc_home</th>\n",
       "      <th>shooting_standard_g_per_sh_home</th>\n",
       "      <th>shooting_standard_g_per_sot_home</th>\n",
       "      <th>shooting_standard_dist_home</th>\n",
       "      <th>shooting_standard_fk_home</th>\n",
       "      <th>shooting_standard_pk_home</th>\n",
       "      <th>shooting_standard_pkatt_home</th>\n",
       "      <th>shooting_expected_npxg_home</th>\n",
       "      <th>shooting_expected_npxg_per_sh_home</th>\n",
       "      <th>shooting_expected_g_minus_xg_home</th>\n",
       "      <th>shooting_expected_npg_minus_xg_home</th>\n",
       "      <th>keeper_performance_sota_home</th>\n",
       "      <th>keeper_performance_saves_home</th>\n",
       "      <th>keeper_performance_save_perc_home</th>\n",
       "      <th>keeper_performance_cs_home</th>\n",
       "      <th>keeper_performance_psxg_home</th>\n",
       "      <th>keeper_performance_psxg_plus_minus_home</th>\n",
       "      <th>keeper_penaltykicks_pkatt_home</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "      <th>keeper_penaltykicks_pksv_home</th>\n",
       "      <th>keeper_penaltykicks_pkm_home</th>\n",
       "      <th>keeper_launched_cmp_home</th>\n",
       "      <th>keeper_launched_att_home</th>\n",
       "      <th>keeper_launched_cmp_perc_home</th>\n",
       "      <th>keeper_passes_att_home</th>\n",
       "      <th>keeper_passes_thr_home</th>\n",
       "      <th>keeper_passes_launch_perc_home</th>\n",
       "      <th>keeper_passes_avglen_home</th>\n",
       "      <th>keeper_goalkicks_att_home</th>\n",
       "      <th>keeper_goalkicks_launch_perc_home</th>\n",
       "      <th>...</th>\n",
       "      <th>defense_tackles_tkl_away</th>\n",
       "      <th>defense_tackles_tklw_away</th>\n",
       "      <th>defense_tackles_def3rd_away</th>\n",
       "      <th>defense_tackles_mid3rd_away</th>\n",
       "      <th>defense_tackles_att3rd_away</th>\n",
       "      <th>defense_challenges_tkl_away</th>\n",
       "      <th>defense_challenges_att_away</th>\n",
       "      <th>defense_challenges_tkl_perc_away</th>\n",
       "      <th>defense_challenges_lost_away</th>\n",
       "      <th>defense_blocks_blocks_away</th>\n",
       "      <th>defense_blocks_sh_away</th>\n",
       "      <th>defense_blocks_pass_away</th>\n",
       "      <th>defense_general_int_away</th>\n",
       "      <th>defense_general_tkl_plus_int_away</th>\n",
       "      <th>defense_general_clr_away</th>\n",
       "      <th>defense_general_err_away</th>\n",
       "      <th>possession_general_poss_away</th>\n",
       "      <th>possession_touches_touches_away</th>\n",
       "      <th>possession_touches_defpen_away</th>\n",
       "      <th>possession_touches_def3rd_away</th>\n",
       "      <th>possession_touches_mid3rd_away</th>\n",
       "      <th>possession_touches_att3rd_away</th>\n",
       "      <th>possession_touches_attpen_away</th>\n",
       "      <th>possession_touches_live_away</th>\n",
       "      <th>possession_takeons_att_away</th>\n",
       "      <th>possession_takeons_succ_away</th>\n",
       "      <th>possession_takeons_succ_perc_away</th>\n",
       "      <th>possession_takeons_tkld_away</th>\n",
       "      <th>possession_takeons_tkld_perc_away</th>\n",
       "      <th>possession_carries_carries_away</th>\n",
       "      <th>possession_carries_totdist_away</th>\n",
       "      <th>possession_carries_prgdist_away</th>\n",
       "      <th>possession_carries_prgc_away</th>\n",
       "      <th>possession_carries_1_per_3_away</th>\n",
       "      <th>possession_carries_cpa_away</th>\n",
       "      <th>possession_carries_mis_away</th>\n",
       "      <th>possession_carries_dis_away</th>\n",
       "      <th>possession_receiving_rec_away</th>\n",
       "      <th>possession_receiving_prgr_away</th>\n",
       "      <th>misc_performance_crdy_away</th>\n",
       "      <th>misc_performance_crdr_away</th>\n",
       "      <th>misc_performance_2crdy_away</th>\n",
       "      <th>misc_performance_fls_away</th>\n",
       "      <th>misc_performance_fld_away</th>\n",
       "      <th>misc_performance_off_away</th>\n",
       "      <th>misc_performance_og_away</th>\n",
       "      <th>misc_performance_recov_away</th>\n",
       "      <th>misc_aerialduels_won_away</th>\n",
       "      <th>misc_aerialduels_lost_away</th>\n",
       "      <th>misc_aerialduels_won_perc_away</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>0</td>\n",
       "      <td>Matchweek 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>39226.0</td>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.43</td>\n",
       "      <td>19.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>27.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>0</td>\n",
       "      <td>Matchweek 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>39457.0</td>\n",
       "      <td>970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.50</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>1</td>\n",
       "      <td>Matchweek 5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>35652.0</td>\n",
       "      <td>749</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.7</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>22.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>32.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>76.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>251.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-23</th>\n",
       "      <td>1</td>\n",
       "      <td>Matchweek 6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40856.0</td>\n",
       "      <td>998</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.44</td>\n",
       "      <td>18.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-14</th>\n",
       "      <td>0</td>\n",
       "      <td>Matchweek 8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>39145.0</td>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>281.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-15</th>\n",
       "      <td>12</td>\n",
       "      <td>Matchweek 7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>30438.0</td>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>10652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-18</th>\n",
       "      <td>2</td>\n",
       "      <td>Matchweek 28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>30157.0</td>\n",
       "      <td>793</td>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>92</td>\n",
       "      <td>10653</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>71.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>34</td>\n",
       "      <td>Matchweek 30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>30963.0</td>\n",
       "      <td>793</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>112</td>\n",
       "      <td>10654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>521.0</td>\n",
       "      <td>2691.0</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-15</th>\n",
       "      <td>2</td>\n",
       "      <td>Matchweek 31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30309.0</td>\n",
       "      <td>793</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>121</td>\n",
       "      <td>10655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>59.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>251.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>35</td>\n",
       "      <td>Matchweek 33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30414.0</td>\n",
       "      <td>793</td>\n",
       "      <td>2</td>\n",
       "      <td>199</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>77</td>\n",
       "      <td>10656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>31.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10657 rows Ã— 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               schedule_time schedule_round  schedule_day  result_home  gf_home  gf_away  xg_home  \\\n",
       "schedule_date                                                                                       \n",
       "2017-08-19                 0    Matchweek 1             0            0      3.0      0.0      1.1   \n",
       "2017-09-09                 0    Matchweek 3             0            0      3.0      0.0      1.3   \n",
       "2017-09-20                 1    Matchweek 5             1            0      1.0      0.0      0.9   \n",
       "2017-09-23                 1    Matchweek 6             0            0      4.0      0.0      2.2   \n",
       "2017-10-14                 0    Matchweek 8             0            1      1.0      2.0      2.3   \n",
       "...                      ...            ...           ...          ...      ...      ...      ...   \n",
       "2023-03-15                12    Matchweek 7             1            1      0.0      2.0      0.5   \n",
       "2023-03-18                 2   Matchweek 28             0            2      3.0      3.0      2.4   \n",
       "2023-04-08                34   Matchweek 30             0            1      1.0      4.0      0.4   \n",
       "2023-04-15                 2   Matchweek 31             0            1      0.0      2.0      0.8   \n",
       "2023-04-27                35   Matchweek 33             6            1      0.0      1.0      0.5   \n",
       "\n",
       "               xg_away  attendance  captain_home  formation_home  referee  fbref_season  \\\n",
       "schedule_date                                                                             \n",
       "2017-08-19         1.4     39226.0           998               0        0             0   \n",
       "2017-09-09         0.6     39457.0           970               1        1             0   \n",
       "2017-09-20         0.4     35652.0           749               0        2             0   \n",
       "2017-09-23         0.2     40856.0           998               2        3             0   \n",
       "2017-10-14         1.6     39145.0           998               1        4             0   \n",
       "...                ...         ...           ...             ...      ...           ...   \n",
       "2023-03-15         1.9     30438.0           793               0      204             5   \n",
       "2023-03-18         2.3     30157.0           793               2      193             5   \n",
       "2023-04-08         2.9     30963.0           793               2      200             5   \n",
       "2023-04-15         0.9     30309.0           793               2      180             5   \n",
       "2023-04-27         0.9     30414.0           793               2      199             5   \n",
       "\n",
       "               fbref_league_id  fbref_home_id  fbref_away_id  fbref_match_id  \\\n",
       "schedule_date                                                                  \n",
       "2017-08-19                   0            132             76               0   \n",
       "2017-09-09                   0            132            133               1   \n",
       "2017-09-20                   0            132             39               2   \n",
       "2017-09-23                   0            132             26               3   \n",
       "2017-10-14                   0            132             49               4   \n",
       "...                        ...            ...            ...             ...   \n",
       "2023-03-15                   4             43             70           10652   \n",
       "2023-03-18                   4             43             92           10653   \n",
       "2023-04-08                   4             43            112           10654   \n",
       "2023-04-15                   4             43            121           10655   \n",
       "2023-04-27                   4             43             77           10656   \n",
       "\n",
       "               shooting_standard_gls_home  shooting_standard_sh_home  shooting_standard_sot_home  \\\n",
       "schedule_date                                                                                      \n",
       "2017-08-19                            3.0                       17.0                         7.0   \n",
       "2017-09-09                            2.0                       15.0                         4.0   \n",
       "2017-09-20                            1.0                       12.0                         5.0   \n",
       "2017-09-23                            4.0                       23.0                         9.0   \n",
       "2017-10-14                            1.0                       17.0                         5.0   \n",
       "...                                   ...                        ...                         ...   \n",
       "2023-03-15                            0.0                        7.0                         0.0   \n",
       "2023-03-18                            3.0                       18.0                         6.0   \n",
       "2023-04-08                            1.0                        4.0                         1.0   \n",
       "2023-04-15                            0.0                       11.0                         4.0   \n",
       "2023-04-27                            0.0                       11.0                         2.0   \n",
       "\n",
       "               shooting_standard_sot_perc_home  shooting_standard_g_per_sh_home  \\\n",
       "schedule_date                                                                     \n",
       "2017-08-19                                41.2                             0.18   \n",
       "2017-09-09                                26.7                             0.13   \n",
       "2017-09-20                                41.7                             0.08   \n",
       "2017-09-23                                39.1                             0.17   \n",
       "2017-10-14                                29.4                             0.06   \n",
       "...                                        ...                              ...   \n",
       "2023-03-15                                 0.0                             0.00   \n",
       "2023-03-18                                33.3                             0.11   \n",
       "2023-04-08                                25.0                             0.25   \n",
       "2023-04-15                                36.4                             0.00   \n",
       "2023-04-27                                18.2                             0.00   \n",
       "\n",
       "               shooting_standard_g_per_sot_home  shooting_standard_dist_home  \\\n",
       "schedule_date                                                                  \n",
       "2017-08-19                                 0.43                         19.8   \n",
       "2017-09-09                                 0.50                         17.5   \n",
       "2017-09-20                                 0.20                         22.6   \n",
       "2017-09-23                                 0.44                         18.2   \n",
       "2017-10-14                                 0.20                         21.6   \n",
       "...                                         ...                          ...   \n",
       "2023-03-15                                  NaN                         19.2   \n",
       "2023-03-18                                 0.33                         19.6   \n",
       "2023-04-08                                 1.00                         17.0   \n",
       "2023-04-15                                 0.00                         18.0   \n",
       "2023-04-27                                 0.00                         19.9   \n",
       "\n",
       "               shooting_standard_fk_home  shooting_standard_pk_home  shooting_standard_pkatt_home  \\\n",
       "schedule_date                                                                                       \n",
       "2017-08-19                           2.0                        0.0                           0.0   \n",
       "2017-09-09                           0.0                        0.0                           0.0   \n",
       "2017-09-20                           1.0                        0.0                           0.0   \n",
       "2017-09-23                           1.0                        0.0                           0.0   \n",
       "2017-10-14                           0.0                        0.0                           1.0   \n",
       "...                                  ...                        ...                           ...   \n",
       "2023-03-15                           1.0                        0.0                           0.0   \n",
       "2023-03-18                           1.0                        1.0                           1.0   \n",
       "2023-04-08                           0.0                        0.0                           0.0   \n",
       "2023-04-15                           0.0                        0.0                           0.0   \n",
       "2023-04-27                           0.0                        0.0                           0.0   \n",
       "\n",
       "               shooting_expected_npxg_home  shooting_expected_npxg_per_sh_home  \\\n",
       "schedule_date                                                                    \n",
       "2017-08-19                             1.1                                0.07   \n",
       "2017-09-09                             1.3                                0.08   \n",
       "2017-09-20                             0.9                                0.08   \n",
       "2017-09-23                             2.2                                0.10   \n",
       "2017-10-14                             1.5                                0.09   \n",
       "...                                    ...                                 ...   \n",
       "2023-03-15                             0.5                                0.07   \n",
       "2023-03-18                             1.6                                0.10   \n",
       "2023-04-08                             0.4                                0.10   \n",
       "2023-04-15                             0.8                                0.07   \n",
       "2023-04-27                             0.5                                0.05   \n",
       "\n",
       "               shooting_expected_g_minus_xg_home  shooting_expected_npg_minus_xg_home  \\\n",
       "schedule_date                                                                           \n",
       "2017-08-19                                   1.9                                  1.9   \n",
       "2017-09-09                                   0.7                                  0.7   \n",
       "2017-09-20                                   0.1                                  0.1   \n",
       "2017-09-23                                   1.8                                  1.8   \n",
       "2017-10-14                                  -1.3                                 -0.5   \n",
       "...                                          ...                                  ...   \n",
       "2023-03-15                                  -0.5                                 -0.5   \n",
       "2023-03-18                                   0.6                                  0.4   \n",
       "2023-04-08                                   0.6                                  0.6   \n",
       "2023-04-15                                  -0.8                                 -0.8   \n",
       "2023-04-27                                  -0.5                                 -0.5   \n",
       "\n",
       "               keeper_performance_sota_home  keeper_performance_saves_home  \\\n",
       "schedule_date                                                                \n",
       "2017-08-19                              2.0                            1.0   \n",
       "2017-09-09                              2.0                            2.0   \n",
       "2017-09-20                              0.0                            0.0   \n",
       "2017-09-23                              1.0                            1.0   \n",
       "2017-10-14                              5.0                            3.0   \n",
       "...                                     ...                            ...   \n",
       "2023-03-15                              4.0                            2.0   \n",
       "2023-03-18                              3.0                            0.0   \n",
       "2023-04-08                              8.0                            4.0   \n",
       "2023-04-15                              2.0                            0.0   \n",
       "2023-04-27                              2.0                            1.0   \n",
       "\n",
       "               keeper_performance_save_perc_home  keeper_performance_cs_home  \\\n",
       "schedule_date                                                                  \n",
       "2017-08-19                                 100.0                         1.0   \n",
       "2017-09-09                                 100.0                         1.0   \n",
       "2017-09-20                                   NaN                         1.0   \n",
       "2017-09-23                                 100.0                         1.0   \n",
       "2017-10-14                                  80.0                         0.0   \n",
       "...                                          ...                         ...   \n",
       "2023-03-15                                  50.0                         0.0   \n",
       "2023-03-18                                   0.0                         0.0   \n",
       "2023-04-08                                  62.5                         0.0   \n",
       "2023-04-15                                   0.0                         0.0   \n",
       "2023-04-27                                  50.0                         0.0   \n",
       "\n",
       "               keeper_performance_psxg_home  keeper_performance_psxg_plus_minus_home  \\\n",
       "schedule_date                                                                          \n",
       "2017-08-19                              1.0                                      1.0   \n",
       "2017-09-09                              0.5                                      0.5   \n",
       "2017-09-20                              0.0                                      0.0   \n",
       "2017-09-23                              0.0                                      0.0   \n",
       "2017-10-14                              2.5                                      0.5   \n",
       "...                                     ...                                      ...   \n",
       "2023-03-15                              1.9                                     -0.1   \n",
       "2023-03-18                              1.6                                     -1.4   \n",
       "2023-04-08                              2.7                                     -1.3   \n",
       "2023-04-15                              1.2                                     -0.8   \n",
       "2023-04-27                              0.5                                     -0.5   \n",
       "\n",
       "               keeper_penaltykicks_pkatt_home  keeper_penaltykicks_pka  \\\n",
       "schedule_date                                                            \n",
       "2017-08-19                                1.0                      0.0   \n",
       "2017-09-09                                0.0                      0.0   \n",
       "2017-09-20                                0.0                      0.0   \n",
       "2017-09-23                                0.0                      0.0   \n",
       "2017-10-14                                1.0                      1.0   \n",
       "...                                       ...                      ...   \n",
       "2023-03-15                                0.0                      0.0   \n",
       "2023-03-18                                0.0                      0.0   \n",
       "2023-04-08                                1.0                      1.0   \n",
       "2023-04-15                                0.0                      0.0   \n",
       "2023-04-27                                0.0                      0.0   \n",
       "\n",
       "               keeper_penaltykicks_pksv_home  keeper_penaltykicks_pkm_home  \\\n",
       "schedule_date                                                                \n",
       "2017-08-19                               1.0                           0.0   \n",
       "2017-09-09                               0.0                           0.0   \n",
       "2017-09-20                               0.0                           0.0   \n",
       "2017-09-23                               0.0                           0.0   \n",
       "2017-10-14                               0.0                           0.0   \n",
       "...                                      ...                           ...   \n",
       "2023-03-15                               0.0                           0.0   \n",
       "2023-03-18                               0.0                           0.0   \n",
       "2023-04-08                               0.0                           0.0   \n",
       "2023-04-15                               0.0                           0.0   \n",
       "2023-04-27                               0.0                           0.0   \n",
       "\n",
       "               keeper_launched_cmp_home  keeper_launched_att_home  keeper_launched_cmp_perc_home  \\\n",
       "schedule_date                                                                                      \n",
       "2017-08-19                          5.0                       8.0                           62.5   \n",
       "2017-09-09                         10.0                      16.0                           62.5   \n",
       "2017-09-20                          3.0                      10.0                           30.0   \n",
       "2017-09-23                          2.0                       3.0                           66.7   \n",
       "2017-10-14                          3.0                       5.0                           60.0   \n",
       "...                                 ...                       ...                            ...   \n",
       "2023-03-15                          4.0                      16.0                           25.0   \n",
       "2023-03-18                          2.0                      10.0                           20.0   \n",
       "2023-04-08                          5.0                      20.0                           25.0   \n",
       "2023-04-15                          3.0                       6.0                           50.0   \n",
       "2023-04-27                          1.0                      11.0                            9.1   \n",
       "\n",
       "               keeper_passes_att_home  keeper_passes_thr_home  keeper_passes_launch_perc_home  \\\n",
       "schedule_date                                                                                   \n",
       "2017-08-19                       29.0                     6.0                            24.1   \n",
       "2017-09-09                       27.0                     2.0                            29.6   \n",
       "2017-09-20                       22.0                     1.0                            31.8   \n",
       "2017-09-23                       20.0                     2.0                            15.0   \n",
       "2017-10-14                       23.0                     5.0                            17.4   \n",
       "...                               ...                     ...                             ...   \n",
       "2023-03-15                       38.0                     4.0                            34.2   \n",
       "2023-03-18                       15.0                     2.0                            40.0   \n",
       "2023-04-08                       42.0                     4.0                            45.2   \n",
       "2023-04-15                       26.0                     7.0                            15.4   \n",
       "2023-04-27                       38.0                     3.0                            23.7   \n",
       "\n",
       "               keeper_passes_avglen_home  keeper_goalkicks_att_home  \\\n",
       "schedule_date                                                         \n",
       "2017-08-19                          27.4                        4.0   \n",
       "2017-09-09                          33.7                       13.0   \n",
       "2017-09-20                          32.5                        9.0   \n",
       "2017-09-23                          28.9                        3.0   \n",
       "2017-10-14                          27.0                        3.0   \n",
       "...                                  ...                        ...   \n",
       "2023-03-15                          30.7                        5.0   \n",
       "2023-03-18                          35.1                        6.0   \n",
       "2023-04-08                          38.0                        3.0   \n",
       "2023-04-15                          26.8                        8.0   \n",
       "2023-04-27                          31.4                        8.0   \n",
       "\n",
       "               keeper_goalkicks_launch_perc_home  ...  defense_tackles_tkl_away  \\\n",
       "schedule_date                                     ...                             \n",
       "2017-08-19                                  25.0  ...                      17.0   \n",
       "2017-09-09                                  61.5  ...                      18.0   \n",
       "2017-09-20                                  33.3  ...                      12.0   \n",
       "2017-09-23                                   0.0  ...                      17.0   \n",
       "2017-10-14                                  33.3  ...                      11.0   \n",
       "...                                          ...  ...                       ...   \n",
       "2023-03-15                                  60.0  ...                      20.0   \n",
       "2023-03-18                                  66.7  ...                      19.0   \n",
       "2023-04-08                                  33.3  ...                       9.0   \n",
       "2023-04-15                                  25.0  ...                      22.0   \n",
       "2023-04-27                                  25.0  ...                      21.0   \n",
       "\n",
       "               defense_tackles_tklw_away  defense_tackles_def3rd_away  \\\n",
       "schedule_date                                                           \n",
       "2017-08-19                          15.0                          7.0   \n",
       "2017-09-09                          10.0                          8.0   \n",
       "2017-09-20                          10.0                          2.0   \n",
       "2017-09-23                          15.0                          8.0   \n",
       "2017-10-14                           6.0                          4.0   \n",
       "...                                  ...                          ...   \n",
       "2023-03-15                          11.0                          7.0   \n",
       "2023-03-18                          13.0                         11.0   \n",
       "2023-04-08                           7.0                          6.0   \n",
       "2023-04-15                          17.0                          9.0   \n",
       "2023-04-27                          12.0                          9.0   \n",
       "\n",
       "               defense_tackles_mid3rd_away  defense_tackles_att3rd_away  \\\n",
       "schedule_date                                                             \n",
       "2017-08-19                             9.0                          1.0   \n",
       "2017-09-09                             8.0                          2.0   \n",
       "2017-09-20                             7.0                          3.0   \n",
       "2017-09-23                             8.0                          1.0   \n",
       "2017-10-14                             6.0                          1.0   \n",
       "...                                    ...                          ...   \n",
       "2023-03-15                            11.0                          2.0   \n",
       "2023-03-18                             6.0                          2.0   \n",
       "2023-04-08                             3.0                          0.0   \n",
       "2023-04-15                            11.0                          2.0   \n",
       "2023-04-27                            11.0                          1.0   \n",
       "\n",
       "               defense_challenges_tkl_away  defense_challenges_att_away  \\\n",
       "schedule_date                                                             \n",
       "2017-08-19                             3.0                         19.0   \n",
       "2017-09-09                             4.0                         15.0   \n",
       "2017-09-20                             5.0                         15.0   \n",
       "2017-09-23                             7.0                         23.0   \n",
       "2017-10-14                             6.0                         25.0   \n",
       "...                                    ...                          ...   \n",
       "2023-03-15                             6.0                         18.0   \n",
       "2023-03-18                             8.0                         26.0   \n",
       "2023-04-08                             6.0                         19.0   \n",
       "2023-04-15                             8.0                         20.0   \n",
       "2023-04-27                             8.0                         25.0   \n",
       "\n",
       "               defense_challenges_tkl_perc_away  defense_challenges_lost_away  \\\n",
       "schedule_date                                                                   \n",
       "2017-08-19                                 15.8                          16.0   \n",
       "2017-09-09                                 26.7                          11.0   \n",
       "2017-09-20                                 33.3                          10.0   \n",
       "2017-09-23                                 30.4                          16.0   \n",
       "2017-10-14                                 24.0                          19.0   \n",
       "...                                         ...                           ...   \n",
       "2023-03-15                                 33.3                          12.0   \n",
       "2023-03-18                                 30.8                          18.0   \n",
       "2023-04-08                                 31.6                          13.0   \n",
       "2023-04-15                                 40.0                          12.0   \n",
       "2023-04-27                                 32.0                          17.0   \n",
       "\n",
       "               defense_blocks_blocks_away  defense_blocks_sh_away  defense_blocks_pass_away  \\\n",
       "schedule_date                                                                                 \n",
       "2017-08-19                           13.0                     5.0                       8.0   \n",
       "2017-09-09                           10.0                     4.0                       6.0   \n",
       "2017-09-20                           17.0                     5.0                      12.0   \n",
       "2017-09-23                           13.0                     4.0                       9.0   \n",
       "2017-10-14                           13.0                     7.0                       6.0   \n",
       "...                                   ...                     ...                       ...   \n",
       "2023-03-15                           18.0                     3.0                      15.0   \n",
       "2023-03-18                            7.0                     5.0                       2.0   \n",
       "2023-04-08                            8.0                     1.0                       7.0   \n",
       "2023-04-15                           12.0                     3.0                       9.0   \n",
       "2023-04-27                           12.0                     3.0                       9.0   \n",
       "\n",
       "               defense_general_int_away  defense_general_tkl_plus_int_away  \\\n",
       "schedule_date                                                                \n",
       "2017-08-19                          9.0                               26.0   \n",
       "2017-09-09                         15.0                               33.0   \n",
       "2017-09-20                         12.0                               24.0   \n",
       "2017-09-23                          7.0                               24.0   \n",
       "2017-10-14                         21.0                               32.0   \n",
       "...                                 ...                                ...   \n",
       "2023-03-15                         14.0                               34.0   \n",
       "2023-03-18                          9.0                               28.0   \n",
       "2023-04-08                          6.0                               15.0   \n",
       "2023-04-15                          8.0                               30.0   \n",
       "2023-04-27                          6.0                               27.0   \n",
       "\n",
       "               defense_general_clr_away  defense_general_err_away  possession_general_poss_away  \\\n",
       "schedule_date                                                                                     \n",
       "2017-08-19                         23.0                       0.0                          38.0   \n",
       "2017-09-09                         22.0                       0.0                          42.0   \n",
       "2017-09-20                         21.0                       0.0                          40.0   \n",
       "2017-09-23                         20.0                       2.0                          34.0   \n",
       "2017-10-14                         38.0                       0.0                          40.0   \n",
       "...                                 ...                       ...                           ...   \n",
       "2023-03-15                         26.0                       0.0                          34.0   \n",
       "2023-03-18                         21.0                       0.0                          49.0   \n",
       "2023-04-08                          4.0                       0.0                          73.0   \n",
       "2023-04-15                         19.0                       0.0                          42.0   \n",
       "2023-04-27                         35.0                       0.0                          43.0   \n",
       "\n",
       "               possession_touches_touches_away  possession_touches_defpen_away  \\\n",
       "schedule_date                                                                    \n",
       "2017-08-19                               538.0                            50.0   \n",
       "2017-09-09                               521.0                            60.0   \n",
       "2017-09-20                               532.0                            50.0   \n",
       "2017-09-23                               489.0                            89.0   \n",
       "2017-10-14                               559.0                            78.0   \n",
       "...                                        ...                             ...   \n",
       "2023-03-15                               447.0                            72.0   \n",
       "2023-03-18                               594.0                            80.0   \n",
       "2023-04-08                               833.0                            65.0   \n",
       "2023-04-15                               499.0                            67.0   \n",
       "2023-04-27                               566.0                            74.0   \n",
       "\n",
       "               possession_touches_def3rd_away  possession_touches_mid3rd_away  \\\n",
       "schedule_date                                                                   \n",
       "2017-08-19                              176.0                           265.0   \n",
       "2017-09-09                              148.0                           250.0   \n",
       "2017-09-20                              188.0                           251.0   \n",
       "2017-09-23                              211.0                           228.0   \n",
       "2017-10-14                              235.0                           251.0   \n",
       "...                                       ...                             ...   \n",
       "2023-03-15                              185.0                           179.0   \n",
       "2023-03-18                              246.0                           228.0   \n",
       "2023-04-08                              244.0                           432.0   \n",
       "2023-04-15                              199.0                           209.0   \n",
       "2023-04-27                              207.0                           239.0   \n",
       "\n",
       "               possession_touches_att3rd_away  possession_touches_attpen_away  \\\n",
       "schedule_date                                                                   \n",
       "2017-08-19                              104.0                            12.0   \n",
       "2017-09-09                              126.0                            13.0   \n",
       "2017-09-20                               96.0                             7.0   \n",
       "2017-09-23                               56.0                             6.0   \n",
       "2017-10-14                               81.0                            15.0   \n",
       "...                                       ...                             ...   \n",
       "2023-03-15                               92.0                            22.0   \n",
       "2023-03-18                              128.0                            17.0   \n",
       "2023-04-08                              161.0                            30.0   \n",
       "2023-04-15                               95.0                            17.0   \n",
       "2023-04-27                              132.0                            31.0   \n",
       "\n",
       "               possession_touches_live_away  possession_takeons_att_away  \\\n",
       "schedule_date                                                              \n",
       "2017-08-19                            537.0                         12.0   \n",
       "2017-09-09                            521.0                          2.0   \n",
       "2017-09-20                            532.0                         13.0   \n",
       "2017-09-23                            489.0                         19.0   \n",
       "2017-10-14                            558.0                         19.0   \n",
       "...                                     ...                          ...   \n",
       "2023-03-15                            447.0                         17.0   \n",
       "2023-03-18                            594.0                         14.0   \n",
       "2023-04-08                            832.0                         13.0   \n",
       "2023-04-15                            499.0                         22.0   \n",
       "2023-04-27                            566.0                         27.0   \n",
       "\n",
       "               possession_takeons_succ_away  possession_takeons_succ_perc_away  \\\n",
       "schedule_date                                                                    \n",
       "2017-08-19                             10.0                               83.3   \n",
       "2017-09-09                              1.0                               50.0   \n",
       "2017-09-20                             10.0                               76.9   \n",
       "2017-09-23                             13.0                               68.4   \n",
       "2017-10-14                              9.0                               47.4   \n",
       "...                                     ...                                ...   \n",
       "2023-03-15                             10.0                               58.8   \n",
       "2023-03-18                             10.0                               71.4   \n",
       "2023-04-08                              8.0                               61.5   \n",
       "2023-04-15                             13.0                               59.1   \n",
       "2023-04-27                             17.0                               63.0   \n",
       "\n",
       "               possession_takeons_tkld_away  possession_takeons_tkld_perc_away  \\\n",
       "schedule_date                                                                    \n",
       "2017-08-19                              2.0                               16.7   \n",
       "2017-09-09                              1.0                               50.0   \n",
       "2017-09-20                              3.0                               23.1   \n",
       "2017-09-23                              6.0                               31.6   \n",
       "2017-10-14                             10.0                               52.6   \n",
       "...                                     ...                                ...   \n",
       "2023-03-15                              7.0                               41.2   \n",
       "2023-03-18                              4.0                               28.6   \n",
       "2023-04-08                              4.0                               30.8   \n",
       "2023-04-15                              7.0                               31.8   \n",
       "2023-04-27                              9.0                               33.3   \n",
       "\n",
       "               possession_carries_carries_away  possession_carries_totdist_away  \\\n",
       "schedule_date                                                                     \n",
       "2017-08-19                               257.0                           1322.0   \n",
       "2017-09-09                               264.0                           1451.0   \n",
       "2017-09-20                               251.0                           1412.0   \n",
       "2017-09-23                               323.0                           1617.0   \n",
       "2017-10-14                               281.0                           1452.0   \n",
       "...                                        ...                              ...   \n",
       "2023-03-15                               178.0                            943.0   \n",
       "2023-03-18                               262.0                           1390.0   \n",
       "2023-04-08                               521.0                           2691.0   \n",
       "2023-04-15                               251.0                           1438.0   \n",
       "2023-04-27                               257.0                           1703.0   \n",
       "\n",
       "               possession_carries_prgdist_away  possession_carries_prgc_away  \\\n",
       "schedule_date                                                                  \n",
       "2017-08-19                               607.0                           9.0   \n",
       "2017-09-09                               696.0                          11.0   \n",
       "2017-09-20                               616.0                          12.0   \n",
       "2017-09-23                               768.0                          10.0   \n",
       "2017-10-14                               871.0                          12.0   \n",
       "...                                        ...                           ...   \n",
       "2023-03-15                               519.0                          11.0   \n",
       "2023-03-18                               768.0                          10.0   \n",
       "2023-04-08                              1294.0                          20.0   \n",
       "2023-04-15                               691.0                          11.0   \n",
       "2023-04-27                               749.0                          19.0   \n",
       "\n",
       "               possession_carries_1_per_3_away  possession_carries_cpa_away  \\\n",
       "schedule_date                                                                 \n",
       "2017-08-19                                 9.0                          1.0   \n",
       "2017-09-09                                 8.0                          1.0   \n",
       "2017-09-20                                 8.0                          2.0   \n",
       "2017-09-23                                 5.0                          2.0   \n",
       "2017-10-14                                 7.0                          4.0   \n",
       "...                                        ...                          ...   \n",
       "2023-03-15                                 6.0                          4.0   \n",
       "2023-03-18                                12.0                          3.0   \n",
       "2023-04-08                                18.0                          7.0   \n",
       "2023-04-15                                11.0                          3.0   \n",
       "2023-04-27                                17.0                          7.0   \n",
       "\n",
       "               possession_carries_mis_away  possession_carries_dis_away  \\\n",
       "schedule_date                                                             \n",
       "2017-08-19                            13.0                          6.0   \n",
       "2017-09-09                             5.0                         17.0   \n",
       "2017-09-20                            15.0                         13.0   \n",
       "2017-09-23                            19.0                         10.0   \n",
       "2017-10-14                            12.0                          6.0   \n",
       "...                                    ...                          ...   \n",
       "2023-03-15                            10.0                          9.0   \n",
       "2023-03-18                            16.0                          9.0   \n",
       "2023-04-08                             8.0                          7.0   \n",
       "2023-04-15                            14.0                          8.0   \n",
       "2023-04-27                            18.0                         10.0   \n",
       "\n",
       "               possession_receiving_rec_away  possession_receiving_prgr_away  \\\n",
       "schedule_date                                                                  \n",
       "2017-08-19                             341.0                            36.0   \n",
       "2017-09-09                             346.0                            40.0   \n",
       "2017-09-20                             345.0                            27.0   \n",
       "2017-09-23                             309.0                            19.0   \n",
       "2017-10-14                             345.0                            29.0   \n",
       "...                                      ...                             ...   \n",
       "2023-03-15                             204.0                            19.0   \n",
       "2023-03-18                             397.0                            33.0   \n",
       "2023-04-08                             666.0                            52.0   \n",
       "2023-04-15                             280.0                            25.0   \n",
       "2023-04-27                             326.0                            37.0   \n",
       "\n",
       "               misc_performance_crdy_away  misc_performance_crdr_away  \\\n",
       "schedule_date                                                           \n",
       "2017-08-19                            0.0                         0.0   \n",
       "2017-09-09                            1.0                         0.0   \n",
       "2017-09-20                            4.0                         1.0   \n",
       "2017-09-23                            4.0                         1.0   \n",
       "2017-10-14                            1.0                         0.0   \n",
       "...                                   ...                         ...   \n",
       "2023-03-15                            2.0                         0.0   \n",
       "2023-03-18                            1.0                         0.0   \n",
       "2023-04-08                            2.0                         0.0   \n",
       "2023-04-15                            1.0                         0.0   \n",
       "2023-04-27                            3.0                         0.0   \n",
       "\n",
       "               misc_performance_2crdy_away  misc_performance_fls_away  misc_performance_fld_away  \\\n",
       "schedule_date                                                                                      \n",
       "2017-08-19                             0.0                       11.0                       13.0   \n",
       "2017-09-09                             0.0                        7.0                       15.0   \n",
       "2017-09-20                             1.0                       23.0                       10.0   \n",
       "2017-09-23                             1.0                       12.0                       16.0   \n",
       "2017-10-14                             0.0                       14.0                        8.0   \n",
       "...                                    ...                        ...                        ...   \n",
       "2023-03-15                             0.0                       10.0                       14.0   \n",
       "2023-03-18                             0.0                        8.0                       12.0   \n",
       "2023-04-08                             0.0                       10.0                        6.0   \n",
       "2023-04-15                             0.0                       13.0                        6.0   \n",
       "2023-04-27                             0.0                       11.0                        7.0   \n",
       "\n",
       "               misc_performance_off_away  misc_performance_og_away  misc_performance_recov_away  \\\n",
       "schedule_date                                                                                     \n",
       "2017-08-19                           0.0                       0.0                         40.0   \n",
       "2017-09-09                           1.0                       1.0                         34.0   \n",
       "2017-09-20                           1.0                       0.0                         46.0   \n",
       "2017-09-23                           1.0                       0.0                         41.0   \n",
       "2017-10-14                           1.0                       0.0                         47.0   \n",
       "...                                  ...                       ...                          ...   \n",
       "2023-03-15                           1.0                       0.0                         51.0   \n",
       "2023-03-18                           1.0                       0.0                         48.0   \n",
       "2023-04-08                           2.0                       0.0                         45.0   \n",
       "2023-04-15                           1.0                       0.0                         53.0   \n",
       "2023-04-27                           2.0                       0.0                         60.0   \n",
       "\n",
       "               misc_aerialduels_won_away  misc_aerialduels_lost_away  \\\n",
       "schedule_date                                                          \n",
       "2017-08-19                           9.0                         8.0   \n",
       "2017-09-09                          10.0                        10.0   \n",
       "2017-09-20                           8.0                         9.0   \n",
       "2017-09-23                           6.0                        11.0   \n",
       "2017-10-14                          14.0                        12.0   \n",
       "...                                  ...                         ...   \n",
       "2023-03-15                          23.0                        17.0   \n",
       "2023-03-18                          14.0                        10.0   \n",
       "2023-04-08                          13.0                         7.0   \n",
       "2023-04-15                          14.0                        20.0   \n",
       "2023-04-27                          12.0                        10.0   \n",
       "\n",
       "               misc_aerialduels_won_perc_away  \n",
       "schedule_date                                  \n",
       "2017-08-19                               52.9  \n",
       "2017-09-09                               50.0  \n",
       "2017-09-20                               47.1  \n",
       "2017-09-23                               35.3  \n",
       "2017-10-14                               53.8  \n",
       "...                                       ...  \n",
       "2023-03-15                               57.5  \n",
       "2023-03-18                               58.3  \n",
       "2023-04-08                               65.0  \n",
       "2023-04-15                               41.2  \n",
       "2023-04-27                               54.5  \n",
       "\n",
       "[10657 rows x 295 columns]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "e281351e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/279171873.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    }
   ],
   "source": [
    "empty_df = pd.DataFrame(columns = list(new_data.dataset_team(0)), index = [0])\n",
    "\n",
    "for team in set(list(new_data1.fbref_home_id.unique()) + list(new_data1.fbref_away_id.unique())):\n",
    "    empty_df = pd.concat([new_data.dataset_team(team), empty_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "b14bd65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result                 1\n",
       "gf                   0.0\n",
       "xg                   0.8\n",
       "captain              580\n",
       "formation              1\n",
       "                   ...  \n",
       "fbref_league_id        4\n",
       "fbref_own            121\n",
       "fbref_oppon           99\n",
       "fbref_match_id     10534\n",
       "home                   0\n",
       "Name: 2023-04-25, Length: 152, dtype: object"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts2.loc[\"2023-04-25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e0c116e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>xg</th>\n",
       "      <th>captain</th>\n",
       "      <th>formation</th>\n",
       "      <th>shooting_standard_gls</th>\n",
       "      <th>shooting_standard_sh</th>\n",
       "      <th>shooting_standard_sot</th>\n",
       "      <th>shooting_standard_sot_perc</th>\n",
       "      <th>shooting_standard_g_per_sh</th>\n",
       "      <th>shooting_standard_g_per_sot</th>\n",
       "      <th>shooting_standard_dist</th>\n",
       "      <th>shooting_standard_fk</th>\n",
       "      <th>shooting_standard_pk</th>\n",
       "      <th>shooting_standard_pkatt</th>\n",
       "      <th>shooting_expected_npxg</th>\n",
       "      <th>shooting_expected_npxg_per_sh</th>\n",
       "      <th>shooting_expected_g_minus_xg</th>\n",
       "      <th>shooting_expected_npg_minus_xg</th>\n",
       "      <th>keeper_performance_sota</th>\n",
       "      <th>keeper_performance_saves</th>\n",
       "      <th>keeper_performance_save_perc</th>\n",
       "      <th>keeper_performance_cs</th>\n",
       "      <th>keeper_performance_psxg</th>\n",
       "      <th>keeper_performance_psxg_plus_minus</th>\n",
       "      <th>keeper_penaltykicks_pkatt</th>\n",
       "      <th>keeper_penaltykicks_pksv</th>\n",
       "      <th>keeper_penaltykicks_pkm</th>\n",
       "      <th>keeper_launched_cmp</th>\n",
       "      <th>keeper_launched_att</th>\n",
       "      <th>keeper_launched_cmp_perc</th>\n",
       "      <th>keeper_passes_att</th>\n",
       "      <th>keeper_passes_thr</th>\n",
       "      <th>keeper_passes_launch_perc</th>\n",
       "      <th>keeper_passes_avglen</th>\n",
       "      <th>keeper_goalkicks_att</th>\n",
       "      <th>keeper_goalkicks_launch_perc</th>\n",
       "      <th>keeper_goalkicks_avglen</th>\n",
       "      <th>keeper_crosses_opp</th>\n",
       "      <th>keeper_crosses_stp</th>\n",
       "      <th>keeper_crosses_stp_perc</th>\n",
       "      <th>keeper_sweeper_number_opa</th>\n",
       "      <th>keeper_sweeper_avgdist</th>\n",
       "      <th>passing_total_cmp</th>\n",
       "      <th>passing_total_att</th>\n",
       "      <th>passing_total_cmp_perc</th>\n",
       "      <th>passing_total_totdist</th>\n",
       "      <th>passing_total_prgdist</th>\n",
       "      <th>passing_short_cmp</th>\n",
       "      <th>passing_short_att</th>\n",
       "      <th>...</th>\n",
       "      <th>defense_blocks_sh</th>\n",
       "      <th>defense_blocks_pass</th>\n",
       "      <th>defense_general_int</th>\n",
       "      <th>defense_general_tkl_plus_int</th>\n",
       "      <th>defense_general_clr</th>\n",
       "      <th>defense_general_err</th>\n",
       "      <th>possession_general_poss</th>\n",
       "      <th>possession_touches_touches</th>\n",
       "      <th>possession_touches_defpen</th>\n",
       "      <th>possession_touches_def3rd</th>\n",
       "      <th>possession_touches_mid3rd</th>\n",
       "      <th>possession_touches_att3rd</th>\n",
       "      <th>possession_touches_attpen</th>\n",
       "      <th>possession_touches_live</th>\n",
       "      <th>possession_takeons_att</th>\n",
       "      <th>possession_takeons_succ</th>\n",
       "      <th>possession_takeons_succ_perc</th>\n",
       "      <th>possession_takeons_tkld</th>\n",
       "      <th>possession_takeons_tkld_perc</th>\n",
       "      <th>possession_carries_carries</th>\n",
       "      <th>possession_carries_totdist</th>\n",
       "      <th>possession_carries_prgdist</th>\n",
       "      <th>possession_carries_prgc</th>\n",
       "      <th>possession_carries_1_per_3</th>\n",
       "      <th>possession_carries_cpa</th>\n",
       "      <th>possession_carries_mis</th>\n",
       "      <th>possession_carries_dis</th>\n",
       "      <th>possession_receiving_rec</th>\n",
       "      <th>possession_receiving_prgr</th>\n",
       "      <th>misc_performance_crdy</th>\n",
       "      <th>misc_performance_crdr</th>\n",
       "      <th>misc_performance_2crdy</th>\n",
       "      <th>misc_performance_fls</th>\n",
       "      <th>misc_performance_fld</th>\n",
       "      <th>misc_performance_off</th>\n",
       "      <th>misc_performance_og</th>\n",
       "      <th>misc_performance_recov</th>\n",
       "      <th>misc_aerialduels_won</th>\n",
       "      <th>misc_aerialduels_lost</th>\n",
       "      <th>misc_aerialduels_won_perc</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>attendance</th>\n",
       "      <th>referee</th>\n",
       "      <th>fbref_season</th>\n",
       "      <th>fbref_league_id</th>\n",
       "      <th>fbref_own</th>\n",
       "      <th>fbref_oppon</th>\n",
       "      <th>fbref_match_id</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [result, gf, xg, captain, formation, shooting_standard_gls, shooting_standard_sh, shooting_standard_sot, shooting_standard_sot_perc, shooting_standard_g_per_sh, shooting_standard_g_per_sot, shooting_standard_dist, shooting_standard_fk, shooting_standard_pk, shooting_standard_pkatt, shooting_expected_npxg, shooting_expected_npxg_per_sh, shooting_expected_g_minus_xg, shooting_expected_npg_minus_xg, keeper_performance_sota, keeper_performance_saves, keeper_performance_save_perc, keeper_performance_cs, keeper_performance_psxg, keeper_performance_psxg_plus_minus, keeper_penaltykicks_pkatt, keeper_penaltykicks_pksv, keeper_penaltykicks_pkm, keeper_launched_cmp, keeper_launched_att, keeper_launched_cmp_perc, keeper_passes_att, keeper_passes_thr, keeper_passes_launch_perc, keeper_passes_avglen, keeper_goalkicks_att, keeper_goalkicks_launch_perc, keeper_goalkicks_avglen, keeper_crosses_opp, keeper_crosses_stp, keeper_crosses_stp_perc, keeper_sweeper_number_opa, keeper_sweeper_avgdist, passing_total_cmp, passing_total_att, passing_total_cmp_perc, passing_total_totdist, passing_total_prgdist, passing_short_cmp, passing_short_att, passing_short_cmp_perc, passing_medium_cmp, passing_medium_att, passing_medium_cmp_perc, passing_long_cmp, passing_long_att, passing_long_cmp_perc, passing_attacking_ast, passing_attacking_xag, passing_attacking_xa, passing_attacking_kp, passing_attacking_1_per_3, passing_attacking_ppa, passing_attacking_crspa, passing_attacking_prgp, passing_types_passtypes_live, passing_types_passtypes_dead, passing_types_passtypes_fk, passing_types_passtypes_tb, passing_types_passtypes_sw, passing_types_passtypes_crs, passing_types_passtypes_ti, passing_types_passtypes_ck, passing_types_cornerkicks_in, passing_types_cornerkicks_out, passing_types_cornerkicks_str, passing_types_outcomes_off, passing_types_outcomes_blocks, gca_scatypes_sca, gca_scatypes_passlive, gca_scatypes_passdead, gca_scatypes_to, gca_scatypes_sh, gca_scatypes_fld, gca_scatypes_def, gca_gcatypes_gca, gca_gcatypes_passlive, gca_gcatypes_passdead, gca_gcatypes_to, gca_gcatypes_sh, gca_gcatypes_fld, gca_gcatypes_def, defense_tackles_tkl, defense_tackles_tklw, defense_tackles_def3rd, defense_tackles_mid3rd, defense_tackles_att3rd, defense_challenges_tkl, defense_challenges_att, defense_challenges_tkl_perc, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 152 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts1#.loc[\"2022-08-13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "1ffc8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Alarm\n",
      "Alarm\n",
      "1\n",
      "Alarm\n",
      "Alarm\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Alarm\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Alarm\n",
      "16\n",
      "17\n",
      "18\n",
      "Alarm\n",
      "19\n",
      "Alarm\n",
      "20\n",
      "Alarm\n",
      "21\n",
      "Alarm\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Alarm\n",
      "Alarm\n",
      "26\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "27\n",
      "28\n",
      "29\n",
      "Alarm\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "Alarm\n",
      "35\n",
      "36\n",
      "Alarm\n",
      "37\n",
      "Alarm\n",
      "38\n",
      "Alarm\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "Alarm\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "Alarm\n",
      "47\n",
      "Alarm\n",
      "48\n",
      "49\n",
      "Alarm\n",
      "50\n",
      "Alarm\n",
      "51\n",
      "52\n",
      "53\n",
      "Alarm\n",
      "Alarm\n",
      "54\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "Alarm\n",
      "60\n",
      "61\n",
      "Alarm\n",
      "62\n",
      "63\n",
      "Alarm\n",
      "64\n",
      "65\n",
      "66\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "67\n",
      "68\n",
      "Alarm\n",
      "Alarm\n",
      "69\n",
      "70\n",
      "Alarm\n",
      "71\n",
      "72\n",
      "Alarm\n",
      "Alarm\n",
      "73\n",
      "74\n",
      "Alarm\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "Alarm\n",
      "Alarm\n",
      "82\n",
      "83\n",
      "Alarm\n",
      "84\n",
      "85\n",
      "86\n",
      "Alarm\n",
      "87\n",
      "88\n",
      "89\n",
      "Alarm\n",
      "90\n",
      "Alarm\n",
      "91\n",
      "92\n",
      "Alarm\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "Alarm\n",
      "97\n",
      "98\n",
      "Alarm\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "Alarm\n",
      "105\n",
      "Alarm\n",
      "Alarm\n",
      "106\n",
      "Alarm\n",
      "107\n",
      "Alarm\n",
      "108\n",
      "Alarm\n",
      "109\n",
      "110\n",
      "111\n",
      "Alarm\n",
      "Alarm\n",
      "112\n",
      "Alarm\n",
      "Alarm\n",
      "113\n",
      "Alarm\n",
      "114\n",
      "Alarm\n",
      "Alarm\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "Alarm\n",
      "119\n",
      "120\n",
      "Alarm\n",
      "121\n",
      "122\n",
      "Alarm\n",
      "123\n",
      "Alarm\n",
      "124\n",
      "125\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "Alarm\n",
      "130\n",
      "131\n",
      "Alarm\n",
      "132\n",
      "133\n",
      "Alarm\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "Alarm\n",
      "138\n",
      "139\n",
      "Alarm\n",
      "140\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "df = new_data.data_frame\n",
    "X = []\n",
    "y = []\n",
    "for team in set(list(empty_df.fbref_own.unique()) + list(empty_df.fbref_oppon.unique())):\n",
    "    for seas in empty_df.fbref_season.unique():\n",
    "        dts1 = empty_df[(empty_df.fbref_own == team) & (empty_df.fbref_season == seas)]\n",
    "        for i in range(len(dts1)):\n",
    "            i += 11\n",
    "            date11 = dts1.index[i - 11]\n",
    "            date12 = dts1.index[i - 1]\n",
    "            \n",
    "            dts2 = empty_df[(empty_df.fbref_own == dts1.iloc[i].fbref_oppon) & (empty_df.fbref_season == seas)]\n",
    "            date21 = dts2.index[i - 11]\n",
    "            date22 = dts2.index[i - 1]\n",
    "            \n",
    "            #if dts1.index[i] != dts2.index[i]:\n",
    "             #   print(dts1.iloc[i])\n",
    "              #  print(dts2.iloc[i])\n",
    "            if dts1.iloc[i].fbref_match_id != dts2.iloc[i].fbref_match_id:\n",
    "                print(\"Alarm\")\n",
    "            x = [np.array(dts1.loc[date11:date12]), np.array(dts2.loc[date21:date22])]\n",
    "            X.append(x)\n",
    "            y.append(dts1.iloc[i].result) \n",
    "            break\n",
    "            if i == len(dts1)-1:\n",
    "                break\n",
    "    print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "2910fa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-11-04'"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_df[(empty_df.fbref_own == team) & (empty_df.fbref_season == seas)].index[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "0f9afb8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '7c834541'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [462]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m X \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m z]\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m Y \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(x\u001b[38;5;241m.\u001b[39mlong(), num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y]\n",
      "Input \u001b[0;32mIn [462]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m X \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m z]\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m Y \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(x\u001b[38;5;241m.\u001b[39mlong(), num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y]\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '7c834541'"
     ]
    }
   ],
   "source": [
    "X = [torch.from_numpy(x.astype(float)) for z in X for x in z]\n",
    "y = [torch.from_numpy(Y.astype(float)) for Y in y]\n",
    "y = [torch.nn.functional.one_hot(x.long(), num_classes = 3) for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "295b9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_to_2lstm():\n",
    "\n",
    "    def __init__(self, mylist1, mylist2):\n",
    "        self.output =[]\n",
    "        \n",
    "        for i in range(len(mylist1)):\n",
    "            self.output.append((mylist1[i][0], mylist1[i][1], mylist2[i]))\n",
    "        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.output1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.output[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "9316d671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2a9c859d0>"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2lstm = data_to_2lstm(X,y)\n",
    "dataloader = DataLoader(dt2lstm, batch_size = 30,\n",
    "                        shuffle = False)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "6666bafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0.0, 0.4, ..., 140, '7c834541', 0],\n",
       "        [0, 1.0, 0.7, ..., 82, '37f97732', 1],\n",
       "        [2, 1.0, 1.3, ..., 105, 'abccb71c', 0],\n",
       "        ...,\n",
       "        [1, 2.0, 0.5, ..., 112, 'f81f42ed', 0],\n",
       "        [1, 1.0, 1.2, ..., 77, '7da1fc42', 1],\n",
       "        [0, 1.0, 1.1, ..., 135, '7834b95f', 0]], dtype=object),\n",
       " array([[0, 1.0, 0.6, ..., 0, '7c834541', 1],\n",
       "        [2, 1.0, 0.6, ..., 112, '424dc3f9', 0],\n",
       "        [1, 0.0, 0.4, ..., 79, '5a276f0b', 0],\n",
       "        ...,\n",
       "        [2, 1.0, 1.5, ..., 46, '1585521f', 0],\n",
       "        [1, 2.0, 1.0, ..., 82, '73da64ff', 1],\n",
       "        [1, 0.0, 0.6, ..., 13, 'f6cf8af5', 0]], dtype=object),\n",
       " 0)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2lstm.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "74585bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [440]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x1, x2, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, x1, y)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:170\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "for i, (x1, x2, y) in enumerate(dataloader):\n",
    "    print(i, x1, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "a0b895d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_28996/3597671105.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True).copy()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = {}\n",
    "y = []\n",
    "\n",
    "#set(list(df.fbref_away_id.unique()) + list(df.fbref_home_id.unique()))\n",
    "for team in set(list(df.fbref_away_id.unique()) + list(df.fbref_home_id.unique())):\n",
    "    data_team = new_data.dataset_team(team)\n",
    "    for seas in data_team.fbref_season.unique():\n",
    "        dts = data_team[data_team.fbref_season == seas]\n",
    "        for i in range(len(dts)):\n",
    "            string = str(team) + \"_\" + str(seas) + \"_\"\n",
    "            X.append(dts.iloc[i:i + 10])\n",
    "            y.append(dts.iloc[i + 10 + 1].result)\n",
    "            #print(dts.iloc[i:i+10].result)\n",
    "            if i + 10 + 1 == len(dts)-1:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27269c9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "86b94735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dts.iloc[0:4]\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(dts)):\n",
    "    X.append(dts.iloc[i:i + 10])\n",
    "    y.append(dts.iloc[i + 10 + 1])\n",
    "    #print(dts.iloc[i:i+10].result)\n",
    "    if i + 10 + 1 == len(dts)-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "13bc7b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>xg</th>\n",
       "      <th>captain</th>\n",
       "      <th>formation</th>\n",
       "      <th>shooting_standard_gls</th>\n",
       "      <th>shooting_standard_sh</th>\n",
       "      <th>shooting_standard_sot</th>\n",
       "      <th>shooting_standard_sot_perc</th>\n",
       "      <th>shooting_standard_g_per_sh</th>\n",
       "      <th>shooting_standard_g_per_sot</th>\n",
       "      <th>shooting_standard_dist</th>\n",
       "      <th>shooting_standard_fk</th>\n",
       "      <th>shooting_standard_pk</th>\n",
       "      <th>shooting_standard_pkatt</th>\n",
       "      <th>shooting_expected_npxg</th>\n",
       "      <th>shooting_expected_npxg_per_sh</th>\n",
       "      <th>shooting_expected_g_minus_xg</th>\n",
       "      <th>shooting_expected_npg_minus_xg</th>\n",
       "      <th>keeper_performance_sota</th>\n",
       "      <th>keeper_performance_saves</th>\n",
       "      <th>keeper_performance_save_perc</th>\n",
       "      <th>keeper_performance_cs</th>\n",
       "      <th>keeper_performance_psxg</th>\n",
       "      <th>keeper_performance_psxg_plus_minus</th>\n",
       "      <th>keeper_penaltykicks_pkatt</th>\n",
       "      <th>keeper_penaltykicks_pksv</th>\n",
       "      <th>keeper_penaltykicks_pkm</th>\n",
       "      <th>keeper_launched_cmp</th>\n",
       "      <th>keeper_launched_att</th>\n",
       "      <th>keeper_launched_cmp_perc</th>\n",
       "      <th>keeper_passes_att</th>\n",
       "      <th>keeper_passes_thr</th>\n",
       "      <th>keeper_passes_launch_perc</th>\n",
       "      <th>keeper_passes_avglen</th>\n",
       "      <th>keeper_goalkicks_att</th>\n",
       "      <th>keeper_goalkicks_launch_perc</th>\n",
       "      <th>keeper_goalkicks_avglen</th>\n",
       "      <th>keeper_crosses_opp</th>\n",
       "      <th>keeper_crosses_stp</th>\n",
       "      <th>keeper_crosses_stp_perc</th>\n",
       "      <th>keeper_sweeper_number_opa</th>\n",
       "      <th>keeper_sweeper_avgdist</th>\n",
       "      <th>passing_total_cmp</th>\n",
       "      <th>passing_total_att</th>\n",
       "      <th>passing_total_cmp_perc</th>\n",
       "      <th>passing_total_totdist</th>\n",
       "      <th>passing_total_prgdist</th>\n",
       "      <th>passing_short_cmp</th>\n",
       "      <th>passing_short_att</th>\n",
       "      <th>...</th>\n",
       "      <th>defense_blocks_sh</th>\n",
       "      <th>defense_blocks_pass</th>\n",
       "      <th>defense_general_int</th>\n",
       "      <th>defense_general_tkl_plus_int</th>\n",
       "      <th>defense_general_clr</th>\n",
       "      <th>defense_general_err</th>\n",
       "      <th>possession_general_poss</th>\n",
       "      <th>possession_touches_touches</th>\n",
       "      <th>possession_touches_defpen</th>\n",
       "      <th>possession_touches_def3rd</th>\n",
       "      <th>possession_touches_mid3rd</th>\n",
       "      <th>possession_touches_att3rd</th>\n",
       "      <th>possession_touches_attpen</th>\n",
       "      <th>possession_touches_live</th>\n",
       "      <th>possession_takeons_att</th>\n",
       "      <th>possession_takeons_succ</th>\n",
       "      <th>possession_takeons_succ_perc</th>\n",
       "      <th>possession_takeons_tkld</th>\n",
       "      <th>possession_takeons_tkld_perc</th>\n",
       "      <th>possession_carries_carries</th>\n",
       "      <th>possession_carries_totdist</th>\n",
       "      <th>possession_carries_prgdist</th>\n",
       "      <th>possession_carries_prgc</th>\n",
       "      <th>possession_carries_1_per_3</th>\n",
       "      <th>possession_carries_cpa</th>\n",
       "      <th>possession_carries_mis</th>\n",
       "      <th>possession_carries_dis</th>\n",
       "      <th>possession_receiving_rec</th>\n",
       "      <th>possession_receiving_prgr</th>\n",
       "      <th>misc_performance_crdy</th>\n",
       "      <th>misc_performance_crdr</th>\n",
       "      <th>misc_performance_2crdy</th>\n",
       "      <th>misc_performance_fls</th>\n",
       "      <th>misc_performance_fld</th>\n",
       "      <th>misc_performance_off</th>\n",
       "      <th>misc_performance_og</th>\n",
       "      <th>misc_performance_recov</th>\n",
       "      <th>misc_aerialduels_won</th>\n",
       "      <th>misc_aerialduels_lost</th>\n",
       "      <th>misc_aerialduels_won_perc</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>attendance</th>\n",
       "      <th>referee</th>\n",
       "      <th>fbref_season</th>\n",
       "      <th>fbref_league_id</th>\n",
       "      <th>fbref_own</th>\n",
       "      <th>fbref_oppon</th>\n",
       "      <th>fbref_match_id</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>556</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>39.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>55.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>233.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>4563.0</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>76.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>54.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39045.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>7c834541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>556</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>57.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.7</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>29459.0</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>37f97732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>556</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.50</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>47.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>83.7</td>\n",
       "      <td>7409.0</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.4</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>22704.0</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>abccb71c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.9</td>\n",
       "      <td>46.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>271.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>4876.0</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>81.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>29320.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>06ec2f77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>959</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>81.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>43.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>260.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>4637.0</td>\n",
       "      <td>2072.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>271.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>73509.0</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>113</td>\n",
       "      <td>e217ed2c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-15</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>928</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>38.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>323.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>5255.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>39241.0</td>\n",
       "      <td>188</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>107</td>\n",
       "      <td>ecae749b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>928</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>54.8</td>\n",
       "      <td>41.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>241.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>65.5</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>25202.0</td>\n",
       "      <td>203</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>121</td>\n",
       "      <td>25f6dcd1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>928</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>22.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3862.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>39248.0</td>\n",
       "      <td>186</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>138</td>\n",
       "      <td>37a741a7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>282.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>32173.0</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>13</td>\n",
       "      <td>95d2cc61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21315 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           result   gf   xg captain formation  shooting_standard_gls  shooting_standard_sh  \\\n",
       "0             NaN  NaN  NaN     NaN       NaN                    NaN                   NaN   \n",
       "2017-08-12      1  0.0  0.4     556         3                    0.0                   9.0   \n",
       "2017-08-19      0  1.0  0.7     556         3                    1.0                  11.0   \n",
       "2017-08-27      2  1.0  1.3     556         3                    1.0                  16.0   \n",
       "2017-09-09      2  2.0  1.2      72         3                    2.0                  10.0   \n",
       "...           ...  ...  ...     ...       ...                    ...                   ...   \n",
       "2023-04-08      1  0.0  1.0     959         2                    0.0                  15.0   \n",
       "2023-04-15      1  1.0  1.4     928         2                    1.0                  15.0   \n",
       "2023-04-22      2  0.0  0.4     928         0                    0.0                  10.0   \n",
       "2023-04-27      1  1.0  0.9     928         1                    1.0                  13.0   \n",
       "2023-05-01      2  2.0  3.1     959         0                    2.0                  22.0   \n",
       "\n",
       "            shooting_standard_sot  shooting_standard_sot_perc  shooting_standard_g_per_sh  \\\n",
       "0                             NaN                         NaN                         NaN   \n",
       "2017-08-12                    1.0                        11.1                        0.00   \n",
       "2017-08-19                    4.0                        36.4                        0.09   \n",
       "2017-08-27                    2.0                        12.5                        0.06   \n",
       "2017-09-09                    5.0                        50.0                        0.20   \n",
       "...                           ...                         ...                         ...   \n",
       "2023-04-08                    1.0                         6.7                        0.00   \n",
       "2023-04-15                    7.0                        46.7                        0.07   \n",
       "2023-04-22                    5.0                        50.0                        0.00   \n",
       "2023-04-27                    5.0                        38.5                        0.08   \n",
       "2023-05-01                    7.0                        31.8                        0.05   \n",
       "\n",
       "            shooting_standard_g_per_sot  shooting_standard_dist  shooting_standard_fk  \\\n",
       "0                                   NaN                     NaN                   NaN   \n",
       "2017-08-12                         0.00                    22.6                   0.0   \n",
       "2017-08-19                         0.25                    15.4                   0.0   \n",
       "2017-08-27                         0.50                    19.0                   0.0   \n",
       "2017-09-09                         0.40                    16.8                   0.0   \n",
       "...                                 ...                     ...                   ...   \n",
       "2023-04-08                         0.00                    18.0                   0.0   \n",
       "2023-04-15                         0.14                    17.1                   0.0   \n",
       "2023-04-22                         0.00                    22.4                   0.0   \n",
       "2023-04-27                         0.20                    22.3                   1.0   \n",
       "2023-05-01                         0.14                    14.9                   0.0   \n",
       "\n",
       "            shooting_standard_pk  shooting_standard_pkatt  shooting_expected_npxg  \\\n",
       "0                            NaN                      NaN                     NaN   \n",
       "2017-08-12                   NaN                      0.0                     0.4   \n",
       "2017-08-19                   0.0                      0.0                     0.7   \n",
       "2017-08-27                   NaN                      0.0                     1.3   \n",
       "2017-09-09                   0.0                      0.0                     1.2   \n",
       "...                          ...                      ...                     ...   \n",
       "2023-04-08                   NaN                      0.0                     1.0   \n",
       "2023-04-15                   0.0                      0.0                     1.4   \n",
       "2023-04-22                   NaN                      0.0                     0.4   \n",
       "2023-04-27                   0.0                      0.0                     0.9   \n",
       "2023-05-01                   NaN                      1.0                     2.3   \n",
       "\n",
       "            shooting_expected_npxg_per_sh  shooting_expected_g_minus_xg  \\\n",
       "0                                     NaN                           NaN   \n",
       "2017-08-12                           0.04                          -0.4   \n",
       "2017-08-19                           0.06                           0.3   \n",
       "2017-08-27                           0.08                          -0.3   \n",
       "2017-09-09                           0.12                           0.8   \n",
       "...                                   ...                           ...   \n",
       "2023-04-08                           0.07                          -1.0   \n",
       "2023-04-15                           0.10                          -0.4   \n",
       "2023-04-22                           0.04                          -0.4   \n",
       "2023-04-27                           0.07                           0.1   \n",
       "2023-05-01                           0.11                          -1.1   \n",
       "\n",
       "            shooting_expected_npg_minus_xg  keeper_performance_sota  keeper_performance_saves  \\\n",
       "0                                      NaN                      NaN                       NaN   \n",
       "2017-08-12                            -0.4                      4.0                       3.0   \n",
       "2017-08-19                             0.3                      6.0                       6.0   \n",
       "2017-08-27                            -0.3                      2.0                       1.0   \n",
       "2017-09-09                             0.8                      8.0                       6.0   \n",
       "...                                    ...                      ...                       ...   \n",
       "2023-04-08                            -1.0                     11.0                       9.0   \n",
       "2023-04-15                            -0.4                      7.0                       4.0   \n",
       "2023-04-22                            -0.4                      2.0                       2.0   \n",
       "2023-04-27                             0.1                      7.0                       3.0   \n",
       "2023-05-01                            -1.3                      5.0                       2.0   \n",
       "\n",
       "            keeper_performance_save_perc  keeper_performance_cs  keeper_performance_psxg  \\\n",
       "0                                    NaN                    NaN                      NaN   \n",
       "2017-08-12                          75.0                    0.0                      0.6   \n",
       "2017-08-19                         100.0                    1.0                      1.1   \n",
       "2017-08-27                          50.0                    0.0                      0.8   \n",
       "2017-09-09                          75.0                    0.0                      1.7   \n",
       "...                                  ...                    ...                      ...   \n",
       "2023-04-08                          81.8                    0.0                      2.2   \n",
       "2023-04-15                          57.1                    0.0                      2.6   \n",
       "2023-04-22                         100.0                    1.0                      0.4   \n",
       "2023-04-27                          42.9                    0.0                      3.7   \n",
       "2023-05-01                          60.0                    0.0                      2.3   \n",
       "\n",
       "            keeper_performance_psxg_plus_minus  keeper_penaltykicks_pkatt  \\\n",
       "0                                          NaN                        NaN   \n",
       "2017-08-12                                -0.4                        0.0   \n",
       "2017-08-19                                 1.1                        0.0   \n",
       "2017-08-27                                -0.2                        0.0   \n",
       "2017-09-09                                -0.3                        0.0   \n",
       "...                                        ...                        ...   \n",
       "2023-04-08                                 0.2                        0.0   \n",
       "2023-04-15                                -0.4                        0.0   \n",
       "2023-04-22                                 0.4                        0.0   \n",
       "2023-04-27                                -0.3                        0.0   \n",
       "2023-05-01                                 0.3                        1.0   \n",
       "\n",
       "            keeper_penaltykicks_pksv  keeper_penaltykicks_pkm  keeper_launched_cmp  \\\n",
       "0                                NaN                      NaN                  NaN   \n",
       "2017-08-12                       0.0                      0.0                 10.0   \n",
       "2017-08-19                       0.0                      0.0                 15.0   \n",
       "2017-08-27                       0.0                      0.0                  1.0   \n",
       "2017-09-09                       0.0                      0.0                 10.0   \n",
       "...                              ...                      ...                  ...   \n",
       "2023-04-08                       0.0                      0.0                 11.0   \n",
       "2023-04-15                       0.0                      0.0                  2.0   \n",
       "2023-04-22                       0.0                      0.0                  6.0   \n",
       "2023-04-27                       0.0                      0.0                  5.0   \n",
       "2023-05-01                       1.0                      0.0                 13.0   \n",
       "\n",
       "            keeper_launched_att  keeper_launched_cmp_perc  keeper_passes_att  keeper_passes_thr  \\\n",
       "0                           NaN                       NaN                NaN                NaN   \n",
       "2017-08-12                 18.0                      55.6               21.0                4.0   \n",
       "2017-08-19                 37.0                      40.5               30.0                3.0   \n",
       "2017-08-27                 13.0                       7.7               24.0                6.0   \n",
       "2017-09-09                 29.0                      34.5               29.0                3.0   \n",
       "...                         ...                       ...                ...                ...   \n",
       "2023-04-08                 25.0                      44.0               30.0                5.0   \n",
       "2023-04-15                 21.0                       9.5               30.0                3.0   \n",
       "2023-04-22                 23.0                      26.1               31.0                8.0   \n",
       "2023-04-27                 24.0                      20.8               18.0                1.0   \n",
       "2023-05-01                 29.0                      44.8               35.0                3.0   \n",
       "\n",
       "            keeper_passes_launch_perc  keeper_passes_avglen  keeper_goalkicks_att  \\\n",
       "0                                 NaN                   NaN                   NaN   \n",
       "2017-08-12                       57.1                  39.5                   8.0   \n",
       "2017-08-19                       83.3                  57.1                  12.0   \n",
       "2017-08-27                       37.5                  34.5                   7.0   \n",
       "2017-09-09                       75.9                  46.3                   7.0   \n",
       "...                               ...                   ...                   ...   \n",
       "2023-04-08                       60.0                  44.0                  10.0   \n",
       "2023-04-15                       60.0                  42.8                   8.0   \n",
       "2023-04-22                       54.8                  41.9                   8.0   \n",
       "2023-04-27                       88.9                  61.9                   8.0   \n",
       "2023-05-01                       77.1                  48.8                   5.0   \n",
       "\n",
       "            keeper_goalkicks_launch_perc  keeper_goalkicks_avglen  keeper_crosses_opp  \\\n",
       "0                                    NaN                      NaN                 NaN   \n",
       "2017-08-12                          75.0                     55.1                13.0   \n",
       "2017-08-19                         100.0                     64.1                20.0   \n",
       "2017-08-27                          57.1                     47.6                25.0   \n",
       "2017-09-09                         100.0                     69.3                16.0   \n",
       "...                                  ...                      ...                 ...   \n",
       "2023-04-08                          70.0                     43.4                 8.0   \n",
       "2023-04-15                          37.5                     38.6                17.0   \n",
       "2023-04-22                          75.0                     62.1                19.0   \n",
       "2023-04-27                         100.0                     66.9                18.0   \n",
       "2023-05-01                          40.0                     40.0                 8.0   \n",
       "\n",
       "            keeper_crosses_stp  keeper_crosses_stp_perc  keeper_sweeper_number_opa  \\\n",
       "0                          NaN                      NaN                        NaN   \n",
       "2017-08-12                 0.0                      0.0                        1.0   \n",
       "2017-08-19                 1.0                      5.0                        2.0   \n",
       "2017-08-27                 3.0                     12.0                        0.0   \n",
       "2017-09-09                 0.0                      0.0                        1.0   \n",
       "...                        ...                      ...                        ...   \n",
       "2023-04-08                 1.0                     12.5                        2.0   \n",
       "2023-04-15                 3.0                     17.6                        4.0   \n",
       "2023-04-22                 1.0                      5.3                        3.0   \n",
       "2023-04-27                 1.0                      5.6                        3.0   \n",
       "2023-05-01                 1.0                     12.5                        3.0   \n",
       "\n",
       "            keeper_sweeper_avgdist  passing_total_cmp  passing_total_att  passing_total_cmp_perc  \\\n",
       "0                              NaN                NaN                NaN                     NaN   \n",
       "2017-08-12                    14.5              233.0              356.0                    65.4   \n",
       "2017-08-19                    11.4              151.0              243.0                    62.1   \n",
       "2017-08-27                     9.0              406.0              485.0                    83.7   \n",
       "2017-09-09                    14.4              271.0              363.0                    74.7   \n",
       "...                            ...                ...                ...                     ...   \n",
       "2023-04-08                    15.5              260.0              373.0                    69.7   \n",
       "2023-04-15                    16.7              323.0              450.0                    71.8   \n",
       "2023-04-22                    23.5              241.0              368.0                    65.5   \n",
       "2023-04-27                    21.0              213.0              338.0                    63.0   \n",
       "2023-05-01                    20.5              282.0              416.0                    67.8   \n",
       "\n",
       "            passing_total_totdist  passing_total_prgdist  passing_short_cmp  passing_short_att  \\\n",
       "0                             NaN                    NaN                NaN                NaN   \n",
       "2017-08-12                 4563.0                 2068.0               97.0              114.0   \n",
       "2017-08-19                 3390.0                 1900.0               63.0               80.0   \n",
       "2017-08-27                 7409.0                 2562.0              190.0              209.0   \n",
       "2017-09-09                 4876.0                 2118.0              135.0              147.0   \n",
       "...                           ...                    ...                ...                ...   \n",
       "2023-04-08                 4637.0                 2072.0              117.0              153.0   \n",
       "2023-04-15                 5255.0                 1962.0              157.0              182.0   \n",
       "2023-04-22                 4257.0                 1903.0              124.0              149.0   \n",
       "2023-04-27                 3862.0                 1431.0               90.0              118.0   \n",
       "2023-05-01                 5000.0                 2385.0              131.0              157.0   \n",
       "\n",
       "            ...  defense_blocks_sh  defense_blocks_pass  defense_general_int  \\\n",
       "0           ...                NaN                  NaN                  NaN   \n",
       "2017-08-12  ...                2.0                  8.0                 24.0   \n",
       "2017-08-19  ...                6.0                  8.0                  8.0   \n",
       "2017-08-27  ...                0.0                  5.0                  7.0   \n",
       "2017-09-09  ...                4.0                  8.0                  7.0   \n",
       "...         ...                ...                  ...                  ...   \n",
       "2023-04-08  ...                8.0                  7.0                  6.0   \n",
       "2023-04-15  ...                5.0                 13.0                  7.0   \n",
       "2023-04-22  ...                5.0                  6.0                 12.0   \n",
       "2023-04-27  ...                5.0                 17.0                 17.0   \n",
       "2023-05-01  ...                6.0                  6.0                 11.0   \n",
       "\n",
       "            defense_general_tkl_plus_int  defense_general_clr  defense_general_err  \\\n",
       "0                                    NaN                  NaN                  NaN   \n",
       "2017-08-12                          42.0                 26.0                  1.0   \n",
       "2017-08-19                          27.0                 37.0                  1.0   \n",
       "2017-08-27                          27.0                 45.0                  0.0   \n",
       "2017-09-09                          26.0                 31.0                  0.0   \n",
       "...                                  ...                  ...                  ...   \n",
       "2023-04-08                          36.0                 14.0                  3.0   \n",
       "2023-04-15                          21.0                 15.0                  0.0   \n",
       "2023-04-22                          26.0                 26.0                  0.0   \n",
       "2023-04-27                          35.0                 26.0                  0.0   \n",
       "2023-05-01                          26.0                 19.0                  0.0   \n",
       "\n",
       "            possession_general_poss  possession_touches_touches  possession_touches_defpen  \\\n",
       "0                               NaN                         NaN                        NaN   \n",
       "2017-08-12                     40.0                       473.0                       49.0   \n",
       "2017-08-19                     24.0                       356.0                       85.0   \n",
       "2017-08-27                     57.0                       616.0                       57.0   \n",
       "2017-09-09                     37.0                       467.0                       62.0   \n",
       "...                             ...                         ...                        ...   \n",
       "2023-04-08                     37.0                       480.0                       80.0   \n",
       "2023-04-15                     46.0                       554.0                       69.0   \n",
       "2023-04-22                     44.0                       497.0                       64.0   \n",
       "2023-04-27                     40.0                       470.0                       56.0   \n",
       "2023-05-01                     46.0                       542.0                       54.0   \n",
       "\n",
       "            possession_touches_def3rd  possession_touches_mid3rd  possession_touches_att3rd  \\\n",
       "0                                 NaN                        NaN                        NaN   \n",
       "2017-08-12                      154.0                      192.0                      135.0   \n",
       "2017-08-19                      168.0                      132.0                       66.0   \n",
       "2017-08-27                      162.0                      282.0                      178.0   \n",
       "2017-09-09                      155.0                      237.0                       81.0   \n",
       "...                               ...                        ...                        ...   \n",
       "2023-04-08                      157.0                      201.0                      125.0   \n",
       "2023-04-15                      163.0                      267.0                      133.0   \n",
       "2023-04-22                      186.0                      192.0                      124.0   \n",
       "2023-04-27                      141.0                      234.0                      109.0   \n",
       "2023-05-01                      152.0                      210.0                      187.0   \n",
       "\n",
       "            possession_touches_attpen  possession_touches_live  possession_takeons_att  \\\n",
       "0                                 NaN                      NaN                     NaN   \n",
       "2017-08-12                       16.0                    473.0                    13.0   \n",
       "2017-08-19                       10.0                    356.0                    12.0   \n",
       "2017-08-27                       23.0                    616.0                    19.0   \n",
       "2017-09-09                       14.0                    467.0                    11.0   \n",
       "...                               ...                      ...                     ...   \n",
       "2023-04-08                       16.0                    480.0                    16.0   \n",
       "2023-04-15                       16.0                    554.0                    19.0   \n",
       "2023-04-22                       14.0                    497.0                    20.0   \n",
       "2023-04-27                       15.0                    469.0                    20.0   \n",
       "2023-05-01                       31.0                    541.0                    20.0   \n",
       "\n",
       "            possession_takeons_succ  possession_takeons_succ_perc  possession_takeons_tkld  \\\n",
       "0                               NaN                           NaN                      NaN   \n",
       "2017-08-12                     10.0                          76.9                      3.0   \n",
       "2017-08-19                      7.0                          58.3                      5.0   \n",
       "2017-08-27                     10.0                          52.6                      9.0   \n",
       "2017-09-09                      9.0                          81.8                      2.0   \n",
       "...                             ...                           ...                      ...   \n",
       "2023-04-08                      8.0                          50.0                      6.0   \n",
       "2023-04-15                     13.0                          68.4                      5.0   \n",
       "2023-04-22                      7.0                          35.0                     11.0   \n",
       "2023-04-27                     13.0                          65.0                      6.0   \n",
       "2023-05-01                     10.0                          50.0                      9.0   \n",
       "\n",
       "            possession_takeons_tkld_perc  possession_carries_carries  possession_carries_totdist  \\\n",
       "0                                    NaN                         NaN                         NaN   \n",
       "2017-08-12                          23.1                       190.0                      1434.0   \n",
       "2017-08-19                          41.7                       141.0                      1117.0   \n",
       "2017-08-27                          47.4                       322.0                      1876.0   \n",
       "2017-09-09                          18.2                       265.0                      1502.0   \n",
       "...                                  ...                         ...                         ...   \n",
       "2023-04-08                          37.5                       271.0                      1306.0   \n",
       "2023-04-15                          26.3                       345.0                      1874.0   \n",
       "2023-04-22                          55.0                       203.0                      1181.0   \n",
       "2023-04-27                          30.0                       222.0                      1379.0   \n",
       "2023-05-01                          45.0                       272.0                      1522.0   \n",
       "\n",
       "            possession_carries_prgdist  possession_carries_prgc  possession_carries_1_per_3  \\\n",
       "0                                  NaN                      NaN                         NaN   \n",
       "2017-08-12                       729.0                     12.0                        10.0   \n",
       "2017-08-19                       524.0                      8.0                         8.0   \n",
       "2017-08-27                      1102.0                     21.0                        15.0   \n",
       "2017-09-09                       798.0                     15.0                         7.0   \n",
       "...                                ...                      ...                         ...   \n",
       "2023-04-08                       660.0                     15.0                         9.0   \n",
       "2023-04-15                       923.0                     17.0                         9.0   \n",
       "2023-04-22                       537.0                      4.0                         6.0   \n",
       "2023-04-27                       665.0                     10.0                        11.0   \n",
       "2023-05-01                       796.0                     17.0                        17.0   \n",
       "\n",
       "            possession_carries_cpa  possession_carries_mis  possession_carries_dis  \\\n",
       "0                              NaN                     NaN                     NaN   \n",
       "2017-08-12                     5.0                    17.0                    14.0   \n",
       "2017-08-19                     3.0                    10.0                    10.0   \n",
       "2017-08-27                     3.0                    18.0                     8.0   \n",
       "2017-09-09                     5.0                    14.0                     7.0   \n",
       "...                            ...                     ...                     ...   \n",
       "2023-04-08                     3.0                    11.0                     4.0   \n",
       "2023-04-15                     3.0                    17.0                    12.0   \n",
       "2023-04-22                     0.0                    15.0                     4.0   \n",
       "2023-04-27                     1.0                    17.0                     8.0   \n",
       "2023-05-01                     5.0                    16.0                    10.0   \n",
       "\n",
       "            possession_receiving_rec  possession_receiving_prgr  misc_performance_crdy  \\\n",
       "0                                NaN                        NaN                    NaN   \n",
       "2017-08-12                     227.0                       33.0                    1.0   \n",
       "2017-08-19                     146.0                       16.0                    0.0   \n",
       "2017-08-27                     403.0                       54.0                    2.0   \n",
       "2017-09-09                     269.0                       29.0                    0.0   \n",
       "...                              ...                        ...                    ...   \n",
       "2023-04-08                     255.0                       30.0                    0.0   \n",
       "2023-04-15                     321.0                       40.0                    3.0   \n",
       "2023-04-22                     239.0                       24.0                    3.0   \n",
       "2023-04-27                     211.0                       28.0                    2.0   \n",
       "2023-05-01                     278.0                       34.0                    1.0   \n",
       "\n",
       "            misc_performance_crdr  misc_performance_2crdy  misc_performance_fls  \\\n",
       "0                             NaN                     NaN                   NaN   \n",
       "2017-08-12                    0.0                     0.0                  10.0   \n",
       "2017-08-19                    0.0                     0.0                   6.0   \n",
       "2017-08-27                    0.0                     0.0                   9.0   \n",
       "2017-09-09                    0.0                     0.0                  10.0   \n",
       "...                           ...                     ...                   ...   \n",
       "2023-04-08                    0.0                     0.0                   9.0   \n",
       "2023-04-15                    0.0                     0.0                  10.0   \n",
       "2023-04-22                    1.0                     1.0                  14.0   \n",
       "2023-04-27                    0.0                     0.0                   8.0   \n",
       "2023-05-01                    0.0                     0.0                  12.0   \n",
       "\n",
       "            misc_performance_fld  misc_performance_off  misc_performance_og  \\\n",
       "0                            NaN                   NaN                  NaN   \n",
       "2017-08-12                  13.0                   6.0                  0.0   \n",
       "2017-08-19                  11.0                   4.0                  0.0   \n",
       "2017-08-27                  10.0                   0.0                  0.0   \n",
       "2017-09-09                  10.0                   1.0                  0.0   \n",
       "...                          ...                   ...                  ...   \n",
       "2023-04-08                  10.0                   2.0                  0.0   \n",
       "2023-04-15                   6.0                   1.0                  0.0   \n",
       "2023-04-22                  12.0                   3.0                  0.0   \n",
       "2023-04-27                   6.0                   3.0                  0.0   \n",
       "2023-05-01                   9.0                   3.0                  0.0   \n",
       "\n",
       "            misc_performance_recov  misc_aerialduels_won  misc_aerialduels_lost  \\\n",
       "0                              NaN                   NaN                    NaN   \n",
       "2017-08-12                    38.0                  23.0                   19.0   \n",
       "2017-08-19                    38.0                  17.0                    9.0   \n",
       "2017-08-27                    26.0                  28.0                   12.0   \n",
       "2017-09-09                    38.0                  13.0                   16.0   \n",
       "...                            ...                   ...                    ...   \n",
       "2023-04-08                    51.0                  14.0                   14.0   \n",
       "2023-04-15                    63.0                  21.0                   21.0   \n",
       "2023-04-22                    58.0                  35.0                   26.0   \n",
       "2023-04-27                    67.0                  11.0                    9.0   \n",
       "2023-05-01                    62.0                  33.0                   30.0   \n",
       "\n",
       "            misc_aerialduels_won_perc  keeper_penaltykicks_pka  schedule_time  attendance  \\\n",
       "0                                 NaN                      NaN            NaN         NaN   \n",
       "2017-08-12                       54.8                      0.0              2     39045.0   \n",
       "2017-08-19                       65.4                      NaN             34     29459.0   \n",
       "2017-08-27                       70.0                      0.0             13     22704.0   \n",
       "2017-09-09                       44.8                      NaN             34     29320.0   \n",
       "...                               ...                      ...            ...         ...   \n",
       "2023-04-08                       50.0                      0.0              3     73509.0   \n",
       "2023-04-15                       50.0                      NaN              2     39241.0   \n",
       "2023-04-22                       57.4                      0.0              2     25202.0   \n",
       "2023-04-27                       55.0                      NaN             35     39248.0   \n",
       "2023-05-01                       52.4                      0.0             27     32173.0   \n",
       "\n",
       "            referee  fbref_season  fbref_league_id  fbref_own  fbref_oppon  fbref_match_id  home  \n",
       "0               NaN           NaN              NaN        NaN          NaN             NaN   NaN  \n",
       "2017-08-12      177             0                4          0          140        7c834541     0  \n",
       "2017-08-19      186             0                4          0           82        37f97732     1  \n",
       "2017-08-27      188             0                4          0          105        abccb71c     0  \n",
       "2017-09-09      177             0                4          0          113        06ec2f77     1  \n",
       "...             ...           ...              ...        ...          ...             ...   ...  \n",
       "2023-04-08      180             5                4        140          113        e217ed2c     0  \n",
       "2023-04-15      188             5                4        140          107        ecae749b     1  \n",
       "2023-04-22      203             5                4        140          121        25f6dcd1     0  \n",
       "2023-04-27      186             5                4        140          138        37a741a7     1  \n",
       "2023-05-01      180             5                4        140           13        95d2cc61     0  \n",
       "\n",
       "[21315 rows x 152 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "478c6c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0.0, 0.4, ..., 140, '7c834541', 0],\n",
       "       [0, 1.0, 0.7, ..., 82, '37f97732', 1],\n",
       "       [2, 1.0, 1.3, ..., 105, 'abccb71c', 0],\n",
       "       ...,\n",
       "       [1, 2.0, 0.5, ..., 112, 'f81f42ed', 0],\n",
       "       [1, 1.0, 1.2, ..., 77, '7da1fc42', 1],\n",
       "       [0, 1.0, 1.1, ..., 135, '7834b95f', 0]], dtype=object)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X[0])\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "78eab5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sport_pred_2LSTM(torch.nn.Module):\n",
    "    def __init__(self,n_features, hidden, num_classes):\n",
    "        super(Sport_pred_LSTM, self).__init__()\n",
    "        self.n_features = n_features \n",
    "        self.num_classes = num_classes # number of classes (win, draw, lose)\n",
    "        self.n_hidden = hidden # number of hidden states\n",
    "        self.n_layers = 2 # number of LSTM layers (stacked)\n",
    "        \n",
    "        # two separate lstms to account for every teams history\n",
    "        self.l_lstm1 = torch.nn.LSTM(input_size = n_features, \n",
    "                             hidden_size = self.n_hidden,\n",
    "                             num_layers = self.n_layers)\n",
    "        \n",
    "        self.l_lstm2 = torch.nn.LSTM(input_size = n_features, \n",
    "                             hidden_size = self.n_hidden,\n",
    "                             num_layers = self.n_layers)\n",
    "\n",
    "        # classic neural net to process outcomes\n",
    "        self.l_linear1 = torch.nn.Linear(self.n_hidden, self.n_hidden * 0.5)\n",
    "        self.l_linear2 = torch.nn.Linear(self.n_hidden * 0.5, self.n_hidden * 0.5)\n",
    "        self.l_linear3 = torch.nn.Linear(self.n_hidden * 0.5, num_classes)\n",
    "        \n",
    "        self.soft = torch.nn.Softmax(dim = 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # convert input to fit the model\n",
    "        x = x.to(torch.float32)\n",
    "        x = torch.nan_to_num(x, nan = 0.0)\n",
    "        y = y.to(torch.float32)\n",
    "        y = torch.nan_to_num(y, nan = 0.0)    \n",
    "        \n",
    "        \n",
    "        # initialize values for two lstms\n",
    "        h01 = torch.randn(self.n_layers*1, self.n_hidden).to(x.dtype)\n",
    "        h02 = torch.randn(self.n_layers*1, self.n_hidden).to(y.dtype)\n",
    "        c01 = torch.randn(self.n_layers*1, self.n_hidden).to(x.dtype)\n",
    "        c02 = torch.randn(self.n_layers*1, self.n_hidden).to(y.dtype)\n",
    "        \n",
    "        \n",
    "        # run data through lstm and yield output\n",
    "        lstm_out1,_ = self.l_lstm1(x,(h01, c01))\n",
    "        lstm_out2,_ = self.l_lstm2(x,(h02, c02))\n",
    "        x = lstm_out1.contiguous().view(-1, self.n_hidden)\n",
    "        y = lstm_out1.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        # run lstm output through nn to predict outcome\n",
    "        in_lay1 = torch.cat((x, y), 1)\n",
    "        out_lay1 = self.l_linear1(in_lay1)\n",
    "        in_lay2 = self.relu(out_lay1)\n",
    "        out_lay2 = self.l_linear2(in_lay2)\n",
    "        in_lay3 = self.relu(out_lay3)\n",
    "        out = self.soft(self.l_linear3(in_lay3))\n",
    "        \n",
    "        #print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f09c67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sport_pred_standard_nn(torch.nn.Module):\n",
    "    def __init__(self,n_features, hidden, num_classes):\n",
    "        super(Sport_pred_LSTM, self).__init__()\n",
    "        self.n_features = n_features \n",
    "        self.num_classes = num_classes # number of classes (win, draw, lose)\n",
    "        self.n_hidden = hidden # number of hidden states\n",
    "\n",
    "        # classic neural net to process outcomes\n",
    "        self.l_linear1 = torch.nn.Linear(self.n_features * 2, self.n_hidden * 2)\n",
    "        self.l_linear2 = torch.nn.Linear(self.n_hidden * 2, self.n_hidden * 0.5)\n",
    "        self.l_linear3 = torch.nn.Linear(self.n_hidden * 0.5, num_classes)\n",
    "        \n",
    "        self.soft = torch.nn.Softmax(dim = 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # convert input to fit the model\n",
    "        x = x.to(torch.float32)\n",
    "        x = torch.nan_to_num(x, nan = 0.0)\n",
    "        y = y.to(torch.float32)\n",
    "        y = torch.nan_to_num(y, nan = 0.0)    \n",
    "        \n",
    "        # run lstm output through nn to predict outcome\n",
    "        in_lay1 = torch.cat((x, y), 1)\n",
    "        out_lay1 = self.l_linear1(in_lay1)\n",
    "        in_lay2 = self.relu(out_lay1)\n",
    "        out_lay2 = self.l_linear2(in_lay2)\n",
    "        in_lay3 = self.relu(out_lay3)\n",
    "        out = self.soft(self.l_linear3(in_lay3))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5ecb2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dropout: float = 0.1, max_seq_len: int = 5000, d_model: int = 512, batch_first: bool = False):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            dropout: the dropout rate\n",
    "            max_seq_len: the maximum length of the input sequences\n",
    "            d_model: The dimension of the output of sub-layers in the model \n",
    "                     (Vaswani et al, 2017)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.x_dim = 1 if batch_first else 0\n",
    "\n",
    "        # copy pasted from PyTorch tutorial\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "        \n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, enc_seq_len, dim_val] or \n",
    "               [enc_seq_len, batch_size, dim_val]\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(self.x_dim)]\n",
    "\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "8dd93b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sport_pred_Transformer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, dec_seq_len: int, batch_first: bool, out_seq_len: int = 58, \n",
    "                 dim_val: int = 512, n_encoder_layers: int = 4, n_decoder_layers: int = 4, n_heads: int = 8,\n",
    "                 dropout_encoder: float = 0.2, dropout_decoder: float = 0.2, dropout_pos_enc: float = 0.1,\n",
    "                 dim_feedforward_encoder: int = 2048, dim_feedforward_decoder: int = 2048, \n",
    "                 num_predicted_features: int = 1): \n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size: int, number of input variables. 1 if univariate.\n",
    "            dec_seq_len: int, the length of the input sequence fed to the decoder\n",
    "            dim_val: int, aka d_model. All sub-layers in the model produce \n",
    "                     outputs of dimension dim_val\n",
    "            n_encoder_layers: int, number of stacked encoder layers in the encoder\n",
    "            n_decoder_layers: int, number of stacked encoder layers in the decoder\n",
    "            n_heads: int, the number of attention heads (aka parallel attention layers)\n",
    "            dropout_encoder: float, the dropout rate of the encoder\n",
    "            dropout_decoder: float, the dropout rate of the decoder\n",
    "            dropout_pos_enc: float, the dropout rate of the positional encoder\n",
    "            dim_feedforward_encoder: int, number of neurons in the linear layer \n",
    "                                     of the encoder\n",
    "            dim_feedforward_decoder: int, number of neurons in the linear layer \n",
    "                                     of the decoder\n",
    "            num_predicted_features: int, the number of features you want to predict.\n",
    "                                    Most of the time, this will be 1 because we're\n",
    "                                    only forecasting FCR-N prices in DK2, but in\n",
    "                                    we wanted to also predict FCR-D with the same\n",
    "                                    model, num_predicted_features should be 2.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__() \n",
    "\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "\n",
    "        #print(\"input_size is: {}\".format(input_size))\n",
    "        #print(\"dim_val is: {}\".format(dim_val))\n",
    "\n",
    "        # Creating the three linear layers needed for the model\n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features = input_size, \n",
    "            out_features = dim_val \n",
    "            )\n",
    "\n",
    "        self.decoder_input_layer = nn.Linear(\n",
    "            in_features = num_predicted_features,\n",
    "            out_features = dim_val\n",
    "            )  \n",
    "        \n",
    "        self.linear_mapping = nn.Linear(\n",
    "            in_features = dim_val, \n",
    "            out_features = num_predicted_features\n",
    "            )\n",
    "\n",
    "        # Create positional encoder\n",
    "        self.positional_encoding_layer = pe.PositionalEncoder(\n",
    "            d_model = dim_val,\n",
    "            dropout = dropout_pos_enc\n",
    "            )\n",
    "\n",
    "        # The encoder layer used in the paper is identical to the one used by\n",
    "        # Vaswani et al (2017) on which the PyTorch module is based.\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model = dim_val, \n",
    "            nhead = n_heads,\n",
    "            dim_feedforward = dim_feedforward_encoder,\n",
    "            dropout = dropout_encoder,\n",
    "            batch_first = batch_first\n",
    "            )\n",
    "\n",
    "        # Stack the encoder layers in nn.TransformerDecoder\n",
    "        # It seems the option of passing a normalization instance is redundant\n",
    "        # in my case, because nn.TransformerEncoderLayer per default normalizes\n",
    "        # after each sub-layer\n",
    "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer = encoder_layer,\n",
    "            num_layers = n_encoder_layers, \n",
    "            norm = None\n",
    "            )\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model = dim_val,\n",
    "            nhead = n_heads,\n",
    "            dim_feedforward = dim_feedforward_decoder,\n",
    "            dropout = dropout_decoder,\n",
    "            batch_first = batch_first\n",
    "            )\n",
    "\n",
    "        # Stack the decoder layers in nn.TransformerDecoder\n",
    "        # It seems the option of passing a normalization instance is redundant\n",
    "        # in my case, because nn.TransformerDecoderLayer per default normalizes\n",
    "        # after each sub-layer\n",
    "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer = decoder_layer,\n",
    "            num_layers = n_decoder_layers, \n",
    "            norm = None\n",
    "            )\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_mask: torch.Tensor = None, \n",
    "                tgt_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape:\n",
    "        [target_sequence_length, batch_size, num_predicted_features]\n",
    "        \n",
    "        Args:\n",
    "            src: the encoder's output sequence. Shape: (S,E) for unbatched input, \n",
    "                 (S, N, E) if batch_first=False or (N, S, E) if \n",
    "                 batch_first=True, where S is the source sequence length, \n",
    "                 N is the batch size, and E is the number of features (1 if univariate)\n",
    "            tgt: the sequence to the decoder. Shape: (T,E) for unbatched input, \n",
    "                 (T, N, E)(T,N,E) if batch_first=False or (N, T, E) if \n",
    "                 batch_first=True, where T is the target sequence length, \n",
    "                 N is the batch size, and E is the number of features (1 if univariate)\n",
    "            src_mask: the mask for the src sequence to prevent the model from \n",
    "                      using data points from the target sequence\n",
    "            tgt_mask: the mask for the tgt sequence to prevent the model from\n",
    "                      using data points from the target sequence\n",
    "        \"\"\"\n",
    "\n",
    "        #print(\"From model.forward(): Size of src as given to forward(): {}\".format(src.size()))\n",
    "        #print(\"From model.forward(): tgt size = {}\".format(tgt.size()))\n",
    "\n",
    "        # Pass throguh the input layer right before the encoder\n",
    "        src = self.encoder_input_layer(src) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n",
    "        #print(\"From model.forward(): Size of src after input layer: {}\".format(src.size()))\n",
    "\n",
    "        # Pass through the positional encoding layer\n",
    "        src = self.positional_encoding_layer(src) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n",
    "        #print(\"From model.forward(): Size of src after pos_enc layer: {}\".format(src.size()))\n",
    "\n",
    "        # Pass through all the stacked encoder layers in the encoder\n",
    "        # Masking is only needed in the encoder if input sequences are padded\n",
    "        # which they are not in this time series use case, because all my\n",
    "        # input sequences are naturally of the same length. \n",
    "        # (https://github.com/huggingface/transformers/issues/4083)\n",
    "        src = self.encoder( # src shape: [batch_size, enc_seq_len, dim_val]\n",
    "            src=src\n",
    "            )\n",
    "        #print(\"From model.forward(): Size of src after encoder: {}\".format(src.size()))\n",
    "\n",
    "        # Pass decoder input through decoder input layer\n",
    "        decoder_output = self.decoder_input_layer(tgt) # src shape: [target sequence length, batch_size, dim_val] regardless of number of input features\n",
    "        #print(\"From model.forward(): Size of decoder_output after linear decoder layer: {}\".format(decoder_output.size()))\n",
    "\n",
    "        #if src_mask is not None:\n",
    "            #print(\"From model.forward(): Size of src_mask: {}\".format(src_mask.size()))\n",
    "        #if tgt_mask is not None:\n",
    "            #print(\"From model.forward(): Size of tgt_mask: {}\".format(tgt_mask.size()))\n",
    "\n",
    "        # Pass throguh decoder - output shape: [batch_size, target seq len, dim_val]\n",
    "        decoder_output = self.decoder(\n",
    "            tgt=decoder_output,\n",
    "            memory=src,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=src_mask\n",
    "            )\n",
    "\n",
    "        #print(\"From model.forward(): decoder_output shape after decoder: {}\".format(decoder_output.shape))\n",
    "\n",
    "        # Pass through linear mapping\n",
    "        decoder_output = self.linear_mapping(decoder_output) # shape [batch_size, target seq len]\n",
    "        #print(\"From model.forward(): decoder_output size after linear_mapping = {}\".format(decoder_output.size()))\n",
    "\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3f0a9ac0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [292]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m output_sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m58\u001b[39m \u001b[38;5;66;03m# Length of the target sequence, i.e. how many time steps should your forecast cover\u001b[39;00m\n\u001b[1;32m     10\u001b[0m max_seq_len \u001b[38;5;241m=\u001b[39m enc_seq_len \u001b[38;5;66;03m# What's the longest sequence the model will encounter? Used to make the positional encoder\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtst\u001b[49m\u001b[38;5;241m.\u001b[39mTimeSeriesTransformer(\n\u001b[1;32m     13\u001b[0m     dim_val\u001b[38;5;241m=\u001b[39mdim_val,\n\u001b[1;32m     14\u001b[0m     input_size\u001b[38;5;241m=\u001b[39minput_size, \n\u001b[1;32m     15\u001b[0m     dec_seq_len\u001b[38;5;241m=\u001b[39mdec_seq_len,\n\u001b[1;32m     16\u001b[0m     max_seq_len\u001b[38;5;241m=\u001b[39mmax_seq_len,\n\u001b[1;32m     17\u001b[0m     out_seq_len\u001b[38;5;241m=\u001b[39moutput_sequence_length, \n\u001b[1;32m     18\u001b[0m     n_decoder_layers\u001b[38;5;241m=\u001b[39mn_decoder_layers,\n\u001b[1;32m     19\u001b[0m     n_encoder_layers\u001b[38;5;241m=\u001b[39mn_encoder_layers,\n\u001b[1;32m     20\u001b[0m     n_heads\u001b[38;5;241m=\u001b[39mn_heads)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tst' is not defined"
     ]
    }
   ],
   "source": [
    "## Model parameters\n",
    "dim_val = 512 # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
    "n_heads = 8 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
    "n_decoder_layers = 4 # Number of times the decoder layer is stacked in the decoder\n",
    "n_encoder_layers = 4 # Number of times the encoder layer is stacked in the encoder\n",
    "input_size = 1 # The number of input variables. 1 if univariate forecasting.\n",
    "dec_seq_len = 92 # length of input given to decoder. Can have any integer value.\n",
    "enc_seq_len = 153 # length of input given to encoder. Can have any integer value.\n",
    "output_sequence_length = 58 # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
    "max_seq_len = enc_seq_len # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
    "\n",
    "model = tst.TimeSeriesTransformer(\n",
    "    dim_val=dim_val,\n",
    "    input_size=input_size, \n",
    "    dec_seq_len=dec_seq_len,\n",
    "    max_seq_len=max_seq_len,\n",
    "    out_seq_len=output_sequence_length, \n",
    "    n_decoder_layers=n_decoder_layers,\n",
    "    n_encoder_layers=n_encoder_layers,\n",
    "    n_heads=n_heads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9f35778a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tuple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [293]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_src_trg\u001b[39m(\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      3\u001b[0m         sequence: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m      4\u001b[0m         enc_seq_len: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m      5\u001b[0m         target_seq_len: \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m----> 6\u001b[0m         ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mTuple\u001b[49m[torch\u001b[38;5;241m.\u001b[39mtensor, torch\u001b[38;5;241m.\u001b[39mtensor, torch\u001b[38;5;241m.\u001b[39mtensor]:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        Generate the src (encoder input), trg (decoder input) and trg_y (the target)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m        sequences from a sequence. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m#print(\"Called dataset.TransformerDataset.get_src_trg\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tuple' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_src_trg(\n",
    "        self,\n",
    "        sequence: torch.Tensor, \n",
    "        enc_seq_len: int, \n",
    "        target_seq_len: int\n",
    "        ) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        Generate the src (encoder input), trg (decoder input) and trg_y (the target)\n",
    "        sequences from a sequence. \n",
    "        Args:\n",
    "            sequence: tensor, a 1D tensor of length n where \n",
    "                    n = encoder input length + target sequence length  \n",
    "            enc_seq_len: int, the desired length of the input to the transformer encoder\n",
    "            target_seq_len: int, the desired length of the target sequence (the \n",
    "                            one against which the model output is compared)\n",
    "        Return: \n",
    "            src: tensor, 1D, used as input to the transformer model\n",
    "            trg: tensor, 1D, used as input to the transformer model\n",
    "            trg_y: tensor, 1D, the target sequence against which the model output\n",
    "                is compared when computing loss. \n",
    "        \n",
    "        \"\"\"\n",
    "        #print(\"Called dataset.TransformerDataset.get_src_trg\")\n",
    "        assert len(sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n",
    "        \n",
    "        #print(\"From data.TransformerDataset.get_src_trg: sequence shape: {}\".format(sequence.shape))\n",
    "\n",
    "        # encoder input\n",
    "        src = sequence[:enc_seq_len] \n",
    "        \n",
    "        # decoder input. As per the paper, it must have the same dimension as the \n",
    "        # target sequence, and it must contain the last value of src, and all\n",
    "        # values of trg_y except the last (i.e. it must be shifted right by 1)\n",
    "        trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
    "\n",
    "        #print(\"From data.TransformerDataset.get_src_trg: trg shape before slice: {}\".format(trg.shape))\n",
    "\n",
    "        trg = trg[:, 0]\n",
    "\n",
    "        #print(\"From data.TransformerDataset.get_src_trg: trg shape after slice: {}\".format(trg.shape))\n",
    "\n",
    "        if len(trg.shape) == 1:\n",
    "\n",
    "            trg = trg.unsqueeze(-1)\n",
    "\n",
    "            #print(\"From data.TransformerDataset.get_src_trg: trg shape after unsqueeze: {}\".format(trg.shape))\n",
    "\n",
    "        \n",
    "        assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n",
    "\n",
    "        # The target sequence against which the model output will be compared to compute loss\n",
    "        trg_y = sequence[-target_seq_len:]\n",
    "\n",
    "        #print(\"From data.TransformerDataset.get_src_trg: trg_y shape before slice: {}\".format(trg_y.shape))\n",
    "\n",
    "        # We only want trg_y to consist of the target variable not any potential exogenous variables\n",
    "        trg_y = trg_y[:, 0]\n",
    "\n",
    "        #print(\"From data.TransformerDataset.get_src_trg: trg_y shape after slice: {}\".format(trg_y.shape))\n",
    "\n",
    "        assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n",
    "\n",
    "        return src, trg, trg_y.squeeze(-1) # change size from [batch_size, target_seq_len, num_features] to [batch_size, target_seq_len] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_square_subsequent_mask(dim1: int, dim2: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
    "    Source:\n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    Args:\n",
    "        dim1: int, for both src and tgt masking, this must be target sequence\n",
    "              length\n",
    "        dim2: int, for src masking this must be encoder sequence length (i.e. \n",
    "              the length of the input sequence to the model), \n",
    "              and for tgt masking, this must be target sequence length \n",
    "    Return:\n",
    "        A Tensor of shape [dim1, dim2]\n",
    "    \"\"\"\n",
    "    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)\n",
    "\n",
    "# Input length\n",
    "enc_seq_len = 100\n",
    "\n",
    "# Output length\n",
    "output_sequence_length = 58\n",
    "\n",
    "# Make src mask for decoder with size:\n",
    "tgt_mask = utils.generate_square_subsequent_mask(\n",
    "    dim1=output_sequence_length,\n",
    "    dim2=output_sequence_length\n",
    "   )\n",
    "\n",
    "src_mask = utils.generate_square_subsequent_mask(\n",
    "    dim1=output_sequence_length,\n",
    "    dim2=enc_seq_len\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8af39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = model(\n",
    "    src=src, \n",
    "    tgt=trg,\n",
    "    src_mask=src_mask,\n",
    "    tgt_mask=tgt_mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733694f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955f061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bce4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c85b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b1124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f6947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a16a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14df31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e8ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de472784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3b37151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 288])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      5\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m output, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "for input_,target in dataloader:\n",
    "    print(input_.shape)\n",
    "    net = torch.nn.LSTM(288,10,1)\n",
    "    h0 = torch.randn(1, 10)\n",
    "    c0 = torch.randn(1, 10)\n",
    "    output, (hn, cn) = net(input_, (h0, c0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "893f3884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0470e+03,  0.0000e+00, -7.5423e-01,  ...,  0.0000e+00,\n",
       "          1.2000e+01,  0.0000e+00],\n",
       "        [ 1.0470e+03,  0.0000e+00, -1.5763e+00,  ...,  0.0000e+00,\n",
       "          1.2000e+01,  0.0000e+00],\n",
       "        [ 1.0470e+03,  0.0000e+00, -1.9825e-02,  ...,  0.0000e+00,\n",
       "          1.2000e+01,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 1.0060e+03,  0.0000e+00, -1.2058e+00,  ...,  1.0000e+00,\n",
       "          1.2000e+01,  0.0000e+00],\n",
       "        [ 1.0060e+03,  0.0000e+00, -4.2011e-01,  ...,  2.0000e+00,\n",
       "          1.2000e+01,  0.0000e+00],\n",
       "        [ 1.0060e+03,  0.0000e+00, -2.2493e-01,  ...,  2.0000e+00,\n",
       "          1.2000e+01,  0.0000e+00]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9782fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes # output size\n",
    "        self.num_layers = num_layers # number of recurrent layers in the lstm\n",
    "        self.input_size = input_size # input size\n",
    "        self.hidden_size = hidden_size # neurons in each lstm layer\n",
    "        # LSTM model\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True, dropout=0.2) # lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) # fully connected \n",
    "        self.fc_2 = nn.Linear(128, num_classes) # fully connected last layer\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # hidden state\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # cell state\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) # (input, hidden, and internal state)\n",
    "        hn = hn.view(-1, self.hidden_size) # reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) # first dense\n",
    "        out = self.relu(out) # relu\n",
    "        out = self.fc_2(out) # final output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a4e267fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def data_to_input(data_frame):\n",
    "    club_np = data_frame.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for cl in range(window_size, len(club_np)-1):\n",
    "        x = [[a] for a in club_np[cl-window_size:cl,3:]]\n",
    "        label = club_np[cl+1,0]\n",
    "        X.append(x)\n",
    "        y.append(label)\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "106a6364",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'club_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [295]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Splitting the independent and dependent variables\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#i_data = dataset.data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#response = dataset.target\u001b[39;00m\n\u001b[1;32m      9\u001b[0m  \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# standardization \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mclub_np\u001b[49m[:,\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m12\u001b[39m]) \n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(scale)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'club_np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "\n",
    "object= StandardScaler()\n",
    " \n",
    "# Splitting the independent and dependent variables\n",
    "#i_data = dataset.data\n",
    "#response = dataset.target\n",
    " \n",
    "# standardization \n",
    "scale = object.fit_transform(club_np[:,10:12]) \n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "aff1e113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " ...\n",
      " [-0.74265998  0.36241024  2.2731764  ...  0.         -0.2657936\n",
      "  -2.14103381]\n",
      " [-1.52490839  3.6499926   3.16798574 ...  0.         -0.26521127\n",
      "   0.12707839]\n",
      " [-1.91495511  1.72677782  2.61776863 ...  0.         -0.00576638\n",
      "   1.25879623]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:980: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/paul/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/paul/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:1005: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "scale = object.fit_transform(d)\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "894638cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2c6409da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e0652b021d8099f8\n",
      "e0652b02c4260e09\n",
      "e0652b02ffcbe334\n",
      "e0652b021d2fe027\n",
      "e0652b02d609edc0\n",
      "e0652b02421387cf\n",
      "e0652b02cc919b35\n",
      "e0652b02dc56fe14\n",
      "e0652b02105360fe\n",
      "e0652b02cf74a709\n",
      "e0652b02922493f3\n",
      "e0652b024ef57aeb\n",
      "e0652b028ff9e3b3\n",
      "e0652b0204eea015\n",
      "e0652b02c5577084\n",
      "e0652b026a7ad59d\n",
      "e0652b024fcb34fd\n",
      "e0652b02eab4234c\n",
      "e0652b029aad3a77\n",
      "e0652b0268449f6d\n",
      "e0652b02658bf2de\n",
      "e0652b02a3d88bd8\n",
      "e0652b027213da33\n",
      "e0652b0221680aa4\n",
      "e0652b020e72edf2\n",
      "e0652b023074d7b1\n",
      "e0652b02d48ad4ff\n",
      "e0652b02af5d5982\n",
      "e0652b02e2befd26\n"
     ]
    }
   ],
   "source": [
    "a = club.fbref_own.unique() + club.fbref_oppon.unique()\n",
    "for i in set(a):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "df4d6aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['result',\n",
       " 'gf',\n",
       " 'xg',\n",
       " 'captain',\n",
       " 'formation',\n",
       " 'shooting_standard_gls',\n",
       " 'shooting_standard_sh',\n",
       " 'shooting_standard_sot',\n",
       " 'shooting_standard_sot_perc',\n",
       " 'shooting_standard_g_per_sh',\n",
       " 'shooting_standard_g_per_sot',\n",
       " 'shooting_standard_dist',\n",
       " 'shooting_standard_fk',\n",
       " 'shooting_standard_pk',\n",
       " 'shooting_standard_pkatt',\n",
       " 'shooting_expected_npxg',\n",
       " 'shooting_expected_npxg_per_sh',\n",
       " 'shooting_expected_g_minus_xg',\n",
       " 'shooting_expected_npg_minus_xg',\n",
       " 'keeper_performance_sota',\n",
       " 'keeper_performance_saves',\n",
       " 'keeper_performance_save_perc',\n",
       " 'keeper_performance_cs',\n",
       " 'keeper_performance_psxg',\n",
       " 'keeper_performance_psxg_plus_minus',\n",
       " 'keeper_penaltykicks_pkatt',\n",
       " 'keeper_penaltykicks_pksv',\n",
       " 'keeper_penaltykicks_pkm',\n",
       " 'keeper_launched_cmp',\n",
       " 'keeper_launched_att',\n",
       " 'keeper_launched_cmp_perc',\n",
       " 'keeper_passes_att',\n",
       " 'keeper_passes_thr',\n",
       " 'keeper_passes_launch_perc',\n",
       " 'keeper_passes_avglen',\n",
       " 'keeper_goalkicks_att',\n",
       " 'keeper_goalkicks_launch_perc',\n",
       " 'keeper_goalkicks_avglen',\n",
       " 'keeper_crosses_opp',\n",
       " 'keeper_crosses_stp',\n",
       " 'keeper_crosses_stp_perc',\n",
       " 'keeper_sweeper_number_opa',\n",
       " 'keeper_sweeper_avgdist',\n",
       " 'passing_total_cmp',\n",
       " 'passing_total_att',\n",
       " 'passing_total_cmp_perc',\n",
       " 'passing_total_totdist',\n",
       " 'passing_total_prgdist',\n",
       " 'passing_short_cmp',\n",
       " 'passing_short_att',\n",
       " 'passing_short_cmp_perc',\n",
       " 'passing_medium_cmp',\n",
       " 'passing_medium_att',\n",
       " 'passing_medium_cmp_perc',\n",
       " 'passing_long_cmp',\n",
       " 'passing_long_att',\n",
       " 'passing_long_cmp_perc',\n",
       " 'passing_attacking_ast',\n",
       " 'passing_attacking_xag',\n",
       " 'passing_attacking_xa',\n",
       " 'passing_attacking_kp',\n",
       " 'passing_attacking_1_per_3',\n",
       " 'passing_attacking_ppa',\n",
       " 'passing_attacking_crspa',\n",
       " 'passing_attacking_prgp',\n",
       " 'passing_types_passtypes_live',\n",
       " 'passing_types_passtypes_dead',\n",
       " 'passing_types_passtypes_fk',\n",
       " 'passing_types_passtypes_tb',\n",
       " 'passing_types_passtypes_sw',\n",
       " 'passing_types_passtypes_crs',\n",
       " 'passing_types_passtypes_ti',\n",
       " 'passing_types_passtypes_ck',\n",
       " 'passing_types_cornerkicks_in',\n",
       " 'passing_types_cornerkicks_out',\n",
       " 'passing_types_cornerkicks_str',\n",
       " 'passing_types_outcomes_off',\n",
       " 'passing_types_outcomes_blocks',\n",
       " 'gca_scatypes_sca',\n",
       " 'gca_scatypes_passlive',\n",
       " 'gca_scatypes_passdead',\n",
       " 'gca_scatypes_to',\n",
       " 'gca_scatypes_sh',\n",
       " 'gca_scatypes_fld',\n",
       " 'gca_scatypes_def',\n",
       " 'gca_gcatypes_gca',\n",
       " 'gca_gcatypes_passlive',\n",
       " 'gca_gcatypes_passdead',\n",
       " 'gca_gcatypes_to',\n",
       " 'gca_gcatypes_sh',\n",
       " 'gca_gcatypes_fld',\n",
       " 'gca_gcatypes_def',\n",
       " 'defense_tackles_tkl',\n",
       " 'defense_tackles_tklw',\n",
       " 'defense_tackles_def3rd',\n",
       " 'defense_tackles_mid3rd',\n",
       " 'defense_tackles_att3rd',\n",
       " 'defense_challenges_tkl',\n",
       " 'defense_challenges_att',\n",
       " 'defense_challenges_tkl_perc',\n",
       " 'defense_challenges_lost',\n",
       " 'defense_blocks_blocks',\n",
       " 'defense_blocks_sh',\n",
       " 'defense_blocks_pass',\n",
       " 'defense_general_int',\n",
       " 'defense_general_tkl_plus_int',\n",
       " 'defense_general_clr',\n",
       " 'defense_general_err',\n",
       " 'possession_general_poss',\n",
       " 'possession_touches_touches',\n",
       " 'possession_touches_defpen',\n",
       " 'possession_touches_def3rd',\n",
       " 'possession_touches_mid3rd',\n",
       " 'possession_touches_att3rd',\n",
       " 'possession_touches_attpen',\n",
       " 'possession_touches_live',\n",
       " 'possession_takeons_att',\n",
       " 'possession_takeons_succ',\n",
       " 'possession_takeons_succ_perc',\n",
       " 'possession_takeons_tkld',\n",
       " 'possession_takeons_tkld_perc',\n",
       " 'possession_carries_carries',\n",
       " 'possession_carries_totdist',\n",
       " 'possession_carries_prgdist',\n",
       " 'possession_carries_prgc',\n",
       " 'possession_carries_1_per_3',\n",
       " 'possession_carries_cpa',\n",
       " 'possession_carries_mis',\n",
       " 'possession_carries_dis',\n",
       " 'possession_receiving_rec',\n",
       " 'possession_receiving_prgr',\n",
       " 'misc_performance_crdy',\n",
       " 'misc_performance_crdr',\n",
       " 'misc_performance_2crdy',\n",
       " 'misc_performance_fls',\n",
       " 'misc_performance_fld',\n",
       " 'misc_performance_off',\n",
       " 'misc_performance_og',\n",
       " 'misc_performance_recov',\n",
       " 'misc_aerialduels_won',\n",
       " 'misc_aerialduels_lost',\n",
       " 'misc_aerialduels_won_perc',\n",
       " 'keeper_penaltykicks_pka',\n",
       " 'attendance',\n",
       " 'referee',\n",
       " 'fbref_season',\n",
       " 'fbref_league_id',\n",
       " 'fbref_own',\n",
       " 'fbref_oppon',\n",
       " 'fbref_match_id',\n",
       " 'home']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(club.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a20d4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['shooting_standard_gls',\n",
    " 'shooting_standard_sh',\n",
    " 'shooting_standard_sot',\n",
    " 'shooting_standard_sot_perc',\n",
    " 'shooting_standard_g_per_sh',\n",
    " 'shooting_standard_g_per_sot',\n",
    " 'shooting_standard_dist',\n",
    " 'shooting_standard_fk',\n",
    " 'shooting_standard_pk',\n",
    " 'shooting_standard_pkatt',\n",
    " 'shooting_expected_npxg',\n",
    " 'shooting_expected_npxg_per_sh',\n",
    " 'shooting_expected_g_minus_xg',\n",
    " 'shooting_expected_npg_minus_xg',\n",
    " 'keeper_performance_sota',\n",
    " 'keeper_performance_saves',\n",
    " 'keeper_performance_save_perc',\n",
    " 'keeper_performance_cs',\n",
    " 'keeper_performance_psxg',\n",
    " 'keeper_performance_psxg_plus_minus',\n",
    " 'keeper_penaltykicks_pkatt',\n",
    " 'keeper_penaltykicks_pksv',\n",
    " 'keeper_penaltykicks_pkm',\n",
    " 'keeper_launched_cmp',\n",
    " 'keeper_launched_att',\n",
    " 'keeper_launched_cmp_perc',\n",
    " 'keeper_passes_att',\n",
    " 'keeper_passes_thr',\n",
    " 'keeper_passes_launch_perc',\n",
    " 'keeper_passes_avglen',\n",
    " 'keeper_goalkicks_att',\n",
    " 'keeper_goalkicks_launch_perc',\n",
    " 'keeper_goalkicks_avglen',\n",
    " 'keeper_crosses_opp',\n",
    " 'keeper_crosses_stp',\n",
    " 'keeper_crosses_stp_perc',\n",
    " 'keeper_sweeper_number_opa',\n",
    " 'keeper_sweeper_avgdist',\n",
    " 'passing_total_cmp',\n",
    " 'passing_total_att',\n",
    " 'passing_total_cmp_perc',\n",
    " 'passing_total_totdist',\n",
    " 'passing_total_prgdist',\n",
    " 'passing_short_cmp',\n",
    " 'passing_short_att',\n",
    " 'passing_short_cmp_perc',\n",
    " 'passing_medium_cmp',\n",
    " 'passing_medium_att',\n",
    " 'passing_medium_cmp_perc',\n",
    " 'passing_long_cmp',\n",
    " 'passing_long_att',\n",
    " 'passing_long_cmp_perc',\n",
    " 'passing_attacking_ast',\n",
    " 'passing_attacking_xag',\n",
    " 'passing_attacking_xa',\n",
    " 'passing_attacking_kp',\n",
    " 'passing_attacking_1_per_3',\n",
    " 'passing_attacking_ppa',\n",
    " 'passing_attacking_crspa',\n",
    " 'passing_attacking_prgp',\n",
    " 'passing_types_passtypes_live',\n",
    " 'passing_types_passtypes_dead',\n",
    " 'passing_types_passtypes_fk',\n",
    " 'passing_types_passtypes_tb',\n",
    " 'passing_types_passtypes_sw',\n",
    " 'passing_types_passtypes_crs',\n",
    " 'passing_types_passtypes_ti',\n",
    " 'passing_types_passtypes_ck',\n",
    " 'passing_types_cornerkicks_in',\n",
    " 'passing_types_cornerkicks_out',\n",
    " 'passing_types_cornerkicks_str',\n",
    " 'passing_types_outcomes_off',\n",
    " 'passing_types_outcomes_blocks',\n",
    " 'gca_scatypes_sca',\n",
    " 'gca_scatypes_passlive',\n",
    " 'gca_scatypes_passdead',\n",
    " 'gca_scatypes_to',\n",
    " 'gca_scatypes_sh',\n",
    " 'gca_scatypes_fld',\n",
    " 'gca_scatypes_def',\n",
    " 'gca_gcatypes_gca',\n",
    " 'gca_gcatypes_passlive',\n",
    " 'gca_gcatypes_passdead',\n",
    " 'gca_gcatypes_to',\n",
    " 'gca_gcatypes_sh',\n",
    " 'gca_gcatypes_fld',\n",
    " 'gca_gcatypes_def',\n",
    " 'defense_tackles_tkl',\n",
    " 'defense_tackles_tklw',\n",
    " 'defense_tackles_def3rd',\n",
    " 'defense_tackles_mid3rd',\n",
    " 'defense_tackles_att3rd',\n",
    " 'defense_challenges_tkl',\n",
    " 'defense_challenges_att',\n",
    " 'defense_challenges_tkl_perc',\n",
    " 'defense_challenges_lost',\n",
    " 'defense_blocks_blocks',\n",
    " 'defense_blocks_sh',\n",
    " 'defense_blocks_pass',\n",
    " 'defense_general_int',\n",
    " 'defense_general_tkl_plus_int',\n",
    " 'defense_general_clr',\n",
    " 'defense_general_err',\n",
    " 'possession_general_poss',\n",
    " 'possession_touches_touches',\n",
    " 'possession_touches_defpen',\n",
    " 'possession_touches_def3rd',\n",
    " 'possession_touches_mid3rd',\n",
    " 'possession_touches_att3rd',\n",
    " 'possession_touches_attpen',\n",
    " 'possession_touches_live',\n",
    " 'possession_takeons_att',\n",
    " 'possession_takeons_succ',\n",
    " 'possession_takeons_succ_perc',\n",
    " 'possession_takeons_tkld',\n",
    " 'possession_takeons_tkld_perc',\n",
    " 'possession_carries_carries',\n",
    " 'possession_carries_totdist',\n",
    " 'possession_carries_prgdist',\n",
    " 'possession_carries_prgc',\n",
    " 'possession_carries_1_per_3',\n",
    " 'possession_carries_cpa',\n",
    " 'possession_carries_mis',\n",
    " 'possession_carries_dis',\n",
    " 'possession_receiving_rec',\n",
    " 'possession_receiving_prgr',\n",
    " 'misc_performance_crdy',\n",
    " 'misc_performance_crdr',\n",
    " 'misc_performance_2crdy',\n",
    " 'misc_performance_fls',\n",
    " 'misc_performance_fld',\n",
    " 'misc_performance_off',\n",
    " 'misc_performance_og',\n",
    " 'misc_performance_recov',\n",
    " 'misc_aerialduels_won',\n",
    " 'misc_aerialduels_lost',\n",
    " 'misc_aerialduels_won_perc',\n",
    " 'keeper_penaltykicks_pka',\n",
    " 'attendance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "478eefc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 152 instead of 222",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [189]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(l)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#club.shape\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m club\u001b[38;5;241m.\u001b[39mloc[l] \u001b[38;5;241m=\u001b[39m moving_average(club\u001b[38;5;241m.\u001b[39mloc[:,l])\n\u001b[1;32m      5\u001b[0m club\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:712\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 712\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_setitem_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:666\u001b[0m, in \u001b[0;36m_LocationIndexer._get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mrange\u001b[39m):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m--> 666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1290\u001b[0m, in \u001b[0;36m_LocIndexer._convert_to_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1290\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m     (inds,) \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inds\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:2401\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[1;32m   2398\u001b[0m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[1;32m   2399\u001b[0m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[1;32m   2400\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd_array(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m-> 2401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexers/utils.py:579\u001b[0m, in \u001b[0;36mcheck_array_indexer\u001b[0;34m(array, indexer)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[0;32m--> 579\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoolean index has wrong length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         )\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: Boolean index has wrong length: 152 instead of 222"
     ]
    }
   ],
   "source": [
    "l = club.columns.isin(features)\n",
    "len(l)\n",
    "#club.shape\n",
    "club.loc[l] = moving_average(club.loc[:,l])\n",
    "club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "37d7bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17,  8, 19, 15, 30],\n",
       "        [17,  8, 26, 15, 30],\n",
       "        [17,  9,  9, 15, 30],\n",
       "        ...,\n",
       "        [23,  4, 22, 15, 30],\n",
       "        [23,  4, 30, 17, 30],\n",
       "        [23,  5,  7, 17, 30]])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_time_features = []\n",
    "for i in club.index:\n",
    "    past_time_features.append(list(map(int,i.split(\"-\"))) + list(map(int,club.loc[i, \"schedule_time\"].split(\":\"))))\n",
    "for i in past_time_features:\n",
    "    i[0] = i[0]-2000\n",
    "past_time_features = torch.tensor(past_time_features)\n",
    "future_time_features = past_time_features \n",
    "\n",
    "\n",
    "\n",
    "static_categorical_features = torch.tensor(club.loc[:, ['fbref_own', 'fbref_league_id']].values) # static_categorical_features\n",
    "static_categorical_features\n",
    "\n",
    "mask = club.notna()\n",
    "mask\n",
    "attention_mask = torch.tensor(mask.astype(int).to_numpy())\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a93c0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moving_average import moving_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28a774e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_club = moving_average(club.loc[:,\"shooting_standard_gls\":\"keeper_penaltykicks_pka\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0f9e6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        ...,\n",
       "        [ 1.3930, 19.5650,  7.4418,  ...,  9.0850, 53.9059,     nan],\n",
       "        [ 3.6989, 20.7849,  7.7214,  ...,  5.0381, 71.9669,     nan],\n",
       "        [ 2.3500, 20.8925,  6.3597,  ...,  6.0176, 67.5843,     nan]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(first_club.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "173844e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shooting_standard_gls</th>\n",
       "      <th>shooting_standard_sh</th>\n",
       "      <th>shooting_standard_sot</th>\n",
       "      <th>shooting_standard_sot_perc</th>\n",
       "      <th>shooting_standard_g_per_sh</th>\n",
       "      <th>shooting_standard_g_per_sot</th>\n",
       "      <th>shooting_standard_dist</th>\n",
       "      <th>shooting_standard_fk</th>\n",
       "      <th>shooting_standard_pk</th>\n",
       "      <th>shooting_standard_pkatt</th>\n",
       "      <th>...</th>\n",
       "      <th>misc_performance_2crdy</th>\n",
       "      <th>misc_performance_fls</th>\n",
       "      <th>misc_performance_fld</th>\n",
       "      <th>misc_performance_off</th>\n",
       "      <th>misc_performance_og</th>\n",
       "      <th>misc_performance_recov</th>\n",
       "      <th>misc_aerialduels_won</th>\n",
       "      <th>misc_aerialduels_lost</th>\n",
       "      <th>misc_aerialduels_won_perc</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>1.571848</td>\n",
       "      <td>18.253177</td>\n",
       "      <td>5.759531</td>\n",
       "      <td>30.866471</td>\n",
       "      <td>0.082747</td>\n",
       "      <td>0.267253</td>\n",
       "      <td>16.788270</td>\n",
       "      <td>0.199413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.122190</td>\n",
       "      <td>12.968719</td>\n",
       "      <td>1.010753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.111437</td>\n",
       "      <td>15.849462</td>\n",
       "      <td>9.356794</td>\n",
       "      <td>63.273118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-15</th>\n",
       "      <td>1.785924</td>\n",
       "      <td>22.132942</td>\n",
       "      <td>7.882698</td>\n",
       "      <td>34.686999</td>\n",
       "      <td>0.081339</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>16.994233</td>\n",
       "      <td>0.099707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.562072</td>\n",
       "      <td>11.985337</td>\n",
       "      <td>1.004888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.060606</td>\n",
       "      <td>11.924731</td>\n",
       "      <td>9.176931</td>\n",
       "      <td>55.190029</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26</th>\n",
       "      <td>1.392962</td>\n",
       "      <td>19.565005</td>\n",
       "      <td>7.441838</td>\n",
       "      <td>37.948974</td>\n",
       "      <td>0.070674</td>\n",
       "      <td>0.186725</td>\n",
       "      <td>17.097556</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.778104</td>\n",
       "      <td>9.492669</td>\n",
       "      <td>1.503421</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>55.031281</td>\n",
       "      <td>10.963832</td>\n",
       "      <td>9.085044</td>\n",
       "      <td>53.905865</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29</th>\n",
       "      <td>3.698925</td>\n",
       "      <td>20.784946</td>\n",
       "      <td>7.721408</td>\n",
       "      <td>37.172141</td>\n",
       "      <td>0.170440</td>\n",
       "      <td>0.468661</td>\n",
       "      <td>16.800196</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.890518</td>\n",
       "      <td>10.247312</td>\n",
       "      <td>1.751711</td>\n",
       "      <td>0.250244</td>\n",
       "      <td>57.516129</td>\n",
       "      <td>9.978495</td>\n",
       "      <td>5.038123</td>\n",
       "      <td>71.966862</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>2.349951</td>\n",
       "      <td>20.892473</td>\n",
       "      <td>6.359726</td>\n",
       "      <td>30.481427</td>\n",
       "      <td>0.085220</td>\n",
       "      <td>0.234330</td>\n",
       "      <td>18.051906</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.944282</td>\n",
       "      <td>11.623656</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>0.125122</td>\n",
       "      <td>63.263930</td>\n",
       "      <td>10.987292</td>\n",
       "      <td>6.017595</td>\n",
       "      <td>67.584262</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               shooting_standard_gls  shooting_standard_sh  \\\n",
       "schedule_date                                                \n",
       "2017-08-12                       NaN                   NaN   \n",
       "2017-08-19                       NaN                   NaN   \n",
       "2017-08-26                       NaN                   NaN   \n",
       "2017-09-09                       NaN                   NaN   \n",
       "2017-09-15                       NaN                   NaN   \n",
       "...                              ...                   ...   \n",
       "2023-04-08                  1.571848             18.253177   \n",
       "2023-04-15                  1.785924             22.132942   \n",
       "2023-04-26                  1.392962             19.565005   \n",
       "2023-04-29                  3.698925             20.784946   \n",
       "2023-05-04                  2.349951             20.892473   \n",
       "\n",
       "               shooting_standard_sot  shooting_standard_sot_perc  \\\n",
       "schedule_date                                                      \n",
       "2017-08-12                       NaN                         NaN   \n",
       "2017-08-19                       NaN                         NaN   \n",
       "2017-08-26                       NaN                         NaN   \n",
       "2017-09-09                       NaN                         NaN   \n",
       "2017-09-15                       NaN                         NaN   \n",
       "...                              ...                         ...   \n",
       "2023-04-08                  5.759531                   30.866471   \n",
       "2023-04-15                  7.882698                   34.686999   \n",
       "2023-04-26                  7.441838                   37.948974   \n",
       "2023-04-29                  7.721408                   37.172141   \n",
       "2023-05-04                  6.359726                   30.481427   \n",
       "\n",
       "               shooting_standard_g_per_sh  shooting_standard_g_per_sot  \\\n",
       "schedule_date                                                            \n",
       "2017-08-12                            NaN                          NaN   \n",
       "2017-08-19                            NaN                          NaN   \n",
       "2017-08-26                            NaN                          NaN   \n",
       "2017-09-09                            NaN                          NaN   \n",
       "2017-09-15                            NaN                          NaN   \n",
       "...                                   ...                          ...   \n",
       "2023-04-08                       0.082747                     0.267253   \n",
       "2023-04-15                       0.081339                     0.233480   \n",
       "2023-04-26                       0.070674                     0.186725   \n",
       "2023-04-29                       0.170440                     0.468661   \n",
       "2023-05-04                       0.085220                     0.234330   \n",
       "\n",
       "               shooting_standard_dist  shooting_standard_fk  \\\n",
       "schedule_date                                                 \n",
       "2017-08-12                        NaN                   NaN   \n",
       "2017-08-19                        NaN                   NaN   \n",
       "2017-08-26                        NaN                   NaN   \n",
       "2017-09-09                        NaN                   NaN   \n",
       "2017-09-15                        NaN                   NaN   \n",
       "...                               ...                   ...   \n",
       "2023-04-08                  16.788270              0.199413   \n",
       "2023-04-15                  16.994233              0.099707   \n",
       "2023-04-26                  17.097556              0.049853   \n",
       "2023-04-29                  16.800196              0.024438   \n",
       "2023-05-04                  18.051906              0.011730   \n",
       "\n",
       "               shooting_standard_pk  shooting_standard_pkatt  ...  \\\n",
       "schedule_date                                                 ...   \n",
       "2017-08-12                      NaN                      NaN  ...   \n",
       "2017-08-19                      NaN                      NaN  ...   \n",
       "2017-08-26                      NaN                      NaN  ...   \n",
       "2017-09-09                      NaN                      NaN  ...   \n",
       "2017-09-15                      NaN                      NaN  ...   \n",
       "...                             ...                      ...  ...   \n",
       "2023-04-08                      NaN                 0.140762  ...   \n",
       "2023-04-15                      NaN                 0.070381  ...   \n",
       "2023-04-26                      NaN                 0.035191  ...   \n",
       "2023-04-29                      NaN                 0.017595  ...   \n",
       "2023-05-04                      NaN                 0.509286  ...   \n",
       "\n",
       "               misc_performance_2crdy  misc_performance_fls  \\\n",
       "schedule_date                                                 \n",
       "2017-08-12                        NaN                   NaN   \n",
       "2017-08-19                        NaN                   NaN   \n",
       "2017-08-26                        NaN                   NaN   \n",
       "2017-09-09                        NaN                   NaN   \n",
       "2017-09-15                        NaN                   NaN   \n",
       "...                               ...                   ...   \n",
       "2023-04-08                        0.0             12.122190   \n",
       "2023-04-15                        0.0             11.562072   \n",
       "2023-04-26                        0.0              9.778104   \n",
       "2023-04-29                        0.0             11.890518   \n",
       "2023-05-04                        0.0             10.944282   \n",
       "\n",
       "               misc_performance_fld  misc_performance_off  \\\n",
       "schedule_date                                               \n",
       "2017-08-12                      NaN                   NaN   \n",
       "2017-08-19                      NaN                   NaN   \n",
       "2017-08-26                      NaN                   NaN   \n",
       "2017-09-09                      NaN                   NaN   \n",
       "2017-09-15                      NaN                   NaN   \n",
       "...                             ...                   ...   \n",
       "2023-04-08                12.968719              1.010753   \n",
       "2023-04-15                11.985337              1.004888   \n",
       "2023-04-26                 9.492669              1.503421   \n",
       "2023-04-29                10.247312              1.751711   \n",
       "2023-05-04                11.623656              0.873900   \n",
       "\n",
       "               misc_performance_og  misc_performance_recov  \\\n",
       "schedule_date                                                \n",
       "2017-08-12                     NaN                     NaN   \n",
       "2017-08-19                     NaN                     NaN   \n",
       "2017-08-26                     NaN                     NaN   \n",
       "2017-09-09                     NaN                     NaN   \n",
       "2017-09-15                     NaN                     NaN   \n",
       "...                            ...                     ...   \n",
       "2023-04-08                0.000000               51.111437   \n",
       "2023-04-15                0.000000               53.060606   \n",
       "2023-04-26                0.500489               55.031281   \n",
       "2023-04-29                0.250244               57.516129   \n",
       "2023-05-04                0.125122               63.263930   \n",
       "\n",
       "               misc_aerialduels_won  misc_aerialduels_lost  \\\n",
       "schedule_date                                                \n",
       "2017-08-12                      NaN                    NaN   \n",
       "2017-08-19                      NaN                    NaN   \n",
       "2017-08-26                      NaN                    NaN   \n",
       "2017-09-09                      NaN                    NaN   \n",
       "2017-09-15                      NaN                    NaN   \n",
       "...                             ...                    ...   \n",
       "2023-04-08                15.849462               9.356794   \n",
       "2023-04-15                11.924731               9.176931   \n",
       "2023-04-26                10.963832               9.085044   \n",
       "2023-04-29                 9.978495               5.038123   \n",
       "2023-05-04                10.987292               6.017595   \n",
       "\n",
       "               misc_aerialduels_won_perc  keeper_penaltykicks_pka  \n",
       "schedule_date                                                      \n",
       "2017-08-12                           NaN                      NaN  \n",
       "2017-08-19                           NaN                      NaN  \n",
       "2017-08-26                           NaN                      NaN  \n",
       "2017-09-09                           NaN                      NaN  \n",
       "2017-09-15                           NaN                      NaN  \n",
       "...                                  ...                      ...  \n",
       "2023-04-08                     63.273118                      NaN  \n",
       "2023-04-15                     55.190029                      NaN  \n",
       "2023-04-26                     53.905865                      NaN  \n",
       "2023-04-29                     71.966862                      NaN  \n",
       "2023-05-04                     67.584262                      NaN  \n",
       "\n",
       "[222 rows x 138 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ae2cd997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_23020/552253524.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True)\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_23020/3267728420.py:5: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['fbref_match_id', 'schedule_time'], dtype='object')\n",
      "  mov_avg = df.rolling(window = window_size).apply(lambda x: np.sum(weights*x) / sum_weights, raw=False) # compute moving average of window_size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result               0.785924\n",
       "gf                   1.868035\n",
       "xg                   1.234115\n",
       "captain            749.026393\n",
       "formation            3.000000\n",
       "                      ...    \n",
       "fbref_season         5.000000\n",
       "fbref_league_id      9.000000\n",
       "fbref_own          100.000000\n",
       "fbref_oppon         17.977517\n",
       "home                 0.588465\n",
       "Name: 2023-04-08, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = new_data.dataset_team(club.loc[\"2023-04-08\"].fbref_oppon)\n",
    "b = a.loc[get_index_for_slice(a, \"2023-04-08\", 10)[1]:get_index_for_slice(a, \"2023-04-08\", 10)[0]]\n",
    "c = moving_average(b)\n",
    "c.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dcf6fa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-23'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index_for_slice(a, \"2023-04-08\", 10)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8085ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(df, window_size = 10, discount = 0.5, date = None):\n",
    "    \"compute the moving average with recency bias\"\n",
    "    weights = np.array([discount**x for x in reversed(range(window_size))]) # discount y_t-windowsize with discount**windowsize\n",
    "    sum_weights = np.sum(weights)\n",
    "    mov_avg = df.rolling(window = window_size).apply(lambda x: np.sum(weights*x) / sum_weights, raw=False) # compute moving average of window_size \n",
    "    return mov_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a9ba46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>xg</th>\n",
       "      <th>captain</th>\n",
       "      <th>formation</th>\n",
       "      <th>shooting_standard_gls</th>\n",
       "      <th>shooting_standard_sh</th>\n",
       "      <th>shooting_standard_sot</th>\n",
       "      <th>shooting_standard_sot_perc</th>\n",
       "      <th>shooting_standard_g_per_sh</th>\n",
       "      <th>...</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "      <th>schedule_time</th>\n",
       "      <th>attendance</th>\n",
       "      <th>referee</th>\n",
       "      <th>fbref_season</th>\n",
       "      <th>fbref_league_id</th>\n",
       "      <th>fbref_own</th>\n",
       "      <th>fbref_oppon</th>\n",
       "      <th>fbref_match_id</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>847</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:30</td>\n",
       "      <td>30415.0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>072bfc99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>847</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15:00</td>\n",
       "      <td>31902.0</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>e487b860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>847</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15:00</td>\n",
       "      <td>20181.0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>7bd57325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>847</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "      <td>30381.0</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>b81fcf8d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20:00</td>\n",
       "      <td>10369.0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>00836893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-11</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15:00</td>\n",
       "      <td>36471.0</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>3f653d6f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-15</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19:30</td>\n",
       "      <td>30933.0</td>\n",
       "      <td>197</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>d23a30cc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "      <td>31493.0</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>ead2251e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19:45</td>\n",
       "      <td>10266.0</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>95a97dc6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15:00</td>\n",
       "      <td>61405.0</td>\n",
       "      <td>189</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>b3ad7bd4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               result   gf   xg  captain  formation  shooting_standard_gls  \\\n",
       "schedule_date                                                                \n",
       "2017-08-12          1  0.0  0.3      847          2                    0.0   \n",
       "2017-08-19          1  0.0  0.2      847          5                    0.0   \n",
       "2017-08-26          2  0.0  1.1      847          5                    0.0   \n",
       "2017-09-09          0  3.0  0.4      847          5                    3.0   \n",
       "2017-09-15          1  1.0  0.9     1022          5                    1.0   \n",
       "...               ...  ...  ...      ...        ...                    ...   \n",
       "2023-03-11          2  2.0  2.7     1022          0                    2.0   \n",
       "2023-03-15          0  1.0  0.6     1022          0                    1.0   \n",
       "2023-04-01          2  3.0  4.2     1022          0                    3.0   \n",
       "2023-04-04          0  2.0  2.7     1022          0                    2.0   \n",
       "2023-04-08          1  1.0  1.4     1022          0                    1.0   \n",
       "\n",
       "               shooting_standard_sh  shooting_standard_sot  \\\n",
       "schedule_date                                                \n",
       "2017-08-12                      6.0                    2.0   \n",
       "2017-08-19                      5.0                    2.0   \n",
       "2017-08-26                     16.0                    2.0   \n",
       "2017-09-09                     12.0                    6.0   \n",
       "2017-09-15                      9.0                    1.0   \n",
       "...                             ...                    ...   \n",
       "2023-03-11                     15.0                    3.0   \n",
       "2023-03-15                     11.0                    5.0   \n",
       "2023-04-01                     32.0                   13.0   \n",
       "2023-04-04                     16.0                    6.0   \n",
       "2023-04-08                     17.0                    4.0   \n",
       "\n",
       "               shooting_standard_sot_perc  shooting_standard_g_per_sh  ...  \\\n",
       "schedule_date                                                          ...   \n",
       "2017-08-12                           33.3                        0.00  ...   \n",
       "2017-08-19                           40.0                        0.00  ...   \n",
       "2017-08-26                           12.5                        0.00  ...   \n",
       "2017-09-09                           50.0                        0.25  ...   \n",
       "2017-09-15                           11.1                        0.11  ...   \n",
       "...                                   ...                         ...  ...   \n",
       "2023-03-11                           20.0                        0.13  ...   \n",
       "2023-03-15                           45.5                        0.09  ...   \n",
       "2023-04-01                           40.6                        0.06  ...   \n",
       "2023-04-04                           37.5                        0.13  ...   \n",
       "2023-04-08                           23.5                        0.06  ...   \n",
       "\n",
       "               keeper_penaltykicks_pka  schedule_time  attendance  referee  \\\n",
       "schedule_date                                                                \n",
       "2017-08-12                         NaN          17:30     30415.0      180   \n",
       "2017-08-19                         0.0          15:00     31902.0      192   \n",
       "2017-08-26                         0.0          15:00     20181.0      187   \n",
       "2017-09-09                         NaN          15:00     30381.0      191   \n",
       "2017-09-15                         0.0          20:00     10369.0      178   \n",
       "...                                ...            ...         ...      ...   \n",
       "2023-03-11                         0.0          15:00     36471.0      181   \n",
       "2023-03-15                         NaN          19:30     30933.0      197   \n",
       "2023-04-01                         NaN          15:00     31493.0      180   \n",
       "2023-04-04                         0.0          19:45     10266.0      206   \n",
       "2023-04-08                         0.0          15:00     61405.0      189   \n",
       "\n",
       "               fbref_season  fbref_league_id  fbref_own  fbref_oppon  \\\n",
       "schedule_date                                                          \n",
       "2017-08-12                0                9          1           86   \n",
       "2017-08-19                0                9          1          133   \n",
       "2017-08-26                0                9          1          125   \n",
       "2017-09-09                0                9          1           11   \n",
       "2017-09-15                0                9          1           42   \n",
       "...                     ...              ...        ...          ...   \n",
       "2023-03-11                5                9          1           80   \n",
       "2023-03-15                5                9          1          110   \n",
       "2023-04-01                5                9          1          116   \n",
       "2023-04-04                5                9          1           42   \n",
       "2023-04-08                5                9          1          100   \n",
       "\n",
       "               fbref_match_id  home  \n",
       "schedule_date                        \n",
       "2017-08-12           072bfc99     1  \n",
       "2017-08-19           e487b860     0  \n",
       "2017-08-26           7bd57325     0  \n",
       "2017-09-09           b81fcf8d     1  \n",
       "2017-09-15           00836893     0  \n",
       "...                       ...   ...  \n",
       "2023-03-11           3f653d6f     0  \n",
       "2023-03-15           d23a30cc     1  \n",
       "2023-04-01           ead2251e     1  \n",
       "2023-04-04           95a97dc6     0  \n",
       "2023-04-08           b3ad7bd4     0  \n",
       "\n",
       "[218 rows x 152 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "club.loc[:\"2023-04-08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fd9a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_for_slice(df, date, range_):\n",
    "    a = 0\n",
    "    x = []\n",
    "    for i in reversed(df.loc[:date].index):\n",
    "        x.append(i)\n",
    "        a += 1\n",
    "        if a == range_:\n",
    "            break\n",
    "    return x[0], x[range_ - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eb4e5dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-03-11'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index_for_slice(club, \"2023-04-08\",5)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "781377b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_23020/4035811546.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.end_team = random_team.merge(random_team3, \"left\", on = [\"schedule_date\"], sort = True)\n",
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_23020/3267728420.py:5: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['fbref_match_id', 'schedule_time'], dtype='object')\n",
      "  mov_avg = df.rolling(window = window_size).apply(lambda x: np.sum(weights*x) / sum_weights, raw=False) # compute moving average of window_size\n"
     ]
    }
   ],
   "source": [
    "a = club.loc[\"2023-04-08\"].fbref_oppon\n",
    "b = new_data.dataset_team(a)\n",
    "c = moving_average(b)\n",
    "e = c.loc[\"2023-04-08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ead0d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "gf\n",
      "xg\n",
      "captain\n",
      "formation\n",
      "shooting_standard_gls\n",
      "shooting_standard_sh\n",
      "shooting_standard_sot\n",
      "shooting_standard_sot_perc\n",
      "shooting_standard_g_per_sh\n",
      "shooting_standard_g_per_sot\n",
      "shooting_standard_dist\n",
      "shooting_standard_fk\n",
      "shooting_standard_pk\n",
      "shooting_standard_pkatt\n",
      "shooting_expected_npxg\n",
      "shooting_expected_npxg_per_sh\n",
      "shooting_expected_g_minus_xg\n",
      "shooting_expected_npg_minus_xg\n",
      "keeper_performance_sota\n",
      "keeper_performance_saves\n",
      "keeper_performance_save_perc\n",
      "keeper_performance_cs\n",
      "keeper_performance_psxg\n",
      "keeper_performance_psxg_plus_minus\n",
      "keeper_penaltykicks_pkatt\n",
      "keeper_penaltykicks_pksv\n",
      "keeper_penaltykicks_pkm\n",
      "keeper_launched_cmp\n",
      "keeper_launched_att\n",
      "keeper_launched_cmp_perc\n",
      "keeper_passes_att\n",
      "keeper_passes_thr\n",
      "keeper_passes_launch_perc\n",
      "keeper_passes_avglen\n",
      "keeper_goalkicks_att\n",
      "keeper_goalkicks_launch_perc\n",
      "keeper_goalkicks_avglen\n",
      "keeper_crosses_opp\n",
      "keeper_crosses_stp\n",
      "keeper_crosses_stp_perc\n",
      "keeper_sweeper_number_opa\n",
      "keeper_sweeper_avgdist\n",
      "passing_total_cmp\n",
      "passing_total_att\n",
      "passing_total_cmp_perc\n",
      "passing_total_totdist\n",
      "passing_total_prgdist\n",
      "passing_short_cmp\n",
      "passing_short_att\n",
      "passing_short_cmp_perc\n",
      "passing_medium_cmp\n",
      "passing_medium_att\n",
      "passing_medium_cmp_perc\n",
      "passing_long_cmp\n",
      "passing_long_att\n",
      "passing_long_cmp_perc\n",
      "passing_attacking_ast\n",
      "passing_attacking_xag\n",
      "passing_attacking_xa\n",
      "passing_attacking_kp\n",
      "passing_attacking_1_per_3\n",
      "passing_attacking_ppa\n",
      "passing_attacking_crspa\n",
      "passing_attacking_prgp\n",
      "passing_types_passtypes_live\n",
      "passing_types_passtypes_dead\n",
      "passing_types_passtypes_fk\n",
      "passing_types_passtypes_tb\n",
      "passing_types_passtypes_sw\n",
      "passing_types_passtypes_crs\n",
      "passing_types_passtypes_ti\n",
      "passing_types_passtypes_ck\n",
      "passing_types_cornerkicks_in\n",
      "passing_types_cornerkicks_out\n",
      "passing_types_cornerkicks_str\n",
      "passing_types_outcomes_off\n",
      "passing_types_outcomes_blocks\n",
      "gca_scatypes_sca\n",
      "gca_scatypes_passlive\n",
      "gca_scatypes_passdead\n",
      "gca_scatypes_to\n",
      "gca_scatypes_sh\n",
      "gca_scatypes_fld\n",
      "gca_scatypes_def\n",
      "gca_gcatypes_gca\n",
      "gca_gcatypes_passlive\n",
      "gca_gcatypes_passdead\n",
      "gca_gcatypes_to\n",
      "gca_gcatypes_sh\n",
      "gca_gcatypes_fld\n",
      "gca_gcatypes_def\n",
      "defense_tackles_tkl\n",
      "defense_tackles_tklw\n",
      "defense_tackles_def3rd\n",
      "defense_tackles_mid3rd\n",
      "defense_tackles_att3rd\n",
      "defense_challenges_tkl\n",
      "defense_challenges_att\n",
      "defense_challenges_tkl_perc\n",
      "defense_challenges_lost\n",
      "defense_blocks_blocks\n",
      "defense_blocks_sh\n",
      "defense_blocks_pass\n",
      "defense_general_int\n",
      "defense_general_tkl_plus_int\n",
      "defense_general_clr\n",
      "defense_general_err\n",
      "possession_general_poss\n",
      "possession_touches_touches\n",
      "possession_touches_defpen\n",
      "possession_touches_def3rd\n",
      "possession_touches_mid3rd\n",
      "possession_touches_att3rd\n",
      "possession_touches_attpen\n",
      "possession_touches_live\n",
      "possession_takeons_att\n",
      "possession_takeons_succ\n",
      "possession_takeons_succ_perc\n",
      "possession_takeons_tkld\n",
      "possession_takeons_tkld_perc\n",
      "possession_carries_carries\n",
      "possession_carries_totdist\n",
      "possession_carries_prgdist\n",
      "possession_carries_prgc\n",
      "possession_carries_1_per_3\n",
      "possession_carries_cpa\n",
      "possession_carries_mis\n",
      "possession_carries_dis\n",
      "possession_receiving_rec\n",
      "possession_receiving_prgr\n",
      "misc_performance_crdy\n",
      "misc_performance_crdr\n",
      "misc_performance_2crdy\n",
      "misc_performance_fls\n",
      "misc_performance_fld\n",
      "misc_performance_off\n",
      "misc_performance_og\n",
      "misc_performance_recov\n",
      "misc_aerialduels_won\n",
      "misc_aerialduels_lost\n",
      "misc_aerialduels_won_perc\n",
      "keeper_penaltykicks_pka\n",
      "attendance\n",
      "referee\n",
      "fbref_season\n",
      "fbref_league_id\n",
      "fbref_own\n",
      "fbref_oppon\n",
      "home\n"
     ]
    }
   ],
   "source": [
    "for i in c.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "62be7b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/xy9hjc0d0v1bds6v1r_nl1xw0000gn/T/ipykernel_23020/3267728420.py:5: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['fbref_match_id', 'schedule_time'], dtype='object')\n",
      "  mov_avg = df.rolling(window = window_size).apply(lambda x: np.sum(weights*x) / sum_weights, raw=False) # compute moving average of window_size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>xg</th>\n",
       "      <th>captain</th>\n",
       "      <th>formation</th>\n",
       "      <th>shooting_standard_gls</th>\n",
       "      <th>shooting_standard_sh</th>\n",
       "      <th>shooting_standard_sot</th>\n",
       "      <th>shooting_standard_sot_perc</th>\n",
       "      <th>shooting_standard_g_per_sh</th>\n",
       "      <th>...</th>\n",
       "      <th>misc_aerialduels_lost</th>\n",
       "      <th>misc_aerialduels_won_perc</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "      <th>attendance</th>\n",
       "      <th>referee</th>\n",
       "      <th>fbref_season</th>\n",
       "      <th>fbref_league_id</th>\n",
       "      <th>fbref_own</th>\n",
       "      <th>fbref_oppon</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>0.830890</td>\n",
       "      <td>1.571848</td>\n",
       "      <td>2.111535</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>1.571848</td>\n",
       "      <td>18.253177</td>\n",
       "      <td>5.759531</td>\n",
       "      <td>30.866471</td>\n",
       "      <td>0.082747</td>\n",
       "      <td>...</td>\n",
       "      <td>9.356794</td>\n",
       "      <td>63.273118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41248.512219</td>\n",
       "      <td>192.415445</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.750733</td>\n",
       "      <td>0.213099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-15</th>\n",
       "      <td>0.414467</td>\n",
       "      <td>1.785924</td>\n",
       "      <td>2.506354</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>1.785924</td>\n",
       "      <td>22.132942</td>\n",
       "      <td>7.882698</td>\n",
       "      <td>34.686999</td>\n",
       "      <td>0.081339</td>\n",
       "      <td>...</td>\n",
       "      <td>9.176931</td>\n",
       "      <td>55.190029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40691.200391</td>\n",
       "      <td>196.205279</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.813294</td>\n",
       "      <td>0.106549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26</th>\n",
       "      <td>0.707722</td>\n",
       "      <td>1.392962</td>\n",
       "      <td>2.403226</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.392962</td>\n",
       "      <td>19.565005</td>\n",
       "      <td>7.441838</td>\n",
       "      <td>37.948974</td>\n",
       "      <td>0.070674</td>\n",
       "      <td>...</td>\n",
       "      <td>9.085044</td>\n",
       "      <td>53.905865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34748.235582</td>\n",
       "      <td>198.613881</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.925709</td>\n",
       "      <td>0.052786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29</th>\n",
       "      <td>0.352884</td>\n",
       "      <td>3.698925</td>\n",
       "      <td>2.852004</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.698925</td>\n",
       "      <td>20.784946</td>\n",
       "      <td>7.721408</td>\n",
       "      <td>37.172141</td>\n",
       "      <td>0.170440</td>\n",
       "      <td>...</td>\n",
       "      <td>5.038123</td>\n",
       "      <td>71.966862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33169.420332</td>\n",
       "      <td>196.313783</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.940371</td>\n",
       "      <td>0.526882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>0.175953</td>\n",
       "      <td>2.349951</td>\n",
       "      <td>2.576051</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.349951</td>\n",
       "      <td>20.892473</td>\n",
       "      <td>6.359726</td>\n",
       "      <td>30.481427</td>\n",
       "      <td>0.085220</td>\n",
       "      <td>...</td>\n",
       "      <td>6.017595</td>\n",
       "      <td>67.584262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32373.189638</td>\n",
       "      <td>191.150538</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.473118</td>\n",
       "      <td>0.763441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 result        gf        xg  captain  formation  \\\n",
       "schedule_date                                                     \n",
       "2017-08-12          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-08-19          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-08-26          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-09-09          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-09-15          NaN       NaN       NaN      NaN        NaN   \n",
       "...                 ...       ...       ...      ...        ...   \n",
       "2023-04-08     0.830890  1.571848  2.111535   1022.0   0.005865   \n",
       "2023-04-15     0.414467  1.785924  2.506354   1022.0   0.002933   \n",
       "2023-04-26     0.707722  1.392962  2.403226   1022.0   0.000000   \n",
       "2023-04-29     0.352884  3.698925  2.852004   1022.0   0.000000   \n",
       "2023-05-04     0.175953  2.349951  2.576051   1022.0   0.000000   \n",
       "\n",
       "               shooting_standard_gls  shooting_standard_sh  \\\n",
       "schedule_date                                                \n",
       "2017-08-12                       NaN                   NaN   \n",
       "2017-08-19                       NaN                   NaN   \n",
       "2017-08-26                       NaN                   NaN   \n",
       "2017-09-09                       NaN                   NaN   \n",
       "2017-09-15                       NaN                   NaN   \n",
       "...                              ...                   ...   \n",
       "2023-04-08                  1.571848             18.253177   \n",
       "2023-04-15                  1.785924             22.132942   \n",
       "2023-04-26                  1.392962             19.565005   \n",
       "2023-04-29                  3.698925             20.784946   \n",
       "2023-05-04                  2.349951             20.892473   \n",
       "\n",
       "               shooting_standard_sot  shooting_standard_sot_perc  \\\n",
       "schedule_date                                                      \n",
       "2017-08-12                       NaN                         NaN   \n",
       "2017-08-19                       NaN                         NaN   \n",
       "2017-08-26                       NaN                         NaN   \n",
       "2017-09-09                       NaN                         NaN   \n",
       "2017-09-15                       NaN                         NaN   \n",
       "...                              ...                         ...   \n",
       "2023-04-08                  5.759531                   30.866471   \n",
       "2023-04-15                  7.882698                   34.686999   \n",
       "2023-04-26                  7.441838                   37.948974   \n",
       "2023-04-29                  7.721408                   37.172141   \n",
       "2023-05-04                  6.359726                   30.481427   \n",
       "\n",
       "               shooting_standard_g_per_sh  ...  misc_aerialduels_lost  \\\n",
       "schedule_date                              ...                          \n",
       "2017-08-12                            NaN  ...                    NaN   \n",
       "2017-08-19                            NaN  ...                    NaN   \n",
       "2017-08-26                            NaN  ...                    NaN   \n",
       "2017-09-09                            NaN  ...                    NaN   \n",
       "2017-09-15                            NaN  ...                    NaN   \n",
       "...                                   ...  ...                    ...   \n",
       "2023-04-08                       0.082747  ...               9.356794   \n",
       "2023-04-15                       0.081339  ...               9.176931   \n",
       "2023-04-26                       0.070674  ...               9.085044   \n",
       "2023-04-29                       0.170440  ...               5.038123   \n",
       "2023-05-04                       0.085220  ...               6.017595   \n",
       "\n",
       "               misc_aerialduels_won_perc  keeper_penaltykicks_pka  \\\n",
       "schedule_date                                                       \n",
       "2017-08-12                           NaN                      NaN   \n",
       "2017-08-19                           NaN                      NaN   \n",
       "2017-08-26                           NaN                      NaN   \n",
       "2017-09-09                           NaN                      NaN   \n",
       "2017-09-15                           NaN                      NaN   \n",
       "...                                  ...                      ...   \n",
       "2023-04-08                     63.273118                      NaN   \n",
       "2023-04-15                     55.190029                      NaN   \n",
       "2023-04-26                     53.905865                      NaN   \n",
       "2023-04-29                     71.966862                      NaN   \n",
       "2023-05-04                     67.584262                      NaN   \n",
       "\n",
       "                 attendance     referee  fbref_season  fbref_league_id  \\\n",
       "schedule_date                                                            \n",
       "2017-08-12              NaN         NaN           NaN              NaN   \n",
       "2017-08-19              NaN         NaN           NaN              NaN   \n",
       "2017-08-26              NaN         NaN           NaN              NaN   \n",
       "2017-09-09              NaN         NaN           NaN              NaN   \n",
       "2017-09-15              NaN         NaN           NaN              NaN   \n",
       "...                     ...         ...           ...              ...   \n",
       "2023-04-08     41248.512219  192.415445           5.0              9.0   \n",
       "2023-04-15     40691.200391  196.205279           5.0              9.0   \n",
       "2023-04-26     34748.235582  198.613881           5.0              9.0   \n",
       "2023-04-29     33169.420332  196.313783           5.0              9.0   \n",
       "2023-05-04     32373.189638  191.150538           5.0              9.0   \n",
       "\n",
       "               fbref_own  fbref_oppon      home  \n",
       "schedule_date                                    \n",
       "2017-08-12           NaN          NaN       NaN  \n",
       "2017-08-19           NaN          NaN       NaN  \n",
       "2017-08-26           NaN          NaN       NaN  \n",
       "2017-09-09           NaN          NaN       NaN  \n",
       "2017-09-15           NaN          NaN       NaN  \n",
       "...                  ...          ...       ...  \n",
       "2023-04-08           1.0    87.750733  0.213099  \n",
       "2023-04-15           1.0    46.813294  0.106549  \n",
       "2023-04-26           1.0    63.925709  0.052786  \n",
       "2023-04-29           1.0    63.940371  0.526882  \n",
       "2023-05-04           1.0    70.473118  0.763441  \n",
       "\n",
       "[222 rows x 150 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = moving_average(club)#.loc[\"2023-04-08\"]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c9afeaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>xg</th>\n",
       "      <th>captain</th>\n",
       "      <th>formation</th>\n",
       "      <th>shooting_standard_gls</th>\n",
       "      <th>shooting_standard_sh</th>\n",
       "      <th>shooting_standard_sot</th>\n",
       "      <th>shooting_standard_sot_perc</th>\n",
       "      <th>shooting_standard_g_per_sh</th>\n",
       "      <th>...</th>\n",
       "      <th>misc_aerialduels_lost</th>\n",
       "      <th>misc_aerialduels_won_perc</th>\n",
       "      <th>keeper_penaltykicks_pka</th>\n",
       "      <th>attendance</th>\n",
       "      <th>referee</th>\n",
       "      <th>fbref_season</th>\n",
       "      <th>fbref_league_id</th>\n",
       "      <th>fbref_own</th>\n",
       "      <th>fbref_oppon</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>0.830890</td>\n",
       "      <td>1.571848</td>\n",
       "      <td>2.111535</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>1.571848</td>\n",
       "      <td>18.253177</td>\n",
       "      <td>5.759531</td>\n",
       "      <td>30.866471</td>\n",
       "      <td>0.082747</td>\n",
       "      <td>...</td>\n",
       "      <td>9.356794</td>\n",
       "      <td>63.273118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41248.512219</td>\n",
       "      <td>192.415445</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.750733</td>\n",
       "      <td>0.213099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-15</th>\n",
       "      <td>0.414467</td>\n",
       "      <td>1.785924</td>\n",
       "      <td>2.506354</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>1.785924</td>\n",
       "      <td>22.132942</td>\n",
       "      <td>7.882698</td>\n",
       "      <td>34.686999</td>\n",
       "      <td>0.081339</td>\n",
       "      <td>...</td>\n",
       "      <td>9.176931</td>\n",
       "      <td>55.190029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40691.200391</td>\n",
       "      <td>196.205279</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.813294</td>\n",
       "      <td>0.106549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26</th>\n",
       "      <td>0.707722</td>\n",
       "      <td>1.392962</td>\n",
       "      <td>2.403226</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.392962</td>\n",
       "      <td>19.565005</td>\n",
       "      <td>7.441838</td>\n",
       "      <td>37.948974</td>\n",
       "      <td>0.070674</td>\n",
       "      <td>...</td>\n",
       "      <td>9.085044</td>\n",
       "      <td>53.905865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34748.235582</td>\n",
       "      <td>198.613881</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.925709</td>\n",
       "      <td>0.052786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29</th>\n",
       "      <td>0.352884</td>\n",
       "      <td>3.698925</td>\n",
       "      <td>2.852004</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.698925</td>\n",
       "      <td>20.784946</td>\n",
       "      <td>7.721408</td>\n",
       "      <td>37.172141</td>\n",
       "      <td>0.170440</td>\n",
       "      <td>...</td>\n",
       "      <td>5.038123</td>\n",
       "      <td>71.966862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33169.420332</td>\n",
       "      <td>196.313783</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.940371</td>\n",
       "      <td>0.526882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>0.175953</td>\n",
       "      <td>2.349951</td>\n",
       "      <td>2.576051</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.349951</td>\n",
       "      <td>20.892473</td>\n",
       "      <td>6.359726</td>\n",
       "      <td>30.481427</td>\n",
       "      <td>0.085220</td>\n",
       "      <td>...</td>\n",
       "      <td>6.017595</td>\n",
       "      <td>67.584262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32373.189638</td>\n",
       "      <td>191.150538</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.473118</td>\n",
       "      <td>0.763441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 result        gf        xg  captain  formation  \\\n",
       "schedule_date                                                     \n",
       "2017-08-12          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-08-19          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-08-26          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-09-09          NaN       NaN       NaN      NaN        NaN   \n",
       "2017-09-15          NaN       NaN       NaN      NaN        NaN   \n",
       "...                 ...       ...       ...      ...        ...   \n",
       "2023-04-08     0.830890  1.571848  2.111535   1022.0   0.005865   \n",
       "2023-04-15     0.414467  1.785924  2.506354   1022.0   0.002933   \n",
       "2023-04-26     0.707722  1.392962  2.403226   1022.0   0.000000   \n",
       "2023-04-29     0.352884  3.698925  2.852004   1022.0   0.000000   \n",
       "2023-05-04     0.175953  2.349951  2.576051   1022.0   0.000000   \n",
       "\n",
       "               shooting_standard_gls  shooting_standard_sh  \\\n",
       "schedule_date                                                \n",
       "2017-08-12                       NaN                   NaN   \n",
       "2017-08-19                       NaN                   NaN   \n",
       "2017-08-26                       NaN                   NaN   \n",
       "2017-09-09                       NaN                   NaN   \n",
       "2017-09-15                       NaN                   NaN   \n",
       "...                              ...                   ...   \n",
       "2023-04-08                  1.571848             18.253177   \n",
       "2023-04-15                  1.785924             22.132942   \n",
       "2023-04-26                  1.392962             19.565005   \n",
       "2023-04-29                  3.698925             20.784946   \n",
       "2023-05-04                  2.349951             20.892473   \n",
       "\n",
       "               shooting_standard_sot  shooting_standard_sot_perc  \\\n",
       "schedule_date                                                      \n",
       "2017-08-12                       NaN                         NaN   \n",
       "2017-08-19                       NaN                         NaN   \n",
       "2017-08-26                       NaN                         NaN   \n",
       "2017-09-09                       NaN                         NaN   \n",
       "2017-09-15                       NaN                         NaN   \n",
       "...                              ...                         ...   \n",
       "2023-04-08                  5.759531                   30.866471   \n",
       "2023-04-15                  7.882698                   34.686999   \n",
       "2023-04-26                  7.441838                   37.948974   \n",
       "2023-04-29                  7.721408                   37.172141   \n",
       "2023-05-04                  6.359726                   30.481427   \n",
       "\n",
       "               shooting_standard_g_per_sh  ...  misc_aerialduels_lost  \\\n",
       "schedule_date                              ...                          \n",
       "2017-08-12                            NaN  ...                    NaN   \n",
       "2017-08-19                            NaN  ...                    NaN   \n",
       "2017-08-26                            NaN  ...                    NaN   \n",
       "2017-09-09                            NaN  ...                    NaN   \n",
       "2017-09-15                            NaN  ...                    NaN   \n",
       "...                                   ...  ...                    ...   \n",
       "2023-04-08                       0.082747  ...               9.356794   \n",
       "2023-04-15                       0.081339  ...               9.176931   \n",
       "2023-04-26                       0.070674  ...               9.085044   \n",
       "2023-04-29                       0.170440  ...               5.038123   \n",
       "2023-05-04                       0.085220  ...               6.017595   \n",
       "\n",
       "               misc_aerialduels_won_perc  keeper_penaltykicks_pka  \\\n",
       "schedule_date                                                       \n",
       "2017-08-12                           NaN                      NaN   \n",
       "2017-08-19                           NaN                      NaN   \n",
       "2017-08-26                           NaN                      NaN   \n",
       "2017-09-09                           NaN                      NaN   \n",
       "2017-09-15                           NaN                      NaN   \n",
       "...                                  ...                      ...   \n",
       "2023-04-08                     63.273118                      NaN   \n",
       "2023-04-15                     55.190029                      NaN   \n",
       "2023-04-26                     53.905865                      NaN   \n",
       "2023-04-29                     71.966862                      NaN   \n",
       "2023-05-04                     67.584262                      NaN   \n",
       "\n",
       "                 attendance     referee  fbref_season  fbref_league_id  \\\n",
       "schedule_date                                                            \n",
       "2017-08-12              NaN         NaN           NaN              NaN   \n",
       "2017-08-19              NaN         NaN           NaN              NaN   \n",
       "2017-08-26              NaN         NaN           NaN              NaN   \n",
       "2017-09-09              NaN         NaN           NaN              NaN   \n",
       "2017-09-15              NaN         NaN           NaN              NaN   \n",
       "...                     ...         ...           ...              ...   \n",
       "2023-04-08     41248.512219  192.415445           5.0              9.0   \n",
       "2023-04-15     40691.200391  196.205279           5.0              9.0   \n",
       "2023-04-26     34748.235582  198.613881           5.0              9.0   \n",
       "2023-04-29     33169.420332  196.313783           5.0              9.0   \n",
       "2023-05-04     32373.189638  191.150538           5.0              9.0   \n",
       "\n",
       "               fbref_own  fbref_oppon      home  \n",
       "schedule_date                                    \n",
       "2017-08-12           NaN          NaN       NaN  \n",
       "2017-08-19           NaN          NaN       NaN  \n",
       "2017-08-26           NaN          NaN       NaN  \n",
       "2017-09-09           NaN          NaN       NaN  \n",
       "2017-09-15           NaN          NaN       NaN  \n",
       "...                  ...          ...       ...  \n",
       "2023-04-08           1.0    87.750733  0.213099  \n",
       "2023-04-15           1.0    46.813294  0.106549  \n",
       "2023-04-26           1.0    63.925709  0.052786  \n",
       "2023-04-29           1.0    63.940371  0.526882  \n",
       "2023-05-04           1.0    70.473118  0.763441  \n",
       "\n",
       "[222 rows x 150 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5e23fdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.loc[\"2023-04-08\",:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7b1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4fc77b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df_column, x):\n",
    "    df_column = torch.tensor(df_column.values)\n",
    "    print(df_column)\n",
    "    df_mean, df_std = torch.mean(df_column), torch.std(df_column)\n",
    "    print(df_mean, df_std)\n",
    "    norm = T.transforms.Normalize(df_mean, df_std)\n",
    "    return norm(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
